
@article{stringer_high-dimensional_2019,
	title = {High-dimensional geometry of population responses in visual cortex},
	rights = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-019-1346-5},
	doi = {10.1038/s41586-019-1346-5},
	abstract = {Analysis of the encoding of natural images by very large populations of neurons in the visual cortex of awake mice characterizes the high dimensional geometry of the neural responses.},
	pages = {1},
	journaltitle = {Nature},
	author = {Stringer, Carsen and Pachitariu, Marius and Steinmetz, Nicholas and Carandini, Matteo and Harris, Kenneth D.},
	urldate = {2019-07-11},
	date = {2019-06-26},
	file = {Snapshot:/home/jdehning/Zotero/storage/U2QQRY6D/s41586-019-1346-5.html:text/html}
}

@article{demirtas_hierarchical_2019,
	title = {Hierarchical Heterogeneity across Human Cortex Shapes Large-Scale Neural Dynamics},
	volume = {101},
	issn = {1097-4199},
	doi = {10.1016/j.neuron.2019.01.017},
	abstract = {The large-scale organization of dynamical neural activity across cortex emerges through long-range interactions among local circuits. We hypothesized that large-scale dynamics are also shaped by heterogeneity of intrinsic local properties across cortical areas. One key axis along which microcircuit properties are specialized relates to hierarchical levels of cortical organization. We developed a large-scale dynamical circuit model of human cortex that incorporates heterogeneity of local synaptic strengths, following a hierarchical axis inferred from magnetic resonance imaging ({MRI})-derived T1- to T2-weighted (T1w/T2w) mapping and fit the model using multimodal neuroimaging data. We found that incorporating hierarchical heterogeneity substantially improves the model fit to functional {MRI} ({fMRI})-measured resting-state functional connectivity and captures sensory-association organization of multiple {fMRI} features. The model predicts hierarchically organized higher-frequency spectral power, which we tested with resting-state magnetoencephalography. These findings suggest circuit-level mechanisms linking spatiotemporal levels of analysis and highlight the importance of local properties and their hierarchical specialization on the large-scale organization of human cortical dynamics.},
	pages = {1181--1194.e13},
	number = {6},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Demirtaş, Murat and Burt, Joshua B. and Helmer, Markus and Ji, Jie Lisa and Adkinson, Brendan D. and Glasser, Matthew F. and Van Essen, David C. and Sotiropoulos, Stamatios N. and Anticevic, Alan and Murray, John D.},
	date = {2019-03-20},
	pmid = {30744986},
	pmcid = {PMC6447428},
	keywords = {brain networks, computational model, cortical gradients, cortical hierarchy, functional connectivity, large-scale modeling, magnetoencephalography, resting-state {fMRI}, structural connectivity}
}

@article{burt_hierarchy_2018,
	title = {Hierarchy of transcriptomic specialization across human cortex captured by structural neuroimaging topography},
	volume = {21},
	issn = {1546-1726},
	doi = {10.1038/s41593-018-0195-0},
	abstract = {Hierarchy provides a unifying principle for the macroscale organization of anatomical and functional properties across primate cortex, yet microscale bases of specialization across human cortex are poorly understood. Anatomical hierarchy is conventionally informed by invasive tract-tracing measurements, creating a need for a principled proxy measure in humans. Moreover, cortex exhibits marked interareal variation in gene expression, yet organizing principles of cortical transcription remain unclear. We hypothesized that specialization of cortical microcircuitry involves hierarchical gradients of gene expression. We found that a noninvasive neuroimaging measure-{MRI}-derived T1-weighted/T2-weighted (T1w/T2w) mapping-reliably indexes anatomical hierarchy, and it captures the dominant pattern of transcriptional variation across human cortex. We found hierarchical gradients in expression profiles of genes related to microcircuit function, consistent with monkey microanatomy, and implicated in neuropsychiatric disorders. Our findings identify a hierarchical axis linking cortical transcription and anatomy, along which gradients of microscale properties may contribute to the macroscale specialization of cortical function.},
	pages = {1251--1259},
	number = {9},
	journaltitle = {Nature Neuroscience},
	shortjournal = {Nat. Neurosci.},
	author = {Burt, Joshua B. and Demirtaş, Murat and Eckner, William J. and Navejar, Natasha M. and Ji, Jie Lisa and Martin, William J. and Bernacchia, Alberto and Anticevic, Alan and Murray, John D.},
	date = {2018},
	pmid = {30082915},
	pmcid = {PMC6119093},
	keywords = {Animals, Brain Mapping, Cerebral Cortex, Gene Expression Regulation, Humans, Interneurons, Macaca mulatta, Magnetic Resonance Imaging, Mental Disorders, Neuroimaging, Pyramidal Cells, Transcriptome},
	file = {Accepted Version:/home/jdehning/Zotero/storage/J6GYHH62/Burt et al. - 2018 - Hierarchy of transcriptomic specialization across .pdf:application/pdf}
}

@article{cirillo_neural_2018,
	title = {Neural Intrinsic Timescales in the Macaque Dorsal Premotor Cortex Predict the Strength of Spatial Response Coding},
	volume = {10},
	issn = {2589-0042},
	url = {http://www.sciencedirect.com/science/article/pii/S2589004218302232},
	doi = {10.1016/j.isci.2018.11.033},
	abstract = {Summary
Our brain continuously receives information over multiple timescales that are differently processed across areas. In this study, we investigated the intrinsic timescale of neurons in the dorsal premotor cortex ({PMd}) of two rhesus macaques while performing a non-match-to-goal task. The task rule was to reject the previously chosen target and select the alternative one. We defined the intrinsic timescale as the decay constant of the autocorrelation structure computed during a baseline period of the task. We found that neurons with longer intrinsic timescale tended to maintain a stronger spatial response coding during a delay period. This result suggests that longer intrinsic timescales predict the functional role of {PMd} neurons in a cognitive task. Our estimate of the intrinsic timescale integrates an existing hierarchical model (Murray et al., 2014), by assigning to {PMd} a lower position than prefrontal cortex in the hierarchical ordering of the brain areas based on neurons' timescales.},
	pages = {203--210},
	journaltitle = {{iScience}},
	shortjournal = {{iScience}},
	author = {Cirillo, Rossella and Fascianelli, Valeria and Ferrucci, Lorenzo and Genovesio, Aldo},
	urldate = {2019-05-23},
	date = {2018-12-21},
	keywords = {Cognitive Neuroscience, Neuroscience},
	file = {ScienceDirect Full Text PDF:/home/jdehning/Zotero/storage/D494DAS3/Cirillo et al. - 2018 - Neural Intrinsic Timescales in the Macaque Dorsal .pdf:application/pdf;ScienceDirect Snapshot:/home/jdehning/Zotero/storage/QWQEFZPD/S2589004218302232.html:text/html}
}

@article{de_heuvel_characterizing_nodate,
	title = {Characterizing spreading dynamics of subsampled systems with non-stationary external input},
	journaltitle = {in preparation},
	author = {de Heuvel, Jorge and Wilting, Jens and Zierenberg, Johannes and Priesemann, Viola}
}

@article{brecht_body_2017,
	title = {The Body Model Theory of Somatosensory Cortex},
	volume = {94},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(17)30456-7},
	doi = {10.1016/j.neuron.2017.05.018},
	pages = {985--992},
	number = {5},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Brecht, Michael},
	urldate = {2019-04-03},
	date = {2017-06-07},
	pmid = {28595055},
	keywords = {body model, brain theory, cortical simulation, ownership, rubber hand illusion, somatosensory cortex},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/QBMJUWIC/Brecht - 2017 - The Body Model Theory of Somatosensory Cortex.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/3XMFBPK3/S0896-6273(17)30456-7.html:text/html}
}

@article{chaudhuri_large-scale_2015,
	title = {A Large-Scale Circuit Mechanism for Hierarchical Dynamical Processing in the Primate Cortex},
	volume = {88},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627315007655},
	doi = {10.1016/j.neuron.2015.09.008},
	abstract = {Summary
We developed a large-scale dynamical model of the macaque neocortex, which is based on recently acquired directed- and weighted-connectivity data from tract-tracing experiments, and which incorporates heterogeneity across areas. A hierarchy of timescales naturally emerges from this system: sensory areas show brief, transient responses to input (appropriate for sensory processing), whereas association areas integrate inputs over time and exhibit persistent activity (suitable for decision-making and working memory). The model displays multiple temporal hierarchies, as evidenced by contrasting responses to visual versus somatosensory stimulation. Moreover, slower prefrontal and temporal areas have a disproportionate impact on global brain dynamics. These findings establish a circuit mechanism for “temporal receptive windows” that are progressively enlarged along the cortical hierarchy, suggest an extension of time integration in decision making from local to large circuits, and should prompt a re-evaluation of the analysis of functional connectivity (measured by {fMRI} or electroencephalography/magnetoencephalography) by taking into account inter-areal heterogeneity.},
	pages = {419--431},
	number = {2},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Chaudhuri, Rishidev and Knoblauch, Kenneth and Gariel, Marie-Alice and Kennedy, Henry and Wang, Xiao-Jing},
	urldate = {2019-04-02},
	date = {2015-10-21},
	file = {ScienceDirect Full Text PDF:/home/jdehning/Zotero/storage/KTDBQ4Y4/Chaudhuri et al. - 2015 - A Large-Scale Circuit Mechanism for Hierarchical D.pdf:application/pdf;ScienceDirect Snapshot:/home/jdehning/Zotero/storage/N47VCHP3/S0896627315007655.html:text/html}
}

@article{brecht_body_2017-1,
	title = {The Body Model Theory of Somatosensory Cortex},
	volume = {94},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627317304567},
	doi = {10.1016/j.neuron.2017.05.018},
	abstract = {I outline a microcircuit theory of somatosensory cortex as a body model serving both for body representation and “body simulation.” A modular model of innervated and non-innervated body parts resides in somatosensory cortical layer 4. This body model is continuously updated and compares to an avatar (an animatable puppet) rather than a mere sensory map. Superficial layers provide context and store sensory memories, whereas layer 5 provides motor output and stores motor memories. I predict that layer-6-to-layer-4 inputs initiate body simulations allowing rehearsal and risk assessment of difficult actions, such as jumps.},
	pages = {985--992},
	number = {5},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Brecht, Michael},
	urldate = {2019-04-02},
	date = {2017-06-07},
	keywords = {body model, brain theory, cortical simulation, ownership, rubber hand illusion, somatosensory cortex},
	file = {ScienceDirect Full Text PDF:/home/jdehning/Zotero/storage/GNGZFMKI/Brecht - 2017 - The Body Model Theory of Somatosensory Cortex.pdf:application/pdf;ScienceDirect Snapshot:/home/jdehning/Zotero/storage/U32ADCAX/S0896627317304567.html:text/html}
}

@article{bakker_scalable_2015,
	title = {The Scalable Brain Atlas: Instant Web-Based Access to Public Brain Atlases and Related Content},
	volume = {13},
	issn = {1559-0089},
	url = {https://doi.org/10.1007/s12021-014-9258-x},
	doi = {10.1007/s12021-014-9258-x},
	shorttitle = {The Scalable Brain Atlas},
	abstract = {The Scalable Brain Atlas ({SBA}) is a collection of web services that provide unified access to a large collection of brain atlas templates for different species. Its main component is an atlas viewer that displays brain atlas data as a stack of slices in which stereotaxic coordinates and brain regions can be selected. These are subsequently used to launch web queries to resources that require coordinates or region names as input. It supports plugins which run inside the viewer and respond when a new slice, coordinate or region is selected. It contains 20 atlas templates in six species, and plugins to compute coordinate transformations, display anatomical connectivity and fiducial points, and retrieve properties, descriptions, definitions and 3d reconstructions of brain regions. The ambition of {SBA} is to provide a unified representation of all publicly available brain atlases directly in the web browser, while remaining a responsive and light weight resource that specializes in atlas comparisons, searches, coordinate transformations and interactive displays.},
	pages = {353--366},
	number = {3},
	journaltitle = {Neuroinformatics},
	shortjournal = {Neuroinform},
	author = {Bakker, Rembrandt and Tiesinga, Paul and Kötter, Rolf},
	urldate = {2019-03-29},
	date = {2015-07-01},
	langid = {english},
	keywords = {Comparative anatomy, Fiducial points, Human, Macaque, Marmoset, Mouse, Online Brain Atlas, Rat, Scalable vector graphics, Structural connectivity},
	file = {Springer Full Text PDF:/home/jdehning/Zotero/storage/IGJMMGH3/Bakker et al. - 2015 - The Scalable Brain Atlas Instant Web-Based Access.pdf:application/pdf}
}

@report{jaeger_echo_2001,
	title = {The “echo state” approach to analysing and training recurrent neural networks with an erratum note},
	number = {{GMD} Technical Report 148},
	author = {Jaeger, Herbert},
	date = {2001}
}

@article{priesemann_subsampling_2009,
	title = {Subsampling effects in neuronal avalanche distributions recorded in vivo},
	volume = {10},
	issn = {1471-2202},
	url = {https://doi.org/10.1186/1471-2202-10-40},
	doi = {10.1186/1471-2202-10-40},
	abstract = {Many systems in nature are characterized by complex behaviour where large cascades of events, or avalanches, unpredictably alternate with periods of little activity. Snow avalanches are an example. Often the size distribution f(s) of a system's avalanches follows a power law, and the branching parameter sigma, the average number of events triggered by a single preceding event, is unity. A power law for f(s), and sigma = 1, are hallmark features of self-organized critical ({SOC}) systems, and both have been found for neuronal activity in vitro. Therefore, and since {SOC} systems and neuronal activity both show large variability, long-term stability and memory capabilities, {SOC} has been proposed to govern neuronal dynamics in vivo. Testing this hypothesis is difficult because neuronal activity is spatially or temporally subsampled, while theories of {SOC} systems assume full sampling. To close this gap, we investigated how subsampling affects f(s) and sigma by imposing subsampling on three different {SOC} models. We then compared f(s) and sigma of the subsampled models with those of multielectrode local field potential ({LFP}) activity recorded in three macaque monkeys performing a short term memory task.},
	pages = {40},
	number = {1},
	journaltitle = {{BMC} Neuroscience},
	shortjournal = {{BMC} Neuroscience},
	author = {Priesemann, Viola and Munk, Matthias {HJ} and Wibral, Michael},
	urldate = {2019-03-28},
	date = {2009-04-29},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/B7EP4VZH/Priesemann et al. - 2009 - Subsampling effects in neuronal avalanche distribu.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/NPPL38RM/1471-2202-10-40.html:text/html}
}

@article{levina_subsampling_2017,
	title = {Subsampling scaling},
	volume = {8},
	rights = {2017 Nature Publishing Group},
	url = {https://www.nature.com/articles/ncomms15140},
	doi = {10.1038/ncomms15140},
	abstract = {In real-world applications, observations are often constrained to a small fraction of a system. Such spatial subsampling can be caused by the inaccessibility or the sheer size of the system, and cannot be overcome by longer sampling. Spatial subsampling can strongly bias inferences about a system’s aggregated properties. To overcome the bias, we derive analytically a subsampling scaling framework that is applicable to different observables, including distributions of neuronal avalanches, of number of people infected during an epidemic outbreak, and of node degrees. We demonstrate how to infer the correct distributions of the underlying full system, how to apply it to distinguish critical from subcritical systems, and how to disentangle subsampling and finite size effects. Lastly, we apply subsampling scaling to neuronal avalanche models and to recordings from developing neural networks. We show that only mature, but not young networks follow power-law scaling, indicating self-organization to criticality during development.},
	pages = {15140},
	journaltitle = {Nature Communications},
	author = {Levina, Anna and Priesemann, Viola},
	urldate = {2019-03-25},
	date = {2017-05-04},
	langid = {english},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/EPA3263V/Levina and Priesemann - 2017 - Subsampling scaling.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/GKY3265W/ncomms15140.html:text/html}
}

@article{beggs_criticality_2008,
	title = {The criticality hypothesis: how local cortical networks might optimize information processing},
	volume = {366},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rsta.2007.2092},
	doi = {10.1098/rsta.2007.2092},
	shorttitle = {The criticality hypothesis},
	abstract = {Early theoretical and simulation work independently undertaken by Packard, Langton and Kauffman suggested that adaptability and computational power would be optimized in systems at the ‘edge of chaos’, at a critical point in a phase transition between total randomness and boring order. This provocative hypothesis has received much attention, but biological experiments supporting it have been relatively few. Here, we review recent experiments on networks of cortical neurons, showing that they appear to be operating near the critical point. Simulation studies capture the main features of these data and suggest that criticality may allow cortical networks to optimize information processing. These simulations lead to predictions that could be tested in the near future, possibly providing further experimental evidence for the criticality hypothesis.},
	pages = {329--343},
	number = {1864},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	shortjournal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Beggs, John M.},
	urldate = {2019-02-27},
	date = {2008-02-13},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/3RJRQA28/Beggs John M - 2008 - The criticality hypothesis how local cortical net.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/IZU2CNL2/rsta.2007.html:text/html}
}

@book{davison_bootstrap_1997,
	location = {Cambridge ; New York, {NY}, {USA}},
	edition = {1 edition},
	title = {Bootstrap Methods And Their Application},
	isbn = {978-0-521-57471-6},
	abstract = {This book gives a broad and up-to-date coverage of bootstrap methods, with numerous applied examples, developed in a coherent way with the necessary theoretical basis. Applications include stratified data; finite populations; censored and missing data; linear, nonlinear, and smooth regression models; classification; time series and spatial problems. Special features of the book include: extensive discussion of significance tests and confidence intervals; material on various diagnostic methods; and methods for efficient computation, including improved Monte Carlo simulation. Each chapter includes both practical and theoretical exercises. Included with the book is a disk of purpose-written S-Plus programs for implementing the methods described in the text. Computer algorithms are clearly described, and computer code is included on a 3-inch, 1.4M disk for use with {IBM} computers and compatible machines. Users must have the S-Plus computer application. Author resource page: http://statwww.epfl.ch/davison/{BMA}/},
	pagetotal = {592},
	publisher = {Cambridge University Press},
	author = {Davison, A. C.},
	date = {1997-10-28},
	file = {Davison - 1997 - Bootstrap Methods And Their Application.pdf:/home/jdehning/Zotero/storage/N7XEFX3P/Davison - 1997 - Bootstrap Methods And Their Application.pdf:application/pdf}
}

@article{hernandez_procedure_2008,
	title = {Procedure for recording the simultaneous activity of single neurons distributed across cortical areas during sensory discrimination},
	volume = {105},
	issn = {0027-8424},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2571910/},
	doi = {10.1073/pnas.0808702105},
	abstract = {We report a procedure for recording the simultaneous activity of single neurons distributed across five cortical areas in behaving monkeys. The procedure consists of a commercially available microdrive adapted to a commercially available neural data collection system. The critical advantage of this procedure is that, in each cortical area, a configuration of seven microelectrodes spaced 250–500 μm can be inserted transdurally and each can be moved independently in the z axis. For each microelectrode, the data collection system can record the activity of up to five neurons together with the local field potential ({LFP}). With this procedure, we normally monitor the simultaneous activity of 70–100 neurons while trained monkeys discriminate the difference in frequency between two vibrotactile stimuli. Approximately 20–60 of these neurons have response properties previously reported in this task. The neuronal recordings show good signal-to-noise ratio, are remarkably stable along a 1-day session, and allow testing several protocols. Microelectrodes are removed from the brain after a 1-day recording session, but are reinserted again the next day by using the same or different x-y microelectrode array configurations. The fact that microelectrodes can be moved in the z axis during the recording session and that the x-y configuration can be changed from day to day maximizes the probability of studying simultaneous interactions, both local and across distant cortical areas, between neurons associated with the different components of this task.},
	pages = {16785--16790},
	number = {43},
	journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
	shortjournal = {Proc Natl Acad Sci U S A},
	author = {Hernández, Adrián and Nácher, Verónica and Luna, Rogelio and Alvarez, Manuel and Zainos, Antonio and Cordero, Silvia and Camarillo, Liliana and Vázquez, Yuriria and Lemus, Luis and Romo, Ranulfo},
	urldate = {2019-03-25},
	date = {2008-10-28},
	pmid = {18946031},
	pmcid = {PMC2571910},
	file = {PubMed Central Full Text PDF:/home/jdehning/Zotero/storage/7X9Z4V3U/Hernández et al. - 2008 - Procedure for recording the simultaneous activity .pdf:application/pdf}
}

@article{ponce-alvarez_dynamics_2012,
	title = {Dynamics of Cortical Neuronal Ensembles Transit from Decision Making to Storage for Later Report},
	volume = {32},
	rights = {Copyright © 2012 the authors 0270-6474/12/3211956-14\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/32/35/11956},
	doi = {10.1523/JNEUROSCI.6176-11.2012},
	abstract = {Decisions based on sensory evaluation during single trials may depend on the collective activity of neurons distributed across brain circuits. Previous studies have deepened our understanding of how the activity of individual neurons relates to the formation of a decision and its storage for later report. However, little is known about how decision-making and decision maintenance processes evolve in single trials. We addressed this problem by studying the activity of simultaneously recorded neurons from different somatosensory and frontal lobe cortices of monkeys performing a vibrotactile discrimination task. We used the hidden Markov model to describe the spatiotemporal pattern of activity in single trials as a sequence of firing rate states. We show that the animal's decision was reliably maintained in frontal lobe activity through a selective state sequence, initiated by an abrupt state transition, during which many neurons changed their activity in a concomitant way, and for which both latency and variability depended on task difficulty. Indeed, transitions were more delayed and more variable for difficult trials compared with easy trials. In contrast, state sequences in somatosensory cortices were weakly decision related, had less variable transitions, and were not affected by the difficulty of the task. In summary, our results suggest that the decision process and its subsequent maintenance are dynamically linked by a cascade of transient events in frontal lobe cortices.},
	pages = {11956--11969},
	number = {35},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Ponce-Alvarez, Adrián and Nácher, Verónica and Luna, Rogelio and Riehle, Alexa and Romo, Ranulfo},
	urldate = {2019-03-25},
	date = {2012-08-29},
	langid = {english},
	pmid = {22933781},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/BYU8GE7G/Ponce-Alvarez et al. - 2012 - Dynamics of Cortical Neuronal Ensembles Transit fr.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/8JAEEEKG/11956.html:text/html}
}

@article{barrett_hierarchical_2012,
	title = {A hierarchical model of the evolution of human brain specializations},
	volume = {109},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/109/Supplement_1/10733},
	doi = {10.1073/pnas.1201898109},
	abstract = {The study of information-processing adaptations in the brain is controversial, in part because of disputes about the form such adaptations might take. Many psychologists assume that adaptations come in two kinds, specialized and general-purpose. Specialized mechanisms are typically thought of as innate, domain-specific, and isolated from other brain systems, whereas generalized mechanisms are developmentally plastic, domain-general, and interactive. However, if brain mechanisms evolve through processes of descent with modification, they are likely to be heterogeneous, rather than coming in just two kinds. They are likely to be hierarchically organized, with some design features widely shared across brain systems and others specific to particular processes. Also, they are likely to be largely developmentally plastic and interactive with other brain systems, rather than canalized and isolated. This article presents a hierarchical model of brain specialization, reviewing evidence for the model from evolutionary developmental biology, genetics, brain mapping, and comparative studies. Implications for the search for uniquely human traits are discussed, along with ways in which conventional views of modularity in psychology may need to be revised.},
	pages = {10733--10740},
	issue = {Supplement 1},
	journaltitle = {Proceedings of the National Academy of Sciences},
	shortjournal = {{PNAS}},
	author = {Barrett, H. Clark},
	urldate = {2019-03-25},
	date = {2012-06-26},
	langid = {english},
	pmid = {22723350},
	keywords = {development, evo-devo, evolutionary psychology, plasticity},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/AX2VT5UP/Barrett - 2012 - A hierarchical model of the evolution of human bra.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/ZB6Z3VB3/10733.html:text/html}
}

@article{lazar_sorn:_2009,
	title = {{SORN}: A Self-Organizing Recurrent Neural Network},
	volume = {3},
	issn = {1662-5188},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2773171/},
	doi = {10.3389/neuro.10.023.2009},
	shorttitle = {{SORN}},
	abstract = {Understanding the dynamics of recurrent neural networks is crucial for explaining how the brain processes information. In the neocortex, a range of different plasticity mechanisms are shaping recurrent networks into effective information processing circuits that learn appropriate representations for time-varying sensory stimuli. However, it has been difficult to mimic these abilities in artificial neural network models. Here we introduce {SORN}, a self-organizing recurrent network. It combines three distinct forms of local plasticity to learn spatio-temporal patterns in its input while maintaining its dynamics in a healthy regime suitable for learning. The {SORN} learns to encode information in the form of trajectories through its high-dimensional state space reminiscent of recent biological findings on cortical coding. All three forms of plasticity are shown to be essential for the network's success.},
	journaltitle = {Frontiers in Computational Neuroscience},
	shortjournal = {Front Comput Neurosci},
	author = {Lazar, Andreea and Pipa, Gordon and Triesch, Jochen},
	urldate = {2019-03-25},
	date = {2009-10-30},
	pmid = {19893759},
	pmcid = {PMC2773171},
	file = {PubMed Central Full Text PDF:/home/jdehning/Zotero/storage/GR4SUBK6/Lazar et al. - 2009 - SORN A Self-Organizing Recurrent Neural Network.pdf:application/pdf}
}

@article{langton_computation_1990,
	title = {Computation at the edge of chaos: Phase transitions and emergent computation},
	volume = {42},
	issn = {0167-2789},
	url = {http://www.sciencedirect.com/science/article/pii/016727899090064V},
	doi = {10.1016/0167-2789(90)90064-V},
	shorttitle = {Computation at the edge of chaos},
	abstract = {In order for computation to emerge spontaneously and become an important factor in the dynamics of a system, the material substrate must support the primitive functions required for computation: the transmission, storage, and modification of information. Under what conditions might we expect physical systems to support such computational primitives? This paper presents research on cellular automata which suggests that the optimal conditions for the support of information transmission, storage, and modification, are achieved in the vicinity of a phase transition. We observe surprising similarities between the behaviors of computations and systems near phase transitions, finding analogs of computational complexity classes and the halting problem within the phenomenology of phase transitions. We conclude that there is a fundamental connection between computation and phase transitions, especially second-order or “critical” transitions, and discuss some of the implications for our understanding of nature if such a connection is borne out.},
	pages = {12--37},
	number = {1},
	journaltitle = {Physica D: Nonlinear Phenomena},
	shortjournal = {Physica D: Nonlinear Phenomena},
	author = {Langton, Chris G.},
	urldate = {2019-03-25},
	date = {1990-06-01},
	file = {ScienceDirect Full Text PDF:/home/jdehning/Zotero/storage/F9ARSNZY/Langton - 1990 - Computation at the edge of chaos Phase transition.pdf:application/pdf;ScienceDirect Snapshot:/home/jdehning/Zotero/storage/GNT5TBI3/016727899090064V.html:text/html}
}

@article{shew_functional_2013,
	title = {The Functional Benefits of Criticality in the Cortex},
	volume = {19},
	issn = {1073-8584},
	url = {https://doi.org/10.1177/1073858412445487},
	doi = {10.1177/1073858412445487},
	abstract = {Rapidly growing empirical evidence supports the hypothesis that the cortex operates near criticality. Although the confirmation of this hypothesis would mark a significant advance in fundamental understanding of cortical physiology, a natural question arises: What functional benefits are endowed to cortical circuits that operate at criticality? In this review, we first describe an introductory-level thought experiment to provide the reader with an intuitive understanding of criticality. Second, we discuss some practical approaches for investigating criticality. Finally, we review quantitative evidence that three functional properties of the cortex are optimized at criticality: 1) dynamic range, 2) information transmission, and 3) information capacity. We focus on recently reported experimental evidence and briefly discuss the theory and history of these ideas.},
	pages = {88--100},
	number = {1},
	journaltitle = {The Neuroscientist},
	shortjournal = {Neuroscientist},
	author = {Shew, Woodrow L. and Plenz, Dietmar},
	urldate = {2019-03-25},
	date = {2013-02-01},
	langid = {english},
	file = {SAGE PDF Full Text:/home/jdehning/Zotero/storage/DJP66YIF/Shew and Plenz - 2013 - The Functional Benefits of Criticality in the Cort.pdf:application/pdf}
}

@article{williams-garcia_quasicritical_2014,
	title = {Quasicritical brain dynamics on a nonequilibrium Widom line},
	volume = {90},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.90.062714},
	doi = {10.1103/PhysRevE.90.062714},
	abstract = {Is the brain really operating at a critical point? We study the nonequilibrium properties of a neural network which models the dynamics of the neocortex and argue for optimal quasicritical dynamics on the Widom line where the correlation length and information transmission are optimized. We simulate the network and introduce an analytical mean-field approximation, characterize the nonequilibrium phase transitions, and present a nonequilibrium phase diagram, which shows that in addition to an ordered and disordered phase, the system exhibits a “quasiperiodic” phase corresponding to synchronous activity in simulations, which may be related to the pathological synchronization associated with epilepsy.},
	pages = {062714},
	number = {6},
	journaltitle = {Physical Review E},
	shortjournal = {Phys. Rev. E},
	author = {Williams-García, Rashid V. and Moore, Mark and Beggs, John M. and Ortiz, Gerardo},
	urldate = {2019-03-25},
	date = {2014-12-23},
	file = {APS Snapshot:/home/jdehning/Zotero/storage/QEHSIF75/PhysRevE.90.html:text/html;Full Text PDF:/home/jdehning/Zotero/storage/XWTZSRSW/Williams-García et al. - 2014 - Quasicritical brain dynamics on a nonequilibrium W.pdf:application/pdf}
}

@article{ribeiro_undersampled_2014,
	title = {Undersampled Critical Branching Processes on Small-World and Random Networks Fail to Reproduce the Statistics of Spike Avalanches},
	volume = {9},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0094992},
	doi = {10.1371/journal.pone.0094992},
	abstract = {The power-law size distributions obtained experimentally for neuronal avalanches are an important evidence of criticality in the brain. This evidence is supported by the fact that a critical branching process exhibits the same exponent . Models at criticality have been employed to mimic avalanche propagation and explain the statistics observed experimentally. However, a crucial aspect of neuronal recordings has been almost completely neglected in the models: undersampling. While in a typical multielectrode array hundreds of neurons are recorded, in the same area of neuronal tissue tens of thousands of neurons can be found. Here we investigate the consequences of undersampling in models with three different topologies (two-dimensional, small-world and random network) and three different dynamical regimes (subcritical, critical and supercritical). We found that undersampling modifies avalanche size distributions, extinguishing the power laws observed in critical systems. Distributions from subcritical systems are also modified, but the shape of the undersampled distributions is more similar to that of a fully sampled system. Undersampled supercritical systems can recover the general characteristics of the fully sampled version, provided that enough neurons are measured. Undersampling in two-dimensional and small-world networks leads to similar effects, while the random network is insensitive to sampling density due to the lack of a well-defined neighborhood. We conjecture that neuronal avalanches recorded from local field potentials avoid undersampling effects due to the nature of this signal, but the same does not hold for spike avalanches. We conclude that undersampled branching-process-like models in these topologies fail to reproduce the statistics of spike avalanches.},
	pages = {e94992},
	number = {4},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Ribeiro, Tiago L. and Ribeiro, Sidarta and Belchior, Hindiael and Caixeta, Fábio and Copelli, Mauro},
	urldate = {2019-03-25},
	date = {2014-04-21},
	langid = {english},
	keywords = {Action potentials, Electrode recording, Employment, Imitation, Neural networks, Neurons, Statistical mechanics, Synapses},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/4WTDLAGT/Ribeiro et al. - 2014 - Undersampled Critical Branching Processes on Small.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/VEXPJDV4/article.html:text/html}
}

@article{mengistu_evolutionary_2016,
	title = {The Evolutionary Origins of Hierarchy},
	volume = {12},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004829},
	doi = {10.1371/journal.pcbi.1004829},
	abstract = {Hierarchical organization—the recursive composition of sub-modules—is ubiquitous in biological networks, including neural, metabolic, ecological, and genetic regulatory networks, and in human-made systems, such as large organizations and the Internet. To date, most research on hierarchy in networks has been limited to quantifying this property. However, an open, important question in evolutionary biology is why hierarchical organization evolves in the first place. It has recently been shown that modularity evolves because of the presence of a cost for network connections. Here we investigate whether such connection costs also tend to cause a hierarchical organization of such modules. In computational simulations, we find that networks without a connection cost do not evolve to be hierarchical, even when the task has a hierarchical structure. However, with a connection cost, networks evolve to be both modular and hierarchical, and these networks exhibit higher overall performance and evolvability (i.e. faster adaptation to new environments). Additional analyses confirm that hierarchy independently improves adaptability after controlling for modularity. Overall, our results suggest that the same force–the cost of connections–promotes the evolution of both hierarchy and modularity, and that these properties are important drivers of network performance and adaptability. In addition to shedding light on the emergence of hierarchy across the many domains in which it appears, these findings will also accelerate future research into evolving more complex, intelligent computational brains in the fields of artificial intelligence and robotics.},
	pages = {e1004829},
	number = {6},
	journaltitle = {{PLOS} Computational Biology},
	shortjournal = {{PLOS} Computational Biology},
	author = {Mengistu, Henok and Huizinga, Joost and Mouret, Jean-Baptiste and Clune, Jeff},
	urldate = {2019-03-25},
	date = {2016-06-09},
	langid = {english},
	keywords = {Neural networks, Neurons, Evolutionary biology, Evolutionary genetics, Gene regulatory networks, Genetic networks, Logic circuits, Network analysis},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/QJ4J2UGV/Mengistu et al. - 2016 - The Evolutionary Origins of Hierarchy.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/NBEB9P8B/article.html:text/html}
}

@article{fiser_statistically_2010,
	title = {Statistically optimal perception and learning: from behavior to neural representations},
	volume = {14},
	issn = {1364-6613},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661310000045},
	doi = {10.1016/j.tics.2010.01.003},
	shorttitle = {Statistically optimal perception and learning},
	abstract = {Human perception has recently been characterized as statistical inference based on noisy and ambiguous sensory inputs. Moreover, suitable neural representations of uncertainty have been identified that could underlie such probabilistic computations. In this review, we argue that learning an internal model of the sensory environment is another key aspect of the same statistical inference procedure and thus perception and learning need to be treated jointly. We review evidence for statistically optimal learning in humans and animals, and re-evaluate possible neural representations of uncertainty based on their potential to support statistically optimal learning. We propose that spontaneous activity can have a functional role in such representations leading to a new, sampling-based, framework of how the cortex represents information and uncertainty.},
	pages = {119--130},
	number = {3},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Fiser, József and Berkes, Pietro and Orbán, Gergő and Lengyel, Máté},
	urldate = {2019-03-25},
	date = {2010-03-01},
	file = {ScienceDirect Full Text PDF:/home/jdehning/Zotero/storage/5XTSGWEL/Fiser et al. - 2010 - Statistically optimal perception and learning fro.pdf:application/pdf;ScienceDirect Snapshot:/home/jdehning/Zotero/storage/KWF9KD56/S1364661310000045.html:text/html}
}

@article{berkes_spontaneous_2011,
	title = {Spontaneous Cortical Activity Reveals Hallmarks of an Optimal Internal Model of the Environment},
	volume = {331},
	rights = {Copyright © 2011, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/331/6013/83},
	doi = {10.1126/science.1195870},
	abstract = {The brain maintains internal models of its environment to interpret sensory inputs and to prepare actions. Although behavioral studies have demonstrated that these internal models are optimally adapted to the statistics of the environment, the neural underpinning of this adaptation is unknown. Using a Bayesian model of sensory cortical processing, we related stimulus-evoked and spontaneous neural activities to inferences and prior expectations in an internal model and predicted that they should match if the model is statistically optimal. To test this prediction, we analyzed visual cortical activity of awake ferrets during development. Similarity between spontaneous and evoked activities increased with age and was specific to responses evoked by natural scenes. This demonstrates the progressive adaptation of internal models to the statistics of natural stimuli at the neural level.
Internal models of the environment optimize as the brain develops.
Internal models of the environment optimize as the brain develops.},
	pages = {83--87},
	number = {6013},
	journaltitle = {Science},
	author = {Berkes, Pietro and Orbán, Gergő and Lengyel, Máté and Fiser, József},
	urldate = {2019-03-25},
	date = {2011-01-07},
	langid = {english},
	pmid = {21212356},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/6HUTYJGL/Berkes et al. - 2011 - Spontaneous Cortical Activity Reveals Hallmarks of.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/EH4KIHKF/83.html:text/html}
}

@online{noauthor_frontiers_nodate,
	title = {Frontiers {\textbar} {SORN}: a self-organizing recurrent neural network {\textbar} Frontiers in Computational Neuroscience},
	url = {https://www.frontiersin.org/articles/10.3389/neuro.10.023.2009/full},
	urldate = {2019-03-25},
	file = {Frontiers | SORN\: a self-organizing recurrent neural network | Frontiers in Computational Neuroscience:/home/jdehning/Zotero/storage/R4PUDWWG/full.html:text/html}
}

@article{boedecker_information_2012,
	title = {Information processing in echo state networks at the edge of chaos},
	volume = {131},
	issn = {1611-7530},
	doi = {10.1007/s12064-011-0146-8},
	abstract = {We investigate information processing in randomly connected recurrent neural networks. It has been shown previously that the computational capabilities of these networks are maximized when the recurrent layer is close to the border between a stable and an unstable dynamics regime, the so called edge of chaos. The reasons, however, for this maximized performance are not completely understood. We adopt an information-theoretical framework and are for the first time able to quantify the computational capabilities between elements of these networks directly as they undergo the phase transition to chaos. Specifically, we present evidence that both information transfer and storage in the recurrent layer are maximized close to this phase transition, providing an explanation for why guiding the recurrent layer toward the edge of chaos is computationally useful. As a consequence, our study suggests self-organized ways of improving performance in recurrent neural networks, driven by input data. Moreover, the networks we study share important features with biological systems such as feedback connections and online computation on input streams. A key example is the cerebral cortex, which was shown to also operate close to the edge of chaos. Consequently, the behavior of model systems as studied here is likely to shed light on reasons why biological systems are tuned into this specific regime.},
	pages = {205--213},
	number = {3},
	journaltitle = {Theory in Biosciences = Theorie in Den Biowissenschaften},
	shortjournal = {Theory Biosci.},
	author = {Boedecker, Joschka and Obst, Oliver and Lizier, Joseph T. and Mayer, N. Michael and Asada, Minoru},
	date = {2012-09},
	pmid = {22147532},
	keywords = {Cerebral Cortex, Humans, Information Theory, Neural Networks (Computer)}
}

@article{stokes_activity-silent_2015,
	title = {‘Activity-silent’ working memory in prefrontal cortex: a dynamic coding framework},
	volume = {19},
	issn = {1364-6613},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661315001023},
	doi = {10.1016/j.tics.2015.05.004},
	shorttitle = {‘Activity-silent’ working memory in prefrontal cortex},
	abstract = {Working memory ({WM}) provides the functional backbone to high-level cognition. Maintenance in {WM} is often assumed to depend on the stationary persistence of neural activity patterns that represent memory content. However, accumulating evidence suggests that persistent delay activity does not always accompany {WM} maintenance but instead seems to wax and wane as a function of the current task relevance of memoranda. Furthermore, new methods for measuring and analysing population-level patterns show that activity states are highly dynamic. At first glance, these dynamics seem at odds with the very nature of {WM}. How can we keep a stable thought in mind while brain activity is constantly changing? This review considers how neural dynamics might be functionally important for {WM} maintenance.},
	pages = {394--405},
	number = {7},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Stokes, Mark G.},
	date = {2015-07},
	file = {ScienceDirect Snapshot:/home/jdehning/Zotero/storage/8WNG6SCB/S1364661315001023.html:text/html}
}

@article{maass_real-time_2002,
	title = {Real-time computing without stable states: a new framework for neural computation based on perturbations},
	volume = {14},
	issn = {0899-7667},
	doi = {10.1162/089976602760407955},
	shorttitle = {Real-time computing without stable states},
	abstract = {A key challenge for neural modeling is to explain how a continuous stream of multimodal input from a rapidly changing environment can be processed by stereotypical recurrent circuits of integrate-and-fire neurons in real time. We propose a new computational model for real-time computing on time-varying input that provides an alternative to paradigms based on Turing machines or attractor neural networks. It does not require a task-dependent construction of neural circuits. Instead, it is based on principles of high-dimensional dynamical systems in combination with statistical learning theory and can be implemented on generic evolved or found recurrent circuitry. It is shown that the inherent transient dynamics of the high-dimensional dynamical system formed by a sufficiently large and heterogeneous neural circuit may serve as universal analog fading memory. Readout neurons can learn to extract in real time from the current state of such recurrent neural circuit information about current and past inputs that may be needed for diverse tasks. Stable internal states are not required for giving a stable output, since transient internal states can be transformed by readout neurons into stable target outputs due to the high dimensionality of the dynamical system. Our approach is based on a rigorous computational model, the liquid state machine, that, unlike Turing machines, does not require sequential transitions between well-defined discrete internal states. It is supported, as the Turing machine is, by rigorous mathematical results that predict universal computational power under idealized conditions, but for the biologically more realistic scenario of real-time processing of time-varying inputs. Our approach provides new perspectives for the interpretation of neural coding, the design of experiments and data analysis in neurophysiology, and the solution of problems in robotics and neurotechnology.},
	pages = {2531--2560},
	number = {11},
	journaltitle = {Neural Computation},
	shortjournal = {Neural Comput},
	author = {Maass, Wolfgang and Natschläger, Thomas and Markram, Henry},
	date = {2002-11},
	pmid = {12433288},
	keywords = {Neurons, Neural Networks (Computer), Action Potentials, Computer Simulation, Computer Systems, Computers, Models, Neurological}
}

@article{schuecker_optimal_2018,
	title = {Optimal Sequence Memory in Driven Random Networks},
	volume = {8},
	url = {https://link.aps.org/doi/10.1103/PhysRevX.8.041029},
	doi = {10.1103/PhysRevX.8.041029},
	abstract = {Autonomous, randomly coupled, neural networks display a transition to chaos at a critical coupling strength. Here, we investigate the effect of a time-varying input on the onset of chaos and the resulting consequences for information processing. Dynamic mean-field theory yields the statistics of the activity, the maximum Lyapunov exponent, and the memory capacity of the network. We find an exact condition that determines the transition from stable to chaotic dynamics and the sequential memory capacity in closed form. The input suppresses chaos by a dynamic mechanism, shifting the transition to significantly larger coupling strengths than predicted by local stability analysis. Beyond linear stability, a regime of coexistent locally expansive but nonchaotic dynamics emerges that optimizes the capacity of the network to store sequential input.},
	pages = {041029},
	number = {4},
	journaltitle = {Physical Review X},
	shortjournal = {Phys. Rev. X},
	author = {Schuecker, Jannis and Goedeke, Sven and Helias, Moritz},
	urldate = {2019-03-25},
	date = {2018-11-14},
	file = {APS Snapshot:/home/jdehning/Zotero/storage/ELL7MGCY/PhysRevX.8.html:text/html;Full Text PDF:/home/jdehning/Zotero/storage/WRMDWZDM/Schuecker et al. - 2018 - Optimal Sequence Memory in Driven Random Networks.pdf:application/pdf}
}

@article{humplik_probabilistic_2017,
	title = {Probabilistic models for neural populations that naturally capture global coupling and criticality},
	volume = {13},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005763},
	doi = {10.1371/journal.pcbi.1005763},
	abstract = {Advances in multi-unit recordings pave the way for statistical modeling of activity patterns in large neural populations. Recent studies have shown that the summed activity of all neurons strongly shapes the population response. A separate recent finding has been that neural populations also exhibit criticality, an anomalously large dynamic range for the probabilities of different population activity patterns. Motivated by these two observations, we introduce a class of probabilistic models which takes into account the prior knowledge that the neural population could be globally coupled and close to critical. These models consist of an energy function which parametrizes interactions between small groups of neurons, and an arbitrary positive, strictly increasing, and twice differentiable function which maps the energy of a population pattern to its probability. We show that: 1) augmenting a pairwise Ising model with a nonlinearity yields an accurate description of the activity of retinal ganglion cells which outperforms previous models based on the summed activity of neurons; 2) prior knowledge that the population is critical translates to prior expectations about the shape of the nonlinearity; 3) the nonlinearity admits an interpretation in terms of a continuous latent variable globally coupling the system whose distribution we can infer from data. Our method is independent of the underlying system’s state space; hence, it can be applied to other systems such as natural scenes or amino acid sequences of proteins which are also known to exhibit criticality.},
	pages = {e1005763},
	number = {9},
	journaltitle = {{PLOS} Computational Biology},
	shortjournal = {{PLOS} Computational Biology},
	author = {Humplik, Jan and Tkačik, Gašper},
	urldate = {2019-03-25},
	date = {2017-09-19},
	langid = {english},
	keywords = {Neurons, Computational linguistics, Covariance, Entropy, Probability density, Probability distribution, Statistical models, Thermodynamics},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/Z8R8VXEM/Humplik and Tkačik - 2017 - Probabilistic models for neural populations that n.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/P5ZTIYGT/article.html:text/html}
}

@article{gollo_leonardo_l._coexistence_2017,
	title = {Coexistence of critical sensitivity and subcritical specificity can yield optimal population coding},
	volume = {14},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rsif.2017.0207},
	doi = {10.1098/rsif.2017.0207},
	abstract = {The vicinity of phase transitions selectively amplifies weak stimuli, yielding optimal sensitivity to distinguish external input. Along with this enhanced sensitivity, enhanced levels of fluctuations at criticality reduce the specificity of the response. Given that the specificity of the response is largely compromised when the sensitivity is maximal, the overall benefit of criticality for signal processing remains questionable. Here, it is shown that this impasse can be solved by heterogeneous systems incorporating functional diversity, in which critical and subcritical components coexist. The subnetwork of critical elements has optimal sensitivity, and the subnetwork of subcritical elements has enhanced specificity. Combining segregated features extracted from the different subgroups, the resulting collective response can maximize the trade-off between sensitivity and specificity measured by the dynamic-range-to-noise ratio. Although numerous benefits can be observed when the entire system is critical, our results highlight that optimal performance is obtained when only a small subset of the system is at criticality.},
	pages = {20170207},
	number = {134},
	journaltitle = {Journal of The Royal Society Interface},
	shortjournal = {Journal of The Royal Society Interface},
	author = {{Gollo Leonardo L.}},
	urldate = {2019-03-25},
	date = {2017-09-30},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/A95EXMIL/Gollo Leonardo L. - 2017 - Coexistence of critical sensitivity and subcritica.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/FHJA6JX7/rsif.2017.html:text/html}
}

@article{krauss_analysis_2019,
	title = {Analysis of Structure and Dynamics in Three-Neuron Motifs},
	volume = {13},
	issn = {1662-5188},
	url = {https://www.frontiersin.org/articles/10.3389/fncom.2019.00005/full},
	doi = {10.3389/fncom.2019.00005},
	abstract = {Recurrent neural networks can produce ongoing state-to-state transitions without any driving inputs, and the dynamical properties of these transitions are determined by the neuronal connection strengths. Due to non-linearity, it is not clear how strongly the system dynamics is affected by discrete local changes in the connection structure, such as the removal, addition, or sign-switching of individual connections. Moreover, there are no suitable metrics to quantify structural and dynamical differences between two given networks with arbitrarily indexed neurons. In this work, we present such permutation-invariant metrics and apply them to motifs of three binary neurons with discrete ternary connection strengths, an important class of building blocks in biological networks. Using multidimensional scaling, we then study the similarity relations between all 3411 topologically distinct motifs with regard to structure and dynamics, revealing a strong clustering and various symmetries. As expected, the structural and dynamical distance between pairs of motifs show a significant positive correlation. Strikingly, however, the key parameter controlling motif dynamics turns out to be the ratio of excitatory to inhibitory connections.},
	journaltitle = {Frontiers in Computational Neuroscience},
	shortjournal = {Front. Comput. Neurosci.},
	author = {Krauss, Patrick and Zankl, Alexandra and Schilling, Achim and Schulze, Holger and Metzner, Claus},
	urldate = {2019-03-25},
	date = {2019},
	keywords = {Boltzmann Neurons, dynamics, neural networks, Structure, Three-node network motifs},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/SCIDC7G9/Krauss et al. - 2019 - Analysis of Structure and Dynamics in Three-Neuron.pdf:application/pdf}
}

@article{cohen_attention_2009,
	title = {Attention improves performance primarily by reducing interneuronal correlations},
	volume = {12},
	issn = {1097-6256},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2820564/},
	doi = {10.1038/nn.2439},
	abstract = {Visual attention can dramatically improve behavioural performance by allowing observers to focus on the important information in a complex scene. Attention also typically increases the firing rates of cortical sensory neurons. Rate increases improve the signal-to-noise ratio of individual neurons, and this improvement has been assumed to underlie attention-related improvements in behaviour. We recorded dozens of neurons simultaneously in visual area V4 and found that changes in single neurons accounted for only a small fraction of the improvement in the sensitivity of the population. Instead, over 80\% of the attentional improvement in the population signal was caused by decreases in the correlations between the trial-to-trial fluctuations in the responses of pairs of neurons. These results suggest that the representation of sensory information in populations of neurons and the way attention affects the sensitivity of the population may only be understood by considering the interactions between neurons.},
	pages = {1594--1600},
	number = {12},
	journaltitle = {Nature neuroscience},
	shortjournal = {Nat Neurosci},
	author = {Cohen, Marlene R and Maunsell, John {HR}},
	urldate = {2019-03-24},
	date = {2009-12},
	pmid = {19915566},
	pmcid = {PMC2820564},
	file = {PubMed Central Full Text PDF:/home/jdehning/Zotero/storage/MIPSSJ9V/Cohen and Maunsell - 2009 - Attention improves performance primarily by reduci.pdf:application/pdf}
}

@article{johansen-berg_attention_2000,
	title = {Attention to touch modulates activity in both primary and secondary somatosensory areas.},
	volume = {11},
	issn = {0959-4965},
	url = {https://ora.ox.ac.uk/objects/uuid:57d3c102-5ace-4a66-a3d9-28ad41552c81},
	abstract = {We used {fMRI} to establish whether attention to touch enhances somatosensory cortical activity. Subjects received somatosensory and visual stimulation and were instructed to attend selectively to one modality during alternating stimulus detection periods interspersed with rest periods during which no stimulus was delivered. The maximum signal change for each task versus rest was measured in anatomically defined regions of interest for each subject. Attended touch produced greater signal change than unattended touch in primary (S1) and secondary (S2) somatosensory cortex. In contrast to the conclusions of some previous studies, we found that the enhancement of activation with attention was at least as great in S1 as in S2. The attentional effect was unilateral in S1 and bilateral in S2 and the somatosensory insula.},
	number = {6},
	journaltitle = {Neuroreport},
	author = {Johansen-Berg, H. and Christensen, V. and Woolrich, M. and Matthews, P. M.},
	urldate = {2019-03-24},
	date = {2000},
	langid = {english},
	file = {Snapshot:/home/jdehning/Zotero/storage/Q3YRW5W7/uuid57d3c102-5ace-4a66-a3d9-28ad41552c81.html:text/html}
}

@article{stringer_high-dimensional_2018,
	title = {High-dimensional geometry of population responses in visual cortex},
	rights = {© 2018, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-{NonCommercial} 4.0 International), {CC} {BY}-{NC} 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/374090v2},
	doi = {10.1101/374090},
	abstract = {{\textless}p{\textgreater}A neuronal population encodes information most efficiently when its activity is uncorrelated and high-dimensional, and most robustly when its activity is correlated and lower-dimensional. Here, we analyzed the correlation structure of natural image coding, in large visual cortical populations recorded from awake mice. Evoked population activity was high dimensional, with correlations obeying an unexpected power-law: the n-th principal component variance scaled as 1/n. This was not inherited from the 1/f spectrum of natural images, because it persisted after stimulus whitening. We proved mathematically that the variance spectrum must decay at least this fast if a population code is smooth, i.e. if small changes in input cannot dominate population activity. The theory also predicts larger power-law exponents for lower-dimensional stimulus ensembles, which we validated experimentally. These results suggest that coding smoothness represents a fundamental constraint governing correlations in neural population codes.{\textless}/p{\textgreater}},
	pages = {374090},
	journaltitle = {{bioRxiv}},
	author = {Stringer, Carsen and Pachitariu, Marius and Steinmetz, Nicholas and Carandini, Matteo and Harris, Kenneth D.},
	urldate = {2019-03-22},
	date = {2018-08-13},
	langid = {english},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/TP59MYIR/Stringer et al. - 2018 - High-dimensional geometry of population responses .pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/ES8V9Z82/374090v2.html:text/html}
}

@article{runyan_distinct_2017,
	title = {Distinct timescales of population coding across cortex},
	volume = {548},
	rights = {2017 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature23020},
	doi = {10.1038/nature23020},
	abstract = {The cortex represents information across widely varying timescales1,2,3,4,5. For instance, sensory cortex encodes stimuli that fluctuate over few tens of milliseconds6,7, whereas in association cortex behavioural choices can require the maintenance of information over seconds8,9. However, it remains poorly understood whether diverse timescales result mostly from features intrinsic to individual neurons or from neuronal population activity. This question remains unanswered, because the timescales of coding in populations of neurons have not been studied extensively, and population codes have not been compared systematically across cortical regions. Here we show that population codes can be essential to achieve long coding timescales. Furthermore, we find that the properties of population codes differ between sensory and association cortices. We compared coding for sensory stimuli and behavioural choices in auditory cortex and posterior parietal cortex as mice performed a sound localization task. Auditory stimulus information was stronger in auditory cortex than in posterior parietal cortex, and both regions contained choice information. Although auditory cortex and posterior parietal cortex coded information by tiling in time neurons that were transiently informative for approximately 200 milliseconds, the areas had major differences in functional coupling between neurons, measured as activity correlations that could not be explained by task events. Coupling among posterior parietal cortex neurons was strong and extended over long time lags, whereas coupling among auditory cortex neurons was weak and short-lived. Stronger coupling in posterior parietal cortex led to a population code with long timescales and a representation of choice that remained consistent for approximately 1 second. In contrast, auditory cortex had a code with rapid fluctuations in stimulus and choice information over hundreds of milliseconds. Our results reveal that population codes differ across cortex and that coupling is a variable property of cortical populations that affects the timescale of information coding and the accuracy of behaviour.},
	pages = {92--96},
	number = {7665},
	journaltitle = {Nature},
	author = {Runyan, Caroline A. and Piasini, Eugenio and Panzeri, Stefano and Harvey, Christopher D.},
	urldate = {2019-03-21},
	date = {2017-08},
	langid = {english},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/LF739Z7T/Runyan et al. - 2017 - Distinct timescales of population coding across co.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/IG4EG4N3/nature23020.html:text/html}
}

@article{hasson_hierarchical_2015,
	title = {Hierarchical process memory: memory as an integral component of information processing},
	volume = {19},
	issn = {1364-6613},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4457571/},
	doi = {10.1016/j.tics.2015.04.006},
	shorttitle = {Hierarchical process memory},
	abstract = {Models of working memory commonly focus on how information is encoded into and retrieved from storage at specific moments. However, in the majority of real-life processes, past information is used continuously to process incoming information across multiple timescales. Considering single unit, electrocorticography, and functional imaging data, we argue that (i) virtually all cortical circuits can accumulate information over time, and (ii) the timescales of accumulation vary hierarchically, from early sensory areas with short processing timescales (tens to hundreds of milliseconds) to higher-order areas with long processing timescales (many seconds to minutes). In this hierarchical systems perspective, memory is not restricted to a few localized stores, but is intrinsic to information processing that unfolds throughout the brain on multiple timescales.
“The present contains nothing more than the past, and what is found in the effect was already in the cause.”Henri L Bergson},
	pages = {304--313},
	number = {6},
	journaltitle = {Trends in cognitive sciences},
	shortjournal = {Trends Cogn Sci},
	author = {Hasson, Uri and Chen, Janice and Honey, Christopher J.},
	urldate = {2019-03-19},
	date = {2015-06},
	pmid = {25980649},
	pmcid = {PMC4457571},
	file = {PubMed Central Full Text PDF:/home/jdehning/Zotero/storage/XX29XQZH/Hasson et al. - 2015 - Hierarchical process memory memory as an integral.pdf:application/pdf}
}

@article{chevallier_stimulus_2018,
	title = {Stimulus Sensitivity of a Spiking Neural Network Model},
	volume = {170},
	issn = {1572-9613},
	url = {https://doi.org/10.1007/s10955-017-1948-y},
	doi = {10.1007/s10955-017-1948-y},
	abstract = {Some recent papers relate the criticality of complex systems to their maximal capacity of information processing. In the present paper, we consider high dimensional point processes, known as age-dependent Hawkes processes, which have been used to model spiking neural networks. Using mean-field approximation, the response of the network to a stimulus is computed and we provide a notion of stimulus sensitivity. It appears that the maximal sensitivity is achieved in the sub-critical regime, yet almost critical for a range of biologically relevant parameters.},
	pages = {800--808},
	number = {4},
	journaltitle = {Journal of Statistical Physics},
	shortjournal = {J Stat Phys},
	author = {Chevallier, Julien},
	urldate = {2019-03-12},
	date = {2018-02-01},
	langid = {english},
	keywords = {60K35, 82B27, 92B20, Criticality, Hawkes process, Time elapsed equation, Transmission of information},
	file = {Springer Full Text PDF:/home/jdehning/Zotero/storage/KG73C4PM/Chevallier - 2018 - Stimulus Sensitivity of a Spiking Neural Network M.pdf:application/pdf}
}

@article{mongillo_synaptic_2008,
	title = {Synaptic Theory of Working Memory},
	volume = {319},
	rights = {American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/319/5869/1543},
	doi = {10.1126/science.1150769},
	abstract = {It is usually assumed that enhanced spiking activity in the form of persistent reverberation for several seconds is the neural correlate of working memory. Here, we propose that working memory is sustained by calcium-mediated synaptic facilitation in the recurrent connections of neocortical networks. In this account, the presynaptic residual calcium is used as a buffer that is loaded, refreshed, and read out by spiking activity. Because of the long time constants of calcium kinetics, the refresh rate can be low, resulting in a mechanism that is metabolically efficient and robust. The duration and stability of working memory can be regulated by modulating the spontaneous activity in the network.
Stronger synapses induced by calcium currents are responsible for working memory rather than the more metabolically expensive action potential firing, as had been thought.
Stronger synapses induced by calcium currents are responsible for working memory rather than the more metabolically expensive action potential firing, as had been thought.},
	pages = {1543--1546},
	number = {5869},
	journaltitle = {Science},
	author = {Mongillo, Gianluigi and Barak, Omri and Tsodyks, Misha},
	urldate = {2019-03-04},
	date = {2008-03-14},
	langid = {english},
	pmid = {18339943},
	file = {Snapshot:/home/jdehning/Zotero/storage/B3B3TWF8/1543.html:text/html}
}

@article{mongillo_inhibitory_2018,
	title = {Inhibitory connectivity defines the realm of excitatory plasticity},
	volume = {21},
	rights = {2018 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-018-0226-x},
	doi = {10.1038/s41593-018-0226-x},
	abstract = {Mongillo et al. use theoretical modeling to link structure \&amp; activity in a cortical network. They find that activity patterns are predominantly controlled by inhibitory connections, making the network robust to ongoing changes in excitatory synapses.},
	pages = {1463},
	number = {10},
	journaltitle = {Nature Neuroscience},
	author = {Mongillo, Gianluigi and Rumpel, Simon and Loewenstein, Yonatan},
	urldate = {2019-03-04},
	date = {2018-10},
	file = {Snapshot:/home/jdehning/Zotero/storage/QEPHYS6I/s41593-018-0226-x.html:text/html}
}

@article{hoftman_altered_2018,
	title = {Altered Gradients of Glutamate and Gamma-Aminobutyric Acid Transcripts in the Cortical Visuospatial Working Memory Network in Schizophrenia},
	volume = {83},
	issn = {0006-3223, 1873-2402},
	url = {https://www.biologicalpsychiatryjournal.com/article/S0006-3223(17)32250-3/abstract},
	doi = {10.1016/j.biopsych.2017.11.029},
	abstract = {{\textless}h2{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}h3{\textgreater}Background{\textless}/h3{\textgreater}{\textless}p{\textgreater}Visuospatial working memory ({vsWM}), which is impaired in schizophrenia, requires information transfer across multiple nodes in the cerebral cortex, including visual, posterior parietal, and dorsolateral prefrontal regions. Information is conveyed across these regions via the excitatory projections of glutamatergic pyramidal neurons located in layer 3, whose activity is modulated by local inhibitory gamma-aminobutyric acidergic ({GABAergic}) neurons. Key properties of these neurons differ across these cortical regions. Consequently, in schizophrenia, alterations in the expression of gene products regulating these properties could disrupt {vsWM} function in different ways, depending on the region(s) affected.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Methods{\textless}/h3{\textgreater}{\textless}p{\textgreater}Here, we quantified the expression of markers of glutamate and {GABA} neurotransmission selectively in layer 3 of four cortical regions in the {vsWM} network from 20 matched pairs of schizophrenia and unaffected comparison subjects.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater}{\textless}p{\textgreater}In comparison subjects, levels of glutamate transcripts tended to increase, whereas {GABA} transcript levels tended to decrease, from caudal to rostral, across cortical regions of the {vsWM} network. Composite measures across all transcripts revealed a significant effect of region, with the glutamate measure lowest in the primary visual cortex and highest in the dorsolateral prefrontal cortex, whereas the {GABA} measure showed the opposite pattern. In schizophrenia subjects, the expression levels of many of these transcripts were altered. However, this disease effect differed across regions, such that the caudal-to-rostral increase in the glutamate measure was blunted and the caudal-to-rostral decline in the {GABA} measure was enhanced in the illness.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions{\textless}/h3{\textgreater}{\textless}p{\textgreater}Differential alterations in layer 3 glutamate and {GABA} neurotransmission across cortical regions may contribute to {vsWM} deficits in schizophrenia.{\textless}/p{\textgreater}},
	pages = {670--679},
	number = {8},
	journaltitle = {Biological Psychiatry},
	shortjournal = {Biological Psychiatry},
	author = {Hoftman, Gil D. and Dienel, Samuel J. and Bazmi, Holly H. and Zhang, Yun and Chen, Kehui and Lewis, David A.},
	urldate = {2019-03-04},
	date = {2018-04-15},
	pmid = {29357982}
}

@article{kim_brain-wide_2017,
	title = {Brain-wide Maps Reveal Stereotyped Cell Type-based Cortical Architecture and Subcortical Sexual Dimorphism},
	volume = {171},
	issn = {0092-8674},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5870827/},
	doi = {10.1016/j.cell.2017.09.020},
	abstract = {The stereotyped features of neuronal circuits are those most likely to explain the remarkable capacity of the brain to process information and govern behaviors, yet it has not been possible to comprehensively quantify neuronal distributions across animals or genders due to the size and complexity of the mammalian brain. Here we apply our quantitative brain-wide ({qBrain}) mapping platform to document the stereotyped distributions of mainly inhibitory cell types. We discover an unexpected cortical organizing principle: sensory-motor areas are dominated by output-modulating parvalbumin-positive interneurons, whereas association, including frontal, areas are dominated by input-modulating somatostatin-positive interneurons. Furthermore, we identify local cell type distributions with more cells in the female brain in seven out of eight sexually dimorphic subcortical areas, in contrast to the overall larger brains in males. The {qBrain} resource can be further mined to link stereotyped aspects of neuronal distributions to known and unknown functions of diverse brain regions.},
	pages = {456--469.e22},
	number = {2},
	journaltitle = {Cell},
	shortjournal = {Cell},
	author = {Kim, Yongsoo and Yang, Guangyu Robert and Pradhan, Kith and Venkataraju, Kannan Umadevi and Bota, Mihail and García del Molino, Luis Carlos and Fitzgerald, Greg and Ram, Keerthi and He, Miao and Levine, Jesse Maurica and Mitra, Partha and Huang, Z. Josh and Wang, Xiao-Jing and Osten, Pavel},
	urldate = {2019-03-04},
	date = {2017-10-05},
	pmid = {28985566},
	pmcid = {PMC5870827},
	file = {PubMed Central Full Text PDF:/home/jdehning/Zotero/storage/RMG4HGVH/Kim et al. - 2017 - Brain-wide Maps Reveal Stereotyped Cell Type-based.pdf:application/pdf}
}

@article{burt_hierarchy_2018-1,
	title = {Hierarchy of transcriptomic specialization across human cortex captured by structural neuroimaging topography},
	volume = {21},
	rights = {2018 The Author(s)},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-018-0195-0},
	doi = {10.1038/s41593-018-0195-0},
	abstract = {Burt et al. analyze patterns of gene expression across human cortex and show expression primarily varies along a sensory-association hierarchy captured by noninvasive neuroimaging, suggesting an organizing principle for microcircuit specialization.},
	pages = {1251},
	number = {9},
	journaltitle = {Nature Neuroscience},
	author = {Burt, Joshua B. and Demirtaş, Murat and Eckner, William J. and Navejar, Natasha M. and Ji, Jie Lisa and Martin, William J. and Bernacchia, Alberto and Anticevic, Alan and Murray, John D.},
	urldate = {2019-03-04},
	date = {2018-09},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/8LWBS3KD/Burt et al. - 2018 - Hierarchy of transcriptomic specialization across .pdf:application/pdf}
}

@online{noauthor_hierarchy_nodate,
	title = {Hierarchy of transcriptomic specialization across human cortex captured by structural neuroimaging topography {\textbar} Nature Neuroscience},
	url = {https://www.nature.com/articles/s41593-018-0195-0},
	urldate = {2019-03-04},
	file = {Hierarchy of transcriptomic specialization across human cortex captured by structural neuroimaging topography | Nature Neuroscience:/home/jdehning/Zotero/storage/5CLRQUY4/s41593-018-0195-0.html:text/html}
}

@article{churchland_neural_2012,
	title = {Neural population dynamics during reaching},
	volume = {487},
	rights = {2012 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature11129},
	doi = {10.1038/nature11129},
	abstract = {Most theories of motor cortex have assumed that neural activity represents movement parameters. This view derives from what is known about primary visual cortex, where neural activity represents patterns of light. Yet it is unclear how well the analogy between motor and visual cortex holds. Single-neuron responses in motor cortex are complex, and there is marked disagreement regarding which movement parameters are represented. A better analogy might be with other motor systems, where a common principle is rhythmic neural activity. Here we find that motor cortex responses during reaching contain a brief but strong oscillatory component, something quite unexpected for a non-periodic behaviour. Oscillation amplitude and phase followed naturally from the preparatory state, suggesting a mechanistic role for preparatory neural activity. These results demonstrate an unexpected yet surprisingly simple structure in the population response. This underlying structure explains many of the confusing features of individual neural responses.},
	pages = {51--56},
	number = {7405},
	journaltitle = {Nature},
	author = {Churchland, Mark M. and Cunningham, John P. and Kaufman, Matthew T. and Foster, Justin D. and Nuyujukian, Paul and Ryu, Stephen I. and Shenoy, Krishna V.},
	urldate = {2019-03-02},
	date = {2012-07},
	langid = {english},
	file = {Accepted Version:/home/jdehning/Zotero/storage/39NVUV2Y/Churchland et al. - 2012 - Neural population dynamics during reaching.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/B9QGFESM/nature11129.html:text/html}
}

@article{camalet_auditory_2000,
	title = {Auditory sensitivity provided by self-tuned critical oscillations of hair cells},
	volume = {97},
	rights = {Copyright © 2000, The National Academy of Sciences},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/97/7/3183},
	doi = {10.1073/pnas.97.7.3183},
	abstract = {We introduce the concept of self-tuned criticality as a general mechanism for signal detection in sensory systems. In the case of hearing, we argue that active amplification of faint sounds is provided by a dynamical system that is maintained at the threshold of an oscillatory instability. This concept can account for the exquisite sensitivity of the auditory system and its wide dynamic range as well as its capacity to respond selectively to different frequencies. A specific model of sound detection by the hair cells of the inner ear is discussed. We show that a collection of motor proteins within a hair bundle can generate oscillations at a frequency that depends on the elastic properties of the bundle. Simple variation of bundle geometry gives rise to hair cells with characteristic frequencies that span the range of audibility. Tension-gated transduction channels, which primarily serve to detect the motion of a hair bundle, also tune each cell by admitting ions that regulate the motor protein activity. By controlling the bundle's propensity to oscillate, this feedback automatically maintains the system in the operating regime where it is most sensitive to sinusoidal stimuli. The model explains how hair cells can detect sounds that carry less energy than the background noise.},
	pages = {3183--3188},
	number = {7},
	journaltitle = {Proceedings of the National Academy of Sciences},
	shortjournal = {{PNAS}},
	author = {Camalet, Sébastien and Duke, Thomas and Jülicher, Frank and Prost, Jacques},
	urldate = {2019-02-28},
	date = {2000-03-28},
	langid = {english},
	pmid = {10737791},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/WYD3RTGC/Camalet et al. - 2000 - Auditory sensitivity provided by self-tuned critic.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/BUQFI2KN/3183.html:text/html}
}

@article{shriki_optimal_2016,
	title = {Optimal Information Representation and Criticality in an Adaptive Sensory Recurrent Neuronal Network},
	volume = {12},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004698},
	doi = {10.1371/journal.pcbi.1004698},
	abstract = {Recurrent connections play an important role in cortical function, yet their exact contribution to the network computation remains unknown. The principles guiding the long-term evolution of these connections are poorly understood as well. Therefore, gaining insight into their computational role and into the mechanism shaping their pattern would be of great importance. To that end, we studied the learning dynamics and emergent recurrent connectivity in a sensory network model based on a first-principle information theoretic approach. As a test case, we applied this framework to a model of a hypercolumn in the visual cortex and found that the evolved connections between orientation columns have a "Mexican hat" profile, consistent with empirical data and previous modeling work. Furthermore, we found that optimal information representation is achieved when the network operates near a critical point in its dynamics. Neuronal networks working near such a phase transition are most sensitive to their inputs and are thus optimal in terms of information representation. Nevertheless, a mild change in the pattern of interactions may cause such networks to undergo a transition into a different regime of behavior in which the network activity is dominated by its internal recurrent dynamics and does not reflect the objective input. We discuss several mechanisms by which the pattern of interactions can be driven into this supercritical regime and relate them to various neurological and neuropsychiatric phenomena.},
	pages = {e1004698},
	number = {2},
	journaltitle = {{PLOS} Computational Biology},
	shortjournal = {{PLOS} Computational Biology},
	author = {Shriki, Oren and Yellin, Dovi},
	urldate = {2019-02-28},
	date = {2016-02-16},
	langid = {english},
	keywords = {Neural networks, Neurons, Network analysis, Hallucinations, Learning, Neuronal tuning, Vision, Visual cortex},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/8Q9T79XY/Shriki and Yellin - 2016 - Optimal Information Representation and Criticality.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/IC6MEKSU/article.html:text/html}
}

@article{churchland_stimulus_2010,
	title = {Stimulus onset quenches neural variability: a widespread cortical phenomenon},
	volume = {13},
	rights = {2010 Nature Publishing Group},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.2501},
	doi = {10.1038/nn.2501},
	shorttitle = {Stimulus onset quenches neural variability},
	abstract = {Neural responses are typically characterized by computing the mean firing rate, but response variability can exist across trials. Many studies have examined the effect of a stimulus on the mean response, but few have examined the effect on response variability. We measured neural variability in 13 extracellularly recorded datasets and one intracellularly recorded dataset from seven areas spanning the four cortical lobes in monkeys and cats. In every case, stimulus onset caused a decline in neural variability. This occurred even when the stimulus produced little change in mean firing rate. The variability decline was observed in membrane potential recordings, in the spiking of individual neurons and in correlated spiking variability measured with implanted 96-electrode arrays. The variability decline was observed for all stimuli tested, regardless of whether the animal was awake, behaving or anaesthetized. This widespread variability decline suggests a rather general property of cortex, that its state is stabilized by an input.},
	pages = {369--378},
	number = {3},
	journaltitle = {Nature Neuroscience},
	author = {Churchland, Mark M. and Yu, Byron M. and Cunningham, John P. and Sugrue, Leo P. and Cohen, Marlene R. and Corrado, Greg S. and Newsome, William T. and Clark, Andrew M. and Hosseini, Paymon and Scott, Benjamin B. and Bradley, David C. and Smith, Matthew A. and Kohn, Adam and Movshon, J. Anthony and Armstrong, Katherine M. and Moore, Tirin and Chang, Steve W. and Snyder, Lawrence H. and Lisberger, Stephen G. and Priebe, Nicholas J. and Finn, Ian M. and Ferster, David and Ryu, Stephen I. and Santhanam, Gopal and Sahani, Maneesh and Shenoy, Krishna V.},
	urldate = {2019-02-27},
	date = {2010-03},
	langid = {english},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/M76NKDGR/Churchland et al. - 2010 - Stimulus onset quenches neural variability a wide.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/WE94PMW9/nn.html:text/html}
}

@article{gollo_leonardo_l._coexistence_2017-1,
	title = {Coexistence of critical sensitivity and subcritical specificity can yield optimal population coding},
	volume = {14},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rsif.2017.0207},
	doi = {10.1098/rsif.2017.0207},
	abstract = {The vicinity of phase transitions selectively amplifies weak stimuli, yielding optimal sensitivity to distinguish external input. Along with this enhanced sensitivity, enhanced levels of fluctuations at criticality reduce the specificity of the response. Given that the specificity of the response is largely compromised when the sensitivity is maximal, the overall benefit of criticality for signal processing remains questionable. Here, it is shown that this impasse can be solved by heterogeneous systems incorporating functional diversity, in which critical and subcritical components coexist. The subnetwork of critical elements has optimal sensitivity, and the subnetwork of subcritical elements has enhanced specificity. Combining segregated features extracted from the different subgroups, the resulting collective response can maximize the trade-off between sensitivity and specificity measured by the dynamic-range-to-noise ratio. Although numerous benefits can be observed when the entire system is critical, our results highlight that optimal performance is obtained when only a small subset of the system is at criticality.},
	pages = {20170207},
	number = {134},
	journaltitle = {Journal of The Royal Society Interface},
	shortjournal = {Journal of The Royal Society Interface},
	author = {{Gollo Leonardo L.}},
	urldate = {2019-02-27},
	date = {2017-09-30},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/3BGNJZPU/Gollo Leonardo L. - 2017 - Coexistence of critical sensitivity and subcritica.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/W9CSYYHA/rsif.2017.html:text/html}
}

@online{noauthor_coexistence_nodate,
	title = {Coexistence of critical sensitivity and subcritical specificity can yield optimal population coding {\textbar} Journal of The Royal Society Interface},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rsif.2017.0207},
	urldate = {2019-02-27},
	file = {Coexistence of critical sensitivity and subcritical specificity can yield optimal population coding | Journal of The Royal Society Interface:/home/jdehning/Zotero/storage/Z3J8QR8I/rsif.2017.html:text/html}
}

@online{noauthor_optimal_nodate,
	title = {Optimal Information Representation and Criticality in an Adaptive Sensory Recurrent Neuronal Network},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004698},
	urldate = {2019-02-27},
	file = {Optimal Information Representation and Criticality in an Adaptive Sensory Recurrent Neuronal Network:/home/jdehning/Zotero/storage/663523FY/article.html:text/html}
}

@online{noauthor_optimal_nodate-1,
	title = {Optimal dynamical range of excitable networks at criticality {\textbar} Nature Physics},
	url = {https://www.nature.com/articles/nphys289},
	urldate = {2019-02-27},
	file = {Optimal dynamical range of excitable networks at criticality | Nature Physics:/home/jdehning/Zotero/storage/UP6YJXT8/nphys289.html:text/html}
}

@article{munoz_colloquium:_2018,
	title = {Colloquium: Criticality and dynamical scaling in living systems},
	volume = {90},
	url = {https://link.aps.org/doi/10.1103/RevModPhys.90.031001},
	doi = {10.1103/RevModPhys.90.031001},
	shorttitle = {Colloquium},
	abstract = {A celebrated and controversial hypothesis suggests that some biological systems—parts, aspects, or groups of them—may extract important functional benefits from operating at the edge of instability, halfway between order and disorder, i.e., in the vicinity of the critical point of a phase transition. Criticality has been argued to provide biological systems with an optimal balance between robustness against perturbations and flexibility to adapt to changing conditions as well as to confer on them optimal computational capabilities, large dynamical repertoires, unparalleled sensitivity to stimuli, etc. Criticality, with its concomitant scale invariance, can be conjectured to emerge in living systems as the result of adaptive and evolutionary processes that, for reasons to be fully elucidated, select for it as a template upon which further layers of complexity can rest. This hypothesis is suggestive as it proposes that criticality could constitute a general and common organizing strategy in biology stemming from the physics of phase transitions. However, despite its implications, this is still in its infancy state as a well-founded theory and, as such, it has elicited some skepticism. From the experimental side, the advent of high-throughput technologies has created new prospects in the exploration of biological systems, and empirical evidence in favor of criticality has proliferated, with examples ranging from endogenous brain activity and gene-expression patterns to flocks of birds and insect-colony foraging, to name but a few. Some pieces of evidence are quite remarkable, while in some other cases empirical data are limited, incomplete, or not fully convincing. More stringent experimental setups and theoretical analyses are certainly needed to fully clarify the picture. In any case, the time seems ripe for bridging the gap between this theoretical conjecture and its empirical validation. Given the profound implications of shedding light on this issue, it is both pertinent and timely to review the state of the art and to discuss future strategies and perspectives.},
	pages = {031001},
	number = {3},
	journaltitle = {Reviews of Modern Physics},
	shortjournal = {Rev. Mod. Phys.},
	author = {Muñoz, Miguel A.},
	urldate = {2019-02-27},
	date = {2018-07-10},
	file = {APS Snapshot:/home/jdehning/Zotero/storage/4SZBTAQA/RevModPhys.90.html:text/html;Full Text PDF:/home/jdehning/Zotero/storage/9X78UN53/Muñoz - 2018 - Colloquium Criticality and dynamical scaling in l.pdf:application/pdf}
}

@article{schaffelhofer_object_2016,
	title = {Object vision to hand action in macaque parietal, premotor, and motor cortices},
	volume = {5},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.15278},
	doi = {10.7554/eLife.15278},
	abstract = {Grasping requires translating object geometries into appropriate hand shapes. How the brain computes these transformations is currently unclear. We investigated three key areas of the macaque cortical grasping circuit with microelectrode arrays and found cooperative but anatomically separated visual and motor processes. The parietal area {AIP} operated primarily in a visual mode. Its neuronal population revealed a specialization for shape processing, even for abstract geometries, and processed object features ultimately important for grasping. Premotor area F5 acted as a hub that shared the visual coding of {AIP} only temporarily and switched to highly dominant motor signals towards movement planning and execution. We visualize these non-discrete premotor signals that drive the primary motor cortex M1 to reflect the movement of the grasping hand. Our results reveal visual and motor features encoded in the grasping circuit and their communication to achieve transformation for grasping.},
	pages = {e15278},
	journaltitle = {{eLife}},
	author = {Schaffelhofer, Stefan and Scherberger, Hansjörg},
	editor = {Kastner, Sabine},
	urldate = {2019-02-27},
	date = {2016-07-26},
	keywords = {hand grasping, motor cortex, parallel recording, parietal cortex, premotor cortex, sensorimotor transformation},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/NPREHXYU/Schaffelhofer and Scherberger - 2016 - Object vision to hand action in macaque parietal, .pdf:application/pdf}
}

@article{michaels_predicting_2015,
	title = {Predicting Reaction Time from the Neural State Space of the Premotor and Parietal Grasping Network},
	volume = {35},
	issn = {1529-2401},
	doi = {10.1523/JNEUROSCI.1714-15.2015},
	abstract = {Neural networks of the brain involved in the planning and execution of grasping movements are not fully understood. The network formed by macaque anterior intraparietal area ({AIP}) and hand area (F5) of the ventral premotor cortex is implicated strongly in the generation of grasping movements. However, the differential role of each area in this frontoparietal network is unclear. We recorded spiking activity from many electrodes in parallel in {AIP} and F5 while three macaque monkeys (Macaca mulatta) performed a delayed grasping task. By analyzing neural population activity during action preparation, we found that state space analysis of simultaneously recorded units is significantly more predictive of subsequent reaction times ({RTs}) than traditional methods. Furthermore, because we observed a wide variety of individual unit characteristics, we developed the sign-corrected average rate ({SCAR}) method of neural population averaging. The {SCAR} method was able to explain at least as much variance in {RT} overall as state space methods. Overall, F5 activity predicted {RT} (18\% variance explained) significantly better than {AIP} (6\%). The {SCAR} methods provides a straightforward interpretation of population activity, although other state space methods could provide richer descriptions of population dynamics. Together, these results lend support to the differential role of the parietal and frontal cortices in preparation for grasping, suggesting that variability in preparatory activity in F5 has a more potent effect on trial-to-trial {RT} variability than {AIP}.
{SIGNIFICANCE} {STATEMENT}: Grasping movements are planned before they are executed, but how is the preparatory activity in a population of neurons related to the subsequent reaction time ({RT})? A population analysis of the activity of many neurons recorded in parallel in macaque premotor (F5) and parietal ({AIP}) cortices during a delayed grasping task revealed that preparatory activity in F5 could explain a threefold larger fraction of variability in trial-to-trial {RT} than {AIP}. These striking differences lend additional support to a differential role of the parietal and premotor cortices in grasp movement preparation, suggesting that F5 has a more direct influence on trial-to-trial variability and movement timing, whereas {AIP} might be more closely linked to overall movement intentions.},
	pages = {11415--11432},
	number = {32},
	journaltitle = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Michaels, Jonathan A. and Dann, Benjamin and Intveld, Rijk W. and Scherberger, Hansjörg},
	date = {2015-08-12},
	pmid = {26269647},
	keywords = {Animals, Brain Mapping, Macaca mulatta, Neurons, Action Potentials, Eye Movements, Female, grasping, Hand Strength, Male, Motor Cortex, Movement, nonhuman primate, parietal, Parietal Lobe, premotor, Psychomotor Performance, Reaction Time, single unit recording},
	file = {Full Text:/home/jdehning/Zotero/storage/S27JT62D/Michaels et al. - 2015 - Predicting Reaction Time from the Neural State Spa.pdf:application/pdf}
}

@article{dann_uniting_2016,
	title = {Uniting functional network topology and oscillations in the fronto-parietal single unit network of behaving primates},
	volume = {5},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.15719},
	doi = {10.7554/eLife.15719},
	abstract = {The functional communication of neurons in cortical networks underlies higher cognitive processes. Yet, little is known about the organization of the single neuron network or its relationship to the synchronization processes that are essential for its formation. Here, we show that the functional single neuron network of three fronto-parietal areas during active behavior of macaque monkeys is highly complex. The network was closely connected (small-world) and consisted of functional modules spanning these areas. Surprisingly, the importance of different neurons to the network was highly heterogeneous with a small number of neurons contributing strongly to the network function (hubs), which were in turn strongly inter-connected (rich-club). Examination of the network synchronization revealed that the identified rich-club consisted of neurons that were synchronized in the beta or low frequency range, whereas other neurons were mostly non-oscillatory synchronized. Therefore, oscillatory synchrony may be a central communication mechanism for highly organized functional spiking networks.},
	pages = {e15719},
	journaltitle = {{eLife}},
	author = {Dann, Benjamin and Michaels, Jonathan A and Schaffelhofer, Stefan and Scherberger, Hansjörg},
	editor = {Stephan, Klaas Enno},
	urldate = {2019-02-27},
	date = {2016-08-15},
	keywords = {inter-areal communication, network topology, neural circuits, oscillatory synchrony, sensorimotor processing, single neuron functional connectivity},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/8EYLHGUG/Dann et al. - 2016 - Uniting functional network topology and oscillatio.pdf:application/pdf}
}

@article{beggs_neuronal_2003,
	title = {Neuronal avalanches in neocortical circuits},
	volume = {23},
	issn = {1529-2401},
	abstract = {Networks of living neurons exhibit diverse patterns of activity, including oscillations, synchrony, and waves. Recent work in physics has shown yet another mode of activity in systems composed of many nonlinear units interacting locally. For example, avalanches, earthquakes, and forest fires all propagate in systems organized into a critical state in which event sizes show no characteristic scale and are described by power laws. We hypothesized that a similar mode of activity with complex emergent properties could exist in networks of cortical neurons. We investigated this issue in mature organotypic cultures and acute slices of rat cortex by recording spontaneous local field potentials continuously using a 60 channel multielectrode array. Here, we show that propagation of spontaneous activity in cortical networks is described by equations that govern avalanches. As predicted by theory for a critical branching process, the propagation obeys a power law with an exponent of -3/2 for event sizes, with a branching parameter close to the critical value of 1. Simulations show that a branching parameter at this value optimizes information transmission in feedforward networks, while preventing runaway network excitation. Our findings suggest that "neuronal avalanches" may be a generic property of cortical networks, and represent a mode of activity that differs profoundly from oscillatory, synchronized, or wave-like network states. In the critical state, the network may satisfy the competing demands of information transmission and network stability.},
	pages = {11167--11177},
	number = {35},
	journaltitle = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Beggs, John M. and Plenz, Dietmar},
	date = {2003-12-03},
	pmid = {14657176},
	keywords = {Animals, Neurons, Neural Networks (Computer), Computer Simulation, Models, Neurological, Electrodes, In Vitro Techniques, Neocortex, Nerve Net, Rats, Synaptic Transmission}
}

@article{wilting_operating_2018,
	title = {Operating in a Reverberating Regime Enables Rapid Tuning of Network States to Task Requirements},
	volume = {12},
	issn = {1662-5137},
	url = {https://www.frontiersin.org/articles/10.3389/fnsys.2018.00055/full},
	doi = {10.3389/fnsys.2018.00055},
	abstract = {Neural circuits are able to perform computations under very diverse conditions and requirements. The required computations impose clear constraints on their fine-tuning: a rapid and maximally informative response to stimuli in general requires decorrelated baseline neural activity. Such network dynamics is known as asynchronous-irregular. In contrast, spatio-temporal integration of information requires maintenance and transfer of stimulus information over extended time periods. This can be realized at criticality, a phase transition where correlations, sensitivity and integration time diverge. Being able to flexibly switch, or even combine the above properties in a task-dependent manner would present a clear functional advantage. We propose that cortex operates in a reverberating regime because it is particularly favorable for ready adaptation of computational properties to context and task. This reverberating regime enables cortical networks to interpolate between the asynchronous-irregular and the critical state by small changes in effective synaptic strength or excitation-inhibition ratio. These changes directly adapt computational properties, including sensitivity, amplification, integration time and correlation length within the local network. We review recent converging evidence that cortex in vivo operates in the reverberating regime, and that various cortical areas have adapted their integration times to processing requirements. In addition, we propose that neuromodulation enables a fine-tuning of the network, so that local circuits can either decorrelate or integrate, and quench or maintain their input depending on task. We argue that this task-dependent tuning, which we call dynamic adaptive computation, presents a central organization principle of cortical networks and discuss first experimental evidence.},
	journaltitle = {Frontiers in Systems Neuroscience},
	shortjournal = {Front. Syst. Neurosci.},
	author = {Wilting, Jens and Dehning, Jonas and Pinheiro Neto, Joao and Rudelt, Lucas and Wibral, Michael and Zierenberg, Johannes and Priesemann, Viola},
	urldate = {2019-02-26},
	date = {2018},
	keywords = {Criticality, balanced state, Cognitive states, Dynamical state, hierarchy, network function, Neural Network, Neuromodulation},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/AXQI8IIN/Wilting et al. - 2018 - Operating in a Reverberating Regime Enables Rapid .pdf:application/pdf}
}

@article{wibral_bits_2015,
	title = {Bits from brains for biologically inspired computing},
	volume = {2},
	url = {http://journal.frontiersin.org/article/10.3389/frobt.2015.00005/full},
	doi = {10.3389/frobt.2015.00005},
	abstract = {Inspiration for artificial biologically inspired computing is often drawn from neural systems. This article shows how to analyze neural systems using information theory with the aim of obtaining constraints that help to identify the algorithms run by neural systems and the information they represent. Algorithms and representations identified this way may then guide the design of biologically inspired computing systems. The material covered includes the necessary introduction to information theory and to the estimation of information-theoretic quantities from neural recordings. We then show how to analyze the information encoded in a system about its environment, and also discuss recent methodological developments on the question of how much information each agent carries about the environment either uniquely or redundantly or synergistically together with others. Last, we introduce the framework of local information dynamics, where information processing is partitioned into component processes of information storage, transfer, and modification – locally in space and time. We close by discussing example applications of these measures to neural data and other complex systems.},
	pages = {5},
	journaltitle = {Frontiers in Robotics and {AI}},
	shortjournal = {Front. Robot. {AI}},
	author = {Wibral, Michael and Lizier, Joseph T. and Priesemann, Viola},
	urldate = {2016-07-08},
	date = {2015},
	keywords = {artificial neural networks, biologically inspired computing, computational intelligence, information theory, local information dynamics, neural systems, partial information decomposition},
	file = {Wibral-Lizier-Priesemann-2015-InformationTheoryReview.pdf:/home/jdehning/Zotero/storage/JPMHBFZS/Wibral-Lizier-Priesemann-2015-InformationTheoryReview.pdf:application/pdf}
}

@article{priesemann_spike_2014,
	title = {Spike avalanches in vivo suggest a driven, slightly subcritical brain state},
	volume = {8},
	issn = {1662-5137},
	url = {https://www.frontiersin.org/articles/10.3389/fnsys.2014.00108/full},
	doi = {10.3389/fnsys.2014.00108},
	abstract = {In self-organized critical ({SOC}) systems avalanche size distributions follow power-laws. Power-laws have also been observed for neural activity, and so it has been proposed that {SOC} underlies brain organization as well. Surprisingly, for spiking activity in vivo, evidence for {SOC} is still lacking. Therefore we analyzed highly parallel spike recordings from awake rats and monkeys, anaesthetized cats, and also local field potentials from humans. We compared these to spiking activity from two established critical models: the Bak-Tang-Wiesenfeld model, and a stochastic branching model. We found fundamental differences between the neural and the model activity. These differences could be overcome for both models through a combination of three modifications: (1) subsampling, (2) increasing the input to the model (this way eliminating the separation of time scales, which is fundamental to {SOC} and its avalanche definition), and (3) making the model slightly sub-critical. The match between the neural activity and the modified models held not only for the classical avalanche size distributions and estimated branching parameters, but also for two novel measures (mean avalanche size, and frequency of single spikes), and for the dependence of all these measures on the temporal bin size. Our results suggest that neural activity in vivo shows a mélange of avalanches, and not temporally separated ones, and that their global activity propagation can be approximated by the principle that one spike on average triggers a little less than one spike in the next step. This implies that neural activity does not reflect a {SOC} state but a slightly sub-critical regime without a separation of time scales. Potential advantages of this regime may be faster information processing, and a safety margin from super-criticality, which has been linked to epilepsy.},
	journaltitle = {Frontiers in Systems Neuroscience},
	shortjournal = {Front. Syst. Neurosci.},
	author = {Priesemann, Viola and Wibral, Michael and Valderrama, Mario and Pröpper, Robert and Le Van Quyen, Michel and Geisel, Theo and Triesch, Jochen and Nikolić, Danko and Munk, Matthias H. J.},
	urldate = {2019-02-22},
	date = {2014},
	keywords = {Humans, Rats, Cats, highly parallel recordings, human intracranial recordings, intracranial recordings, local field potential, monkeys, multiunit activity, neuronal avalanches, Phase Transition, Population Dynamics, self-organized criticality, separation of time scales, spike train analysis, spiking neural networks, stability analysis, subcritical},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/TXFENJHT/Priesemann et al. - 2014 - Spike avalanches in vivo suggest a driven, slightl.pdf:application/pdf}
}

@article{wasmuht_intrinsic_2018,
	title = {Intrinsic neuronal dynamics predict distinct functional roles during working memory},
	volume = {9},
	rights = {2018 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-018-05961-4},
	doi = {10.1038/s41467-018-05961-4},
	abstract = {Prefrontal neurons exhibit both transient and persistent firing in working memory tasks. Here the authors report that the intrinsic timescale of neuronal firing outside the task is predictive of the temporal dynamics of coding during working memory in three frontoparietal brain areas.},
	pages = {3499},
	number = {1},
	journaltitle = {Nature Communications},
	author = {Wasmuht, D. F. and Spaak, E. and Buschman, T. J. and Miller, E. K. and Stokes, M. G.},
	urldate = {2019-02-22},
	date = {2018-08-29},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/NCD88YFC/Wasmuht et al. - 2018 - Intrinsic neuronal dynamics predict distinct funct.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/3RD5MKSX/s41467-018-05961-4.html:text/html}
}

@article{cavanagh_reconciling_2018,
	title = {Reconciling persistent and dynamic hypotheses of working memory coding in prefrontal cortex},
	volume = {9},
	rights = {2018 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-018-05873-3},
	doi = {10.1038/s41467-018-05873-3},
	abstract = {Working memory ({WM}) is represented in persistent activity of single neurons as well as a dynamic population code. Here, the authors find that neurons flexibly switch their coding according to current attention while those with stable resting activity maintain {WM} representations through dynamic activity patterns.},
	pages = {3498},
	number = {1},
	journaltitle = {Nature Communications},
	author = {Cavanagh, Sean E. and Towers, John P. and Wallis, Joni D. and Hunt, Laurence T. and Kennerley, Steven W.},
	urldate = {2019-02-22},
	date = {2018-08-29},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/CAYQ8Z7X/Cavanagh et al. - 2018 - Reconciling persistent and dynamic hypotheses of w.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/VYVYH2FL/s41467-018-05873-3.html:text/html}
}

@article{wolpert_internal_1995,
	title = {An internal model for sensorimotor integration},
	volume = {269},
	rights = {© 1995},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/269/5232/1880},
	doi = {10.1126/science.7569931},
	abstract = {On the basis of computational studies it has been proposed that the central nervous system internally simulates the dynamic behavior of the motor system in planning, control, and learning; the existence and use of such an internal model is still under debate. A sensorimotor integration task was investigated in which participants estimated the location of one of their hands at the end of movements made in the dark and under externally imposed forces. The temporal propagation of errors in this task was analyzed within the theoretical framework of optimal state estimation. These results provide direct support for the existence of an internal model.},
	pages = {1880--1882},
	number = {5232},
	journaltitle = {Science},
	author = {Wolpert, D. M. and Ghahramani, Z. and Jordan, M. I.},
	urldate = {2019-02-13},
	date = {1995-09-29},
	langid = {english},
	pmid = {7569931},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/UIESPQRM/Wolpert et al. - 1995 - An internal model for sensorimotor integration.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/3NPF2VYM/tab-pdf.html:text/html}
}

@article{larremore_predicting_2011,
	title = {Predicting Criticality and Dynamic Range in Complex Networks: Effects of Topology},
	volume = {106},
	issn = {0031-9007, 1079-7114},
	url = {https://link.aps.org/doi/10.1103/PhysRevLett.106.058101},
	doi = {10.1103/PhysRevLett.106.058101},
	shorttitle = {Predicting Criticality and Dynamic Range in Complex Networks},
	number = {5},
	journaltitle = {Physical Review Letters},
	author = {Larremore, Daniel B. and Shew, Woodrow L. and Restrepo, Juan G.},
	urldate = {2019-02-11},
	date = {2011-01-31},
	langid = {english},
	file = {Larremore et al. - 2011 - Predicting Criticality and Dynamic Range in Comple.pdf:/home/jdehning/Zotero/storage/D5ILEUF7/Larremore et al. - 2011 - Predicting Criticality and Dynamic Range in Comple.pdf:application/pdf}
}

@article{huang_once_2017,
	title = {Once upon a (slow) time in the land of recurrent neuronal networks…},
	volume = {46},
	issn = {0959-4388},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438817300193},
	doi = {10.1016/j.conb.2017.07.003},
	series = {Computational Neuroscience},
	abstract = {The brain must both react quickly to new inputs as well as store a memory of past activity. This requires biology that operates over a vast range of time scales. Fast time scales are determined by the kinetics of synaptic conductances and ionic channels; however, the mechanics of slow time scales are more complicated. In this opinion article we review two distinct network-based mechanisms that impart slow time scales in recurrently coupled neuronal networks. The first is in strongly coupled networks where the time scale of the internally generated fluctuations diverges at the transition between stable and chaotic firing rate activity. The second is in networks with finitely many members where noise-induced transitions between metastable states appear as a slow time scale in the ongoing network firing activity. We discuss these mechanisms with an emphasis on their similarities and differences.},
	pages = {31--38},
	journaltitle = {Current Opinion in Neurobiology},
	shortjournal = {Current Opinion in Neurobiology},
	author = {Huang, Chengcheng and Doiron, Brent},
	urldate = {2019-02-02},
	date = {2017-10-01},
	file = {ScienceDirect Full Text PDF:/home/jdehning/Zotero/storage/UZHH2N7L/Huang and Doiron - 2017 - Once upon a (slow) time in the land of recurrent n.pdf:application/pdf;ScienceDirect Snapshot:/home/jdehning/Zotero/storage/LTFF7X2S/S0959438817300193.html:text/html}
}

@article{beiran_contrasting_2018,
	title = {Contrasting the effects of adaptation and synaptic filtering on the timescales of dynamics in recurrent networks},
	url = {http://arxiv.org/abs/1812.06919},
	abstract = {Neural activity exhibits a vast range of timescales that can be several fold larger than the membrane time constant of individual neurons. Two types of mechanisms have been proposed to explain this conundrum. One possibility is that large timescales are generated by a network mechanism based on positive feedback, but this hypothesis requires fine-tuning of the synaptic connections. A second possibility is that large timescales in the neural dynamics are inherited from large timescales of underlying biophysical processes, two prominent candidates being adaptive ionic currents and synaptic transmission. How the timescales of these processes influence the timescale of the network dynamics has however not been fully explored. To address this question, we analyze large networks of randomly connected excitatory and inhibitory units with additional degrees of freedom that correspond to adaptation or synaptic filtering. We determine the fixed points of the systems, their stability to perturbations and the corresponding dynamical timescales. Furthermore, we apply dynamical mean field theory to study the temporal statistics of the activity in the fluctuating regime, and examine how the adaptation and synaptic timescales transfer from individual units to the whole population. Our overarching finding is that synaptic filtering and adaptation in single neurons have very different effects at the network level. Unexpectedly, the macroscopic network dynamics do not inherit the large timescale present in adaptive currents. In contrast, the timescales of network activity increase proportionally to the time constant of the synaptic filter. Altogether, our study demonstrates that the timescales of different biophysical processes have different effects on the network level, so that the slow processes within individual neurons do not necessarily induce slow activity in large recurrent neural networks.},
	journaltitle = {{arXiv}:1812.06919 [q-bio]},
	author = {Beiran, Manuel and Ostojic, Srdjan},
	urldate = {2019-02-02},
	date = {2018-12-17},
	eprinttype = {arxiv},
	eprint = {1812.06919},
	keywords = {Quantitative Biology - Neurons and Cognition},
	file = {arXiv\:1812.06919 PDF:/home/jdehning/Zotero/storage/EXJ4P2Y2/Beiran and Ostojic - 2018 - Contrasting the effects of adaptation and synaptic.pdf:application/pdf;arXiv.org Snapshot:/home/jdehning/Zotero/storage/722KUBSF/1812.html:text/html}
}

@article{genest_christian_everything_2007,
	title = {Everything You Always Wanted to Know about Copula Modeling but Were Afraid to Ask},
	volume = {12},
	url = {https://ascelibrary.org/doi/abs/10.1061/(ASCE)1084-0699(2007)12:4(347)},
	doi = {10.1061/(ASCE)1084-0699(2007)12:4(347)},
	pages = {347--368},
	number = {4},
	journaltitle = {Journal of Hydrologic Engineering},
	shortjournal = {Journal of Hydrologic Engineering},
	author = {{Genest Christian} and {Favre Anne-Catherine}},
	urldate = {2019-01-28},
	date = {2007-07-01},
	file = {Snapshot:/home/jdehning/Zotero/storage/X3MWKXZB/(ASCE)1084-0699(2007)124(347).html:text/html;Submitted Version:/home/jdehning/Zotero/storage/H2ZGQHHT/Genest Christian and Favre Anne-Catherine - 2007 - Everything You Always Wanted to Know about Copula .pdf:application/pdf}
}

@article{murray_stable_2017,
	title = {Stable population coding for working memory coexists with heterogeneous neural dynamics in prefrontal cortex},
	volume = {114},
	issn = {1091-6490},
	doi = {10.1073/pnas.1619449114},
	abstract = {Working memory ({WM}) is a cognitive function for temporary maintenance and manipulation of information, which requires conversion of stimulus-driven signals into internal representations that are maintained across seconds-long mnemonic delays. Within primate prefrontal cortex ({PFC}), a critical node of the brain's {WM} network, neurons show stimulus-selective persistent activity during {WM}, but many of them exhibit strong temporal dynamics and heterogeneity, raising the questions of whether, and how, neuronal populations in {PFC} maintain stable mnemonic representations of stimuli during {WM}. Here we show that despite complex and heterogeneous temporal dynamics in single-neuron activity, {PFC} activity is endowed with a population-level coding of the mnemonic stimulus that is stable and robust throughout {WM} maintenance. We applied population-level analyses to hundreds of recorded single neurons from lateral {PFC} of monkeys performing two seminal tasks that demand parametric {WM}: oculomotor delayed response and vibrotactile delayed discrimination. We found that the high-dimensional state space of {PFC} population activity contains a low-dimensional subspace in which stimulus representations are stable across time during the cue and delay epochs, enabling robust and generalizable decoding compared with time-optimized subspaces. To explore potential mechanisms, we applied these same population-level analyses to theoretical neural circuit models of {WM} activity. Three previously proposed models failed to capture the key population-level features observed empirically. We propose network connectivity properties, implemented in a linear network model, which can underlie these features. This work uncovers stable population-level {WM} representations in {PFC}, despite strong temporal neural dynamics, thereby providing insights into neural circuit mechanisms supporting {WM}.},
	pages = {394--399},
	number = {2},
	journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
	shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
	author = {Murray, John D. and Bernacchia, Alberto and Roy, Nicholas A. and Constantinidis, Christos and Romo, Ranulfo and Wang, Xiao-Jing},
	date = {2017},
	pmid = {28028221},
	pmcid = {PMC5240715},
	keywords = {Animals, Macaca mulatta, Neurons, Models, Neurological, Population Dynamics, Cognition, Memory, Short-Term, population coding, prefrontal cortex, Prefrontal Cortex, working memory}
}

@online{noauthor_gwdg_nodate,
	title = {{GWDG} {ownCloud} - {GWDG} - {IT} in der Wissenschaft},
	url = {https://www.gwdg.de/storage-services/gwdg-owncloud},
	urldate = {2018-11-08},
	file = {GWDG ownCloud - GWDG - IT in der Wissenschaft:/home/jdehning/Zotero/storage/4VR6YJNU/gwdg-owncloud.html:text/html}
}

@online{noauthor_gwdg_nodate-1,
	title = {{GWDG} {ownCloud} - {GWDG} - {IT} in der Wissenschaft},
	url = {https://www.gwdg.de/storage-services/gwdg-owncloud},
	urldate = {2018-11-08},
	file = {GWDG ownCloud - GWDG - IT in der Wissenschaft:/home/jdehning/Zotero/storage/MQ9KE6JF/gwdg-owncloud.html:text/html}
}

@article{wilting_inferring_2018,
	title = {Inferring collective dynamical states from widely unobserved systems},
	volume = {9},
	rights = {2018 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-018-04725-4},
	doi = {10.1038/s41467-018-04725-4},
	abstract = {From infectious diseases to brain activity, complex systems can be approximated using autoregressive models. Here, the authors show that incomplete sampling can bias estimates of the stability of such systems, and introduce a novel, unbiased metric for use in such situations.},
	pages = {2325},
	number = {1},
	journaltitle = {Nature Communications},
	author = {Wilting, Jens and Priesemann, Viola},
	urldate = {2018-11-05},
	date = {2018-06-13},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/2YYJIDPS/Wilting and Priesemann - 2018 - Inferring collective dynamical states from widely .pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/KKL7MT2J/s41467-018-04725-4.html:text/html}
}

@article{badre_is_2009,
	title = {Is the rostro-caudal axis of the frontal lobe hierarchical?},
	volume = {10},
	issn = {1471-0048},
	doi = {10.1038/nrn2667},
	abstract = {The frontal lobes in the brain are a component of the cerebral system that supports goal-directed behaviour. However, their functional organization remains controversial. Recent studies have reported rostro-caudal distinctions in frontal cortex activity based on the abstractness of action representations. In addition, some have proposed that these differences reflect a hierarchical organization, whereby anterior frontal regions influence processing by posterior frontal regions during the realization of abstract action goals as motor acts. However, few have considered whether the anatomy and physiology of the frontal lobes support such a scheme. To address this gap, this Review surveys anatomical, neuroimaging, electrophysiological and developmental findings, and considers the question: could the organization of the frontal cortex be hierarchical?},
	pages = {659--669},
	number = {9},
	journaltitle = {Nature Reviews. Neuroscience},
	shortjournal = {Nat. Rev. Neurosci.},
	author = {Badre, David and D'Esposito, Mark},
	date = {2009-09},
	pmid = {19672274},
	pmcid = {PMC3258028},
	keywords = {Animals, Humans, Psychomotor Performance, Nerve Net, Frontal Lobe, Functional Laterality, Goals}
}

@article{simola_critical_2017,
	title = {Critical dynamics of endogenous fluctuations predict cognitive flexibility in the Go/{NoGo} task},
	volume = {7},
	rights = {2017 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-017-02750-9},
	doi = {10.1038/s41598-017-02750-9},
	abstract = {Fluctuations with power-law scaling and long-range temporal correlations ({LRTCs}) are characteristic to human psychophysical performance. Systems operating in a critical state exhibit such {LRTCs}, but phenomenologically similar fluctuations and {LRTCs} may also be caused by slow decay of the system’s memory without the system being critical. Theoretically, criticality endows the system with the greatest representational capacity and flexibility in state transitions. Without criticality, however, slowly decaying system memory would predict inflexibility. We addressed these contrasting predictions of the ‘criticality’ and ‘long-memory’ candidate mechanisms of human behavioral {LRTCs} by using a Go/{NoGo} task wherein the commission errors constitute a measure of cognitive flexibility. Response time ({RT}) fluctuations in this task exhibited power-law frequency scaling, autocorrelations, and {LRTCs}. We show here that the {LRTC} scaling exponents, quantifying the strength of long-range correlations, were negatively correlated with the commission error rates. Strong {LRTCs} hence parallel optimal cognitive flexibility and, in line with the criticality hypothesis, indicate a functionally advantageous state. This conclusion was corroborated by a positive correlation between the {LRTC} scaling exponents and executive functions measured with the Rey-Osterrieth Complex Figure test. Our results hence support the notion that {LRTCs} arise from critical dynamics that is functionally significant for human cognitive performance.},
	pages = {2909},
	number = {1},
	journaltitle = {Scientific Reports},
	author = {Simola, Jaana and Zhigalov, Alexander and Morales-Muñoz, Isabel and Palva, J. Matias and Palva, Satu},
	urldate = {2018-10-18},
	date = {2017-06-06},
	langid = {english},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/9RELXIIE/Simola et al. - 2017 - Critical dynamics of endogenous fluctuations predi.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/UDJ67KEL/s41598-017-02750-9.html:text/html}
}

@article{dotson_feature-based_2018,
	title = {Feature-Based Visual Short-Term Memory Is Widely Distributed and Hierarchically Organized},
	volume = {99},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(18)30424-0},
	doi = {10.1016/j.neuron.2018.05.026},
	pages = {215--226.e4},
	number = {1},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Dotson, Nicholas M. and Hoffman, Steven J. and Goodell, Baldwin and Gray, Charles M.},
	urldate = {2018-09-18},
	date = {2018-07-11},
	pmid = {29909999},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/S9M2CEHY/Dotson et al. - 2018 - Feature-Based Visual Short-Term Memory Is Widely D.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/4EK3SXRV/S0896-6273(18)30424-0.html:text/html}
}

@article{baldassano_discovering_2017,
	title = {Discovering Event Structure in Continuous Narrative Perception and Memory},
	volume = {95},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(17)30593-7},
	doi = {10.1016/j.neuron.2017.06.041},
	pages = {709--721.e5},
	number = {3},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Baldassano, Christopher and Chen, Janice and Zadbood, Asieh and Pillow, Jonathan W. and Hasson, Uri and Norman, Kenneth A.},
	urldate = {2018-07-02},
	date = {2017-08-02},
	pmid = {28772125},
	keywords = {event model, event segmentation, {fMRI}, Hidden Markov Model, hippocampus, memory, narrative, perception, recall, reinstatement, situation model},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/7ZA9DWBX/Baldassano et al. - 2017 - Discovering Event Structure in Continuous Narrativ.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/HYLNN7RR/S0896-6273(17)30593-7.html:text/html}
}

@article{glasser_trends_2014,
	title = {Trends and properties of human cerebral cortex: correlations with cortical myelin content},
	volume = {93 Pt 2},
	issn = {1095-9572},
	doi = {10.1016/j.neuroimage.2013.03.060},
	shorttitle = {Trends and properties of human cerebral cortex},
	abstract = {"In vivo Brodmann mapping" or non-invasive cortical parcellation using {MRI}, especially by measuring cortical myelination, has recently become a popular research topic, though myeloarchitectonic cortical parcellation in humans previously languished in favor of cytoarchitecture. We review recent in vivo myelin mapping studies and discuss some of the different methods for estimating myelin content. We discuss some ways in which myelin maps may improve surface registration and be useful for cross-modal and cross-species comparisons, including some preliminary cross-species results. Next, we consider neurobiological aspects of why some parts of cortex are more myelinated than others. Myelin content is inversely correlated with intracortical circuit complexity - in general, more myelin content means simpler and perhaps less dynamic intracortical circuits. Using existing {PET} data and functional network parcellations, we examine metabolic differences in the differently myelinated cortical functional networks. Lightly myelinated cognitive association networks tend to have higher aerobic glycolysis than heavily myelinated early sensory-motor ones, perhaps reflecting greater ongoing dynamic anabolic cortical processes. This finding is consistent with the hypothesis that intracortical myelination may stabilize intracortical circuits and inhibit synaptic plasticity. Finally, we discuss the future of the in vivo myeloarchitectural field and cortical parcellation--"in vivo Brodmann mapping"--in general.},
	pages = {165--175},
	journaltitle = {{NeuroImage}},
	shortjournal = {Neuroimage},
	author = {Glasser, Matthew F. and Goyal, Manu S. and Preuss, Todd M. and Raichle, Marcus E. and Van Essen, David C.},
	date = {2014-06},
	pmid = {23567887},
	pmcid = {PMC3795824},
	keywords = {Animals, Brain Mapping, Cerebral Cortex, Humans, Magnetic Resonance Imaging, Aerobic glycolysis, Cerebral cortex, Cortical area, Cortical parcellation, Macaca, Myelin map, Myelin Sheath, Pan troglodytes, {PET}, Positron-Emission Tomography, Species Specificity}
}

@article{lerner_topographic_2011,
	title = {Topographic mapping of a hierarchy of temporal receptive windows using a narrated story},
	volume = {31},
	issn = {1529-2401},
	doi = {10.1523/JNEUROSCI.3684-10.2011},
	abstract = {Real-life activities, such as watching a movie or engaging in conversation, unfold over many minutes. In the course of such activities, the brain has to integrate information over multiple time scales. We recently proposed that the brain uses similar strategies for integrating information across space and over time. Drawing a parallel with spatial receptive fields, we defined the temporal receptive window ({TRW}) of a cortical microcircuit as the length of time before a response during which sensory information may affect that response. Our previous findings in the visual system are consistent with the hypothesis that {TRWs} become larger when moving from low-level sensory to high-level perceptual and cognitive areas. In this study, we mapped {TRWs} in auditory and language areas by measuring {fMRI} activity in subjects listening to a real-life story scrambled at the time scales of words, sentences, and paragraphs. Our results revealed a hierarchical topography of {TRWs}. In early auditory cortices (A1+), brain responses were driven mainly by the momentary incoming input and were similarly reliable across all scrambling conditions. In areas with an intermediate {TRW}, coherent information at the sentence time scale or longer was necessary to evoke reliable responses. At the apex of the {TRW} hierarchy, we found parietal and frontal areas that responded reliably only when intact paragraphs were heard in a meaningful sequence. These results suggest that the time scale of processing is a functional property that may provide a general organizing principle for the human cerebral cortex.},
	pages = {2906--2915},
	number = {8},
	journaltitle = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Lerner, Yulia and Honey, Christopher J. and Silbert, Lauren J. and Hasson, Uri},
	date = {2011-02-23},
	pmid = {21414912},
	pmcid = {PMC3089381},
	keywords = {Cerebral Cortex, Humans, Reaction Time, Adult, Auditory Perception, Speech Perception, Time Perception, Verbal Behavior, Young Adult}
}

@article{rubin_stabilized_2015,
	title = {The stabilized supralinear network: a unifying circuit motif underlying multi-input integration in sensory cortex},
	volume = {85},
	issn = {1097-4199},
	doi = {10.1016/j.neuron.2014.12.026},
	shorttitle = {The stabilized supralinear network},
	abstract = {Neurons in sensory cortex integrate multiple influences to parse objects and support perception. Across multiple cortical areas, integration is characterized by two neuronal response properties: (1) surround suppression--modulatory contextual stimuli suppress responses to driving stimuli; and (2) "normalization"--responses to multiple driving stimuli add sublinearly. These depend on input strength: for weak driving stimuli, contextual influences facilitate or more weakly suppress and summation becomes linear or supralinear. Understanding the circuit operations underlying integration is critical to understanding cortical function and disease. We present a simple, general theory. A wealth of integrative properties, including the above, emerge robustly from four cortical circuit properties: (1) supralinear neuronal input/output functions; (2) sufficiently strong recurrent excitation; (3) feedback inhibition; and (4) simple spatial properties of intracortical connections. Integrative properties emerge dynamically as circuit properties, with excitatory and inhibitory neurons showing similar behaviors. In new recordings in visual cortex, we confirm key model predictions.},
	pages = {402--417},
	number = {2},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Rubin, Daniel B. and Van Hooser, Stephen D. and Miller, Kenneth D.},
	date = {2015-01-21},
	pmid = {25611511},
	pmcid = {PMC4344127},
	keywords = {Animals, Neurons, Models, Neurological, Auditory Cortex, Feedback, Physiological, Ferrets, Linear Models, Neural Inhibition, Nonlinear Dynamics, Olfactory Cortex, Photic Stimulation, Somatosensory Cortex, Visual Cortex}
}

@article{bernacchia_reservoir_2011,
	title = {A reservoir of time constants for memory traces in cortical neurons},
	volume = {14},
	rights = {2011 Nature Publishing Group},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.2752},
	doi = {10.1038/nn.2752},
	abstract = {According to reinforcement learning theory of decision making, reward expectation is computed by integrating past rewards with a fixed timescale. In contrast, we found that a wide range of time constants is available across cortical neurons recorded from monkeys performing a competitive game task. By recognizing that reward modulates neural activity multiplicatively, we found that one or two time constants of reward memory can be extracted for each neuron in prefrontal, cingulate and parietal cortex. These timescales ranged from hundreds of milliseconds to tens of seconds, according to a power law distribution, which is consistent across areas and reproduced by a 'reservoir' neural network model. These neuronal memory timescales were weakly, but significantly, correlated with those of monkey's decisions. Our findings suggest a flexible memory system in which neural subpopulations with distinct sets of long or short memory timescales may be selectively deployed according to the task demands.},
	pages = {366--372},
	number = {3},
	journaltitle = {Nature Neuroscience},
	author = {Bernacchia, Alberto and Seo, Hyojung and Lee, Daeyeol and Wang, Xiao-Jing},
	urldate = {2018-05-08},
	date = {2011-03},
	langid = {english},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/VQTWVMVG/Bernacchia et al. - 2011 - A reservoir of time constants for memory traces in.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/U24MGMQC/nn.html:text/html}
}

@article{stephens_place_2013,
	title = {A place for time: the spatiotemporal structure of neural dynamics during natural audition},
	volume = {110},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/10.1152/jn.00268.2013},
	doi = {10.1152/jn.00268.2013},
	shorttitle = {A place for time},
	abstract = {We use functional magnetic resonance imaging ({fMRI}) to analyze neural responses to natural auditory stimuli. We characterize the {fMRI} time series through the shape of the voxel power spectrum and find that the timescales of neural dynamics vary along a spatial gradient, with faster dynamics in early auditory cortex and slower dynamics in higher order brain regions. The timescale gradient is observed through the unsupervised clustering of the power spectra of individual brains, both in the presence and absence of a stimulus, and is enhanced in the stimulus-locked component that is shared across listeners. Moreover, intrinsically faster dynamics occur in areas that respond preferentially to momentary stimulus features, while the intrinsically slower dynamics occur in areas that integrate stimulus information over longer timescales. These observations connect the timescales of intrinsic neural dynamics to the timescales of information processing, suggesting a temporal organizing principle for neural computation across the cerebral cortex.},
	pages = {2019--2026},
	number = {9},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Stephens, Greg J. and Honey, Christopher J. and Hasson, Uri},
	urldate = {2018-05-08},
	date = {2013-08-07},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/B56AVCWY/Stephens et al. - 2013 - A place for time the spatiotemporal structure of .pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/SHUIJFEM/jn.00268.html:text/html}
}

@article{gauthier_temporal_2012,
	title = {Temporal Tuning Properties along the Human Ventral Visual Stream},
	volume = {32},
	rights = {Copyright © 2012 the authors 0270-6474/12/3214433-09\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/32/41/14433},
	doi = {10.1523/JNEUROSCI.2467-12.2012},
	abstract = {Both our environment and our behavior contain many spatiotemporal regularities. Preferential and differential tuning of neural populations to these regularities can be demonstrated by assessing rate dependence of neural responses evoked during continuous periodic stimulation. Here, we used functional magnetic resonance imaging to measure regional variations of temporal sensitivity along the human ventral visual stream. By alternating one face and one house stimulus, we combined sufficient low-level signal modulation with changes in semantic meaning and could therefore drive all tiers of visual cortex strongly enough to assess rate dependence. We found several dissociations between early visual cortex and middle- and higher-tier regions. First, there was a progressive slowing down of stimulation rates yielding peak responses along the ventral visual stream. This finding shows the width of temporal integration windows to increase at higher hierarchical levels. Next, for fixed rates, early but not higher visual cortex responses additionally depended on the length of stimulus exposure, which may indicate increased persistence of responses to short stimuli at higher hierarchical levels. Finally, attention, which was recruited by an incidental task, interacted with stimulation rate and shifted tuning peaks toward lower frequencies. Together, these findings quantify neural response properties that are likely to be operational during natural vision and that provide putative neurofunctional substrates of mechanisms that are relevant in several psychophysical phenomena as masking and the attentional blink. Moreover, they illustrate temporal constraints for translating the deployment of attention into enhanced neural responses and thereby account for lower limits of attentional dwell time.},
	pages = {14433--14441},
	number = {41},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Gauthier, Baptiste and Eger, Evelyn and Hesselmann, Guido and Giraud, Anne-Lise and Kleinschmidt, Andreas},
	urldate = {2018-05-08},
	date = {2012-10-10},
	langid = {english},
	pmid = {23055513},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/HA9QLKN2/Gauthier et al. - 2012 - Temporal Tuning Properties along the Human Ventral.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/U2J7GG69/14433.html:text/html}
}

@article{honey_slow_2012,
	title = {Slow Cortical Dynamics and the Accumulation of Information over Long Timescales},
	volume = {76},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(12)00717-9},
	doi = {10.1016/j.neuron.2012.08.011},
	pages = {423--434},
	number = {2},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Honey, Christopher J. and Thesen, Thomas and Donner, Tobias H. and Silbert, Lauren J. and Carlson, Chad E. and Devinsky, Orrin and Doyle, Werner K. and Rubin, Nava and Heeger, David J. and Hasson, Uri},
	urldate = {2018-05-08},
	date = {2012-10-18},
	pmid = {23083743},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/NFRUFSYS/Honey et al. - 2012 - Slow Cortical Dynamics and the Accumulation of Inf.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/UTYVFUEU/S0896-6273(12)00717-9.html:text/html}
}

@article{akrami_posterior_2018,
	title = {Posterior parietal cortex represents sensory history and mediates its effects on behaviour},
	volume = {554},
	rights = {2018 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature25510},
	doi = {10.1038/nature25510},
	abstract = {Many models of cognition and of neural computations posit the use and estimation of prior stimulus statistics1,2,3,4: it has long been known that working memory and perception are strongly impacted by previous sensory experience, even when that sensory history is not relevant to the current task at hand. Nevertheless, the neural mechanisms and regions of the brain that are necessary for computing and using such prior experience are unknown. Here we report that the posterior parietal cortex ({PPC}) is a critical locus for the representation and use of prior stimulus information. We trained rats in an auditory parametric working memory task, and found that they displayed substantial and readily quantifiable behavioural effects of sensory-stimulus history, similar to those observed in humans5,6 and monkeys7. Earlier proposals that the {PPC} supports working memory8,9 predict that optogenetic silencing of this region would impair behaviour in our working memory task. Contrary to this prediction, we found that silencing the {PPC} significantly improved performance. Quantitative analyses of behaviour revealed that this improvement was due to the selective reduction of the effects of prior sensory stimuli. Electrophysiological recordings showed that {PPC} neurons carried far more information about the sensory stimuli of previous trials than about the stimuli of the current trial. Furthermore, for a given rat, the more information about previous trial sensory history in the neural firing rates of the {PPC}, the greater the behavioural effect of sensory history, suggesting a tight link between behaviour and {PPC} representations of stimulus history. Our results indicate that the {PPC} is a central component in the processing of sensory-stimulus history, and could enable further neurobiological investigation of long-standing questions regarding how perception and working memory are affected by prior sensory information.},
	pages = {368--372},
	number = {7692},
	journaltitle = {Nature},
	author = {Akrami, Athena and Kopec, Charles D. and Diamond, Mathew E. and Brody, Carlos D.},
	urldate = {2018-02-26},
	date = {2018-02},
	langid = {english},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/MTYVBGPG/Akrami et al. - 2018 - Posterior parietal cortex represents sensory histo.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/AFSR4U2P/nature25510.html:text/html}
}

@article{huntenburg_large-scale_2018,
	title = {Large-Scale Gradients in Human Cortical Organization},
	volume = {22},
	issn = {1364-6613, 1879-307X},
	url = {http://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(17)30240-1},
	doi = {10.1016/j.tics.2017.11.002},
	pages = {21--31},
	number = {1},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Huntenburg, Julia M. and Bazin, Pierre-Louis and Margulies, Daniel S.},
	urldate = {2018-02-05},
	date = {2018-01-01},
	pmid = {29203085},
	keywords = {cortical organization, functional hierarchy, gradient, intrinsic coordinate system, spatial arrangement},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/N923K7T7/Huntenburg et al. - 2018 - Large-Scale Gradients in Human Cortical Organizati.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/5SIE5BSR/S1364-6613(17)30240-1.html:text/html}
}

@article{honey_slow_2012-1,
	title = {Slow Cortical Dynamics and the Accumulation of Information over Long Timescales},
	volume = {76},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627312007179},
	doi = {10.1016/j.neuron.2012.08.011},
	abstract = {Summary
Making sense of the world requires us to process information over multiple timescales. We sought to identify brain regions that accumulate information over short and long timescales and to characterize the distinguishing features of their dynamics. We recorded electrocorticographic ({ECoG}) signals from individuals watching intact and scrambled movies. Within sensory regions, fluctuations of high-frequency (64–200 Hz) power reliably tracked instantaneous low-level properties of the intact and scrambled movies. Within higher order regions, the power fluctuations were more reliable for the intact movie than the scrambled movie, indicating that these regions accumulate information over relatively long time periods (several seconds or longer). Slow ({\textless}0.1 Hz) fluctuations of high-frequency power with time courses locked to the movies were observed throughout the cortex. Slow fluctuations were relatively larger in regions that accumulated information over longer time periods, suggesting a connection between slow neuronal population dynamics and temporally extended information processing.},
	pages = {423--434},
	number = {2},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Honey, Christopher J. and Thesen, Thomas and Donner, Tobias H. and Silbert, Lauren J. and Carlson, Chad E. and Devinsky, Orrin and Doyle, Werner K. and Rubin, Nava and Heeger, David J. and Hasson, Uri},
	urldate = {2017-12-05},
	date = {2012-10-18},
	file = {ScienceDirect Full Text PDF:/home/jdehning/Zotero/storage/S8JMPMSW/Honey et al. - 2012 - Slow Cortical Dynamics and the Accumulation of Inf.pdf:application/pdf;ScienceDirect Snapshot:/home/jdehning/Zotero/storage/TIEA5468/S0896627312007179.html:text/html}
}

@article{markov_anatomy_2014,
	title = {Anatomy of hierarchy: feedforward and feedback pathways in macaque visual cortex},
	volume = {522},
	issn = {1096-9861},
	doi = {10.1002/cne.23458},
	shorttitle = {Anatomy of hierarchy},
	abstract = {The laminar location of the cell bodies and terminals of interareal connections determines the hierarchical structural organization of the cortex and has been intensively studied. However, we still have only a rudimentary understanding of the connectional principles of feedforward ({FF}) and feedback ({FB}) pathways. Quantitative analysis of retrograde tracers was used to extend the notion that the laminar distribution of neurons interconnecting visual areas provides an index of hierarchical distance (percentage of supragranular labeled neurons [{SLN}]). We show that: 1) {SLN} values constrain models of cortical hierarchy, revealing previously unsuspected areal relations; 2) {SLN} reflects the operation of a combinatorial distance rule acting differentially on sets of connections between areas; 3) Supragranular layers contain highly segregated bottom-up and top-down streams, both of which exhibit point-to-point connectivity. This contrasts with the infragranular layers, which contain diffuse bottom-up and top-down streams; 4) Cell filling of the parent neurons of {FF} and {FB} pathways provides further evidence of compartmentalization; 5) {FF} pathways have higher weights, cross fewer hierarchical levels, and are less numerous than {FB} pathways. Taken together, the present results suggest that cortical hierarchies are built from supra- and infragranular counterstreams. This compartmentalized dual counterstream organization allows point-to-point connectivity in both bottom-up and top-down directions.},
	pages = {225--259},
	number = {1},
	journaltitle = {The Journal of Comparative Neurology},
	shortjournal = {J. Comp. Neurol.},
	author = {Markov, Nikola T. and Vezoli, Julien and Chameau, Pascal and Falchier, Arnaud and Quilodran, René and Huissoud, Cyril and Lamy, Camille and Misery, Pierre and Giroud, Pascale and Ullman, Shimon and Barone, Pascal and Dehay, Colette and Knoblauch, Kenneth and Kennedy, Henry},
	date = {2014-01-01},
	pmid = {23983048},
	pmcid = {PMC4255240},
	keywords = {Animals, Macaca mulatta, Neurons, Female, Male, Visual Cortex, cell morphology, Feedback, Sensory, Macaca fascicularis, monkey, neocortex, Neuroanatomical Tract-Tracing Techniques, retrograde tracing, Visual Pathways}
}

@article{dotson_experimental_2016,
	title = {Experimental observation of phase-flip transitions in the brain},
	volume = {94},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.94.042420},
	doi = {10.1103/PhysRevE.94.042420},
	abstract = {The phase-flip transition has been demonstrated in a host of coupled nonlinear oscillator models, many pertaining directly to understanding neural dynamics. However, there is little evidence that this phenomenon occurs in the brain. Using simultaneous microelectrode recordings in the nonhuman primate cerebral cortex, we demonstrate the presence of phase-flip transitions between oscillatory narrow-band local field potential signals separated by several centimeters. Specifically, we show that sharp transitions between in-phase and antiphase synchronization are accompanied by a jump in synchronization frequency. These findings are significant for two reasons. First, they validate predictions made by model systems. Second, they have potentially far reaching implications for our understanding of the mechanisms underlying corticocortical communication, which are thought to rely on narrow-band oscillatory synchronization with specific relative phase relationships.},
	pages = {042420},
	number = {4},
	journaltitle = {Physical Review E},
	shortjournal = {Phys. Rev. E},
	author = {Dotson, Nicholas M. and Gray, Charles M.},
	urldate = {2017-11-28},
	date = {2016-10-24},
	file = {APS Snapshot:/home/jdehning/Zotero/storage/E27L6EWA/PhysRevE.94.html:text/html}
}

@article{dotson_large-scale_2017,
	title = {A Large-Scale Semi-Chronic Microdrive Recording System for Non-Human Primates},
	volume = {96},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627317309194},
	doi = {10.1016/j.neuron.2017.09.050},
	abstract = {Summary
Multi-electrode recordings in the non-human primate provide a critical method for measuring the widely distributed activity patterns that underlie brain function. However, common techniques rely on small, often immovable arrays, or microdrives, that are only capable of manipulating a small number of closely spaced probes. These techniques restrict the number of cortical areas that can be simultaneously sampled and are typically not capable of reaching subcortical targets. To overcome these limitations, we developed a large-scale, semi-chronic microdrive recording system with up to 256 independently movable microelectrodes spanning an entire cerebral hemisphere. The microdrive system is hermetically sealed, free of internal connecting wires, and has been used to simultaneously record from up to 37 cortical and subcortical areas in awake behaving monkeys for up to 9 months. As a proof of principle, we demonstrate the capability of this technique to address network-level questions using a graph theoretic analysis of functional connectivity data.},
	pages = {769--782.e2},
	number = {4},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Dotson, Nicholas M. and Hoffman, Steven J. and Goodell, Baldwin and Gray, Charles M.},
	urldate = {2017-11-27},
	date = {2017-11-15},
	keywords = {working memory, monkey, electrophysiology, graph theory, large-scale recording, microdrive, multi-electrode, phase locking, synchronization},
	file = {ScienceDirect Full Text PDF:/home/jdehning/Zotero/storage/A5C8DPQE/Dotson et al. - 2017 - A Large-Scale Semi-Chronic Microdrive Recording Sy.pdf:application/pdf;ScienceDirect Snapshot:/home/jdehning/Zotero/storage/7ILZIRKI/S0896627317309194.html:text/html}
}

@article{leech_call_2002,
	title = {A Call for Greater Use of Nonparametric Statistics},
	url = {https://eric.ed.gov/?id=ED471346},
	abstract = {This paper advocates the use of nonparametric statistics. First, the consequence of using parametric inferential techniques under nonnormality is described. Second, the advantages of using nonparametric techniques are presented. The third purpose is to demonstrate empirically how infrequently nonparametric statistics appear in studies, even those published in the most reputable journals. Fourth, a typology of nonparametric statistics is presented for all univariate general linear model analyses. The nonparametric statistics that are available in the most commonly used statistical software are delineated, and finally, nonparametric effect size indices are outlined. (Contains 1 table and 52 references.) (Author/{SLD})},
	author = {Leech, Nancy L. and Onwuegbuzie, Anthony J.},
	urldate = {2017-11-20},
	date = {2002-11},
	langid = {english},
	keywords = {Classification, Computer Software, Educational Research, Effect Size, Nonparametric Statistics, Statistical Inference},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/S5BGSV9U/Leech and Onwuegbuzie - 2002 - A Call for Greater Use of Nonparametric Statistics.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/3EAUV9XE/eric.ed.gov.html:text/html}
}

@article{meisel_interplay_2017,
	title = {The Interplay between Long- and Short-Range Temporal Correlations Shapes Cortex Dynamics across Vigilance States},
	volume = {37},
	rights = {Copyright © 2017 the authors 0270-6474/17/3710114-11\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/37/42/10114},
	doi = {10.1523/JNEUROSCI.0448-17.2017},
	abstract = {Increasing evidence suggests that cortical dynamics during wake exhibits long-range temporal correlations suitable to integrate inputs over extended periods of time to increase the signal-to-noise ratio in decision making and working memory tasks. Accordingly, sleep has been suggested as a state characterized by a breakdown of long-range correlations. However, detailed measurements of neuronal timescales that support this view have so far been lacking. Here, we show that the cortical timescales measured at the individual neuron level in freely behaving male rats change as a function of vigilance state and time awake. Although quiet wake and rapid eye movement ({REM}) sleep are characterized by similar, long timescales, these long timescales are abrogated in non-{REM} sleep. We observe that cortex dynamics exhibits rapid transitions between long-timescale states and sleep-like states governed by short timescales even during wake. This becomes particularly evident during sleep deprivation, when the interplay between these states can lead to an increasing disruption of long timescales that are restored after sleep. Experiments and modeling identify the intrusion of neuronal offline periods as a mechanism that disrupts the long timescales arising from reverberating cortical network activity. Our results provide novel mechanistic and functional links among behavioral manifestations of sleep, wake, and sleep deprivation and specific measurable changes in the network dynamics relevant for characterizing the brain's changing information-processing capabilities. They suggest a network-level function of sleep to reorganize cortical networks toward states governed by long timescales to ensure efficient information integration for the time awake.
{SIGNIFICANCE} {STATEMENT} Lack of sleep deteriorates several key cognitive functions, yet the neuronal underpinnings of these deficits have remained elusive. Cognitive capabilities are generally believed to benefit from a neural circuit's ability to reliably integrate information. Persistent network activity characterized by long timescales may provide the basis for this integration in cortex. Here, we show that long-range temporal correlations indicated by slowly decaying autocorrelation functions in neuronal activity are dependent on vigilance states. Although wake and rapid eye movement ({REM}) sleep exhibit long timescales, these long-range correlations break down during non-{REM} sleep. Our findings thus suggest two distinct states in terms of timescale dynamics. During extended wake, the rapid switching to sleep-like states with short timescales can lead to an overall decline in cortical timescales.},
	pages = {10114--10124},
	number = {42},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Meisel, Christian and Klaus, Andreas and Vyazovskiy, Vladyslav V. and Plenz, Dietmar},
	urldate = {2017-11-05},
	date = {2017-10-18},
	langid = {english},
	pmid = {28947577},
	keywords = {cortical network function, Sleep, sleep deprivation, timescales},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/V9DD5XDF/Meisel et al. - 2017 - The Interplay between Long- and Short-Range Tempor.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/ACHIKDH8/10114.html:text/html}
}

@article{cocchi_criticality_2017,
	title = {Criticality in the brain: A synthesis of neurobiology, models and cognition},
	url = {http://arxiv.org/abs/1707.05952},
	shorttitle = {Criticality in the brain},
	abstract = {Cognitive function requires the coordination of neural activity across many scales, from neurons and circuits to large-scale networks. As such, it is unlikely that an explanatory framework focused upon any single scale will yield a comprehensive theory of brain activity and cognitive function. Modelling and analysis methods for neuroscience should aim to accommodate multiscale phenomena. Emerging research now suggests that multi-scale processes in the brain arise from so-called critical phenomena that occur very broadly in the natural world. Criticality arises in complex systems perched between order and disorder, and is marked by fluctuations that do not have any privileged spatial or temporal scale. We review the core nature of criticality, the evidence supporting its role in neural systems and its explanatory potential in brain health and disease.},
	journaltitle = {{arXiv}:1707.05952 [q-bio]},
	author = {Cocchi, Luca and Gollo, Leonardo L. and Zalesky, Andrew and Breakspear, Michael},
	date = {2017-07-19},
	eprinttype = {arxiv},
	eprint = {1707.05952},
	keywords = {Quantitative Biology - Neurons and Cognition},
	file = {arXiv\:1707.05952 PDF:/home/jdehning/Zotero/storage/2NK3HHU6/Cocchi et al. - 2017 - Criticality in the brain A synthesis of neurobiol.pdf:application/pdf;arXiv.org Snapshot:/home/jdehning/Zotero/storage/ZPADKQXK/1707.html:text/html}
}

@article{kinouchi_optimal_2006,
	title = {Optimal dynamical range of excitable networks at criticality},
	volume = {2},
	rights = {2006 Nature Publishing Group},
	issn = {1745-2481},
	url = {https://www.nature.com/articles/nphys289},
	doi = {10.1038/nphys289},
	abstract = {Article},
	pages = {nphys289},
	number = {5},
	journaltitle = {Nature Physics},
	author = {Kinouchi, Osame and Copelli, Mauro},
	urldate = {2017-11-05},
	date = {2006-04-23},
	langid = {english},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/BS9FNPV6/Kinouchi and Copelli - 2006 - Optimal dynamical range of excitable networks at c.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/GQH3I86B/nphys289.html:text/html}
}

@article{hesse_self-organized_2014,
	title = {Self-organized criticality as a fundamental property of neural systems},
	volume = {8},
	issn = {1662-5137},
	url = {https://www.frontiersin.org/articles/10.3389/fnsys.2014.00166/full},
	doi = {10.3389/fnsys.2014.00166},
	abstract = {The neural criticality hypothesis states that the brain may be poised in a critical state at a boundary between different types of dynamics. Theoretical and experimental studies show that critical systems often exhibit optimal computational properties, suggesting the possibility that criticality has been evolutionarily selected as a useful trait for our nervous system. Evidence for criticality has been found in cell cultures, brain slices, and anesthetized animals. Yet, inconsistent results were reported for recordings in awake animals and humans, and current results point to open questions about the exact nature and mechanism of criticality, as well as its functional role. Therefore, the criticality hypothesis has remained a controversial proposition. Here, we provide an account of the mathematical and physical foundations of criticality. In the light of this conceptual framework, we then review and discuss recent experimental studies with the aim of identifying important next steps to be taken and connections to other fields that should be explored.},
	journaltitle = {Frontiers in Systems Neuroscience},
	shortjournal = {Front. Syst. Neurosci.},
	author = {Hesse, Janina and Gross, Thilo},
	urldate = {2017-11-05},
	date = {2014},
	keywords = {dynamics, Neural Network, Phase Transition, self-organized criticality, Brain}
}

@article{fagerholm_cascades_2015,
	title = {Cascades and Cognitive State: Focused Attention Incurs Subcritical Dynamics},
	volume = {35},
	rights = {Copyright © 2015 the authors 0270-6474/15/354626-09\$15.00/0. This article is freely available online through the J Neurosci Author Open Choice option.},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/35/11/4626},
	doi = {10.1523/JNEUROSCI.3694-14.2015},
	shorttitle = {Cascades and Cognitive State},
	abstract = {The analysis of neuronal avalanches supports the hypothesis that the human cortex operates with critical neural dynamics. Here, we investigate the relationship between cascades of activity in electroencephalogram data, cognitive state, and reaction time in humans using a multimodal approach. We recruited 18 healthy volunteers for the acquisition of simultaneous electroencephalogram and functional magnetic resonance imaging during both rest and during a visuomotor cognitive task. We compared distributions of electroencephalogram-derived cascades to reference power laws for task and rest conditions. We then explored the large-scale spatial correspondence of these cascades in the simultaneously acquired functional magnetic resonance imaging data. Furthermore, we investigated whether individual variability in reaction times is associated with the amount of deviation from power law form. We found that while resting state cascades are associated with approximate power law form, the task state is associated with subcritical dynamics. Furthermore, we found that electroencephalogram cascades are related to blood oxygen level-dependent activation, predominantly in sensorimotor brain regions. Finally, we found that decreased reaction times during the task condition are associated with increased proximity to power law form of cascade distributions. These findings suggest that the resting state is associated with near-critical dynamics, in which a high dynamic range and a large repertoire of brain states may be advantageous. In contrast, a focused cognitive task induces subcritical dynamics, which is associated with a lower dynamic range, which in turn may reduce elements of interference affecting task performance.},
	pages = {4626--4634},
	number = {11},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Fagerholm, Erik D. and Lorenz, Romy and Scott, Gregory and Dinov, Martin and Hellyer, Peter J. and Mirzaei, Nazanin and Leeson, Clare and Carmichael, David W. and Sharp, David J. and Shew, Woodrow L. and Leech, Robert},
	urldate = {2017-11-05},
	date = {2015-03-18},
	langid = {english},
	pmid = {25788679},
	keywords = {{fMRI}, Attention, criticality, {EEG}, power law},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/AA9J3XX4/Fagerholm et al. - 2015 - Cascades and Cognitive State Focused Attention In.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/JHDXSFFH/4626.html:text/html}
}

@article{ahmadian_analysis_2012,
	title = {Analysis of the stabilized supralinear network},
	url = {http://arxiv.org/abs/1202.6670},
	abstract = {We study a rate-model neural network composed of excitatory and inhibitory neurons in which neuronal input-output functions are power laws with a power greater than 1, as observed in primary visual cortex. This supralinear input-output function leads to supralinear summation of network responses to multiple inputs for weak inputs. We show that for stronger inputs, which would drive the excitatory subnetwork to instability, the network will dynamically stabilize provided feedback inhibition is sufficiently strong. For a wide range of network and stimulus parameters, this dynamic stabilization yields a transition from supralinear to sublinear summation of network responses to multiple inputs. We compare this to the dynamic stabilization in the "balanced network", which yields only linear behavior. We more exhaustively analyze the 2-dimensional case of 1 excitatory and 1 inhibitory population. We show that in this case dynamic stabilization will occur whenever the determinant of the weight matrix is positive and the inhibitory time constant is sufficiently small, and analyze the conditions for "supersaturation", or decrease of firing rates with increasing stimulus contrast (which represents increasing input firing rates). In work to be presented elsewhere, we have found that this transition from supralinear to sublinear summation can explain a wide variety of nonlinearities in cerebral cortical processing.},
	journaltitle = {{arXiv}:1202.6670 [q-bio]},
	author = {Ahmadian, Yashar and Rubin, Daniel B. and Miller, Kenneth D.},
	date = {2012-02-29},
	eprinttype = {arxiv},
	eprint = {1202.6670},
	keywords = {Quantitative Biology - Neurons and Cognition},
	file = {arXiv\:1202.6670 PDF:/home/jdehning/Zotero/storage/TZ5TTBZU/Ahmadian et al. - 2012 - Analysis of the stabilized supralinear network.pdf:application/pdf;arXiv.org Snapshot:/home/jdehning/Zotero/storage/FPGPM6HZ/1202.html:text/html}
}

@article{luczak_packet-based_2015,
	title = {Packet-based communication in the cortex},
	volume = {16},
	rights = {© 2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1471-003X},
	url = {https://www.nature.com/nrn/journal/v16/n12/full/nrn4026.html},
	doi = {10.1038/nrn4026},
	abstract = {Cortical circuits work through the generation of coordinated, large-scale activity patterns. In sensory systems, the onset of a discrete stimulus usually evokes a temporally organized packet of population activity lasting {\textasciitilde}50–200 ms. The structure of these packets is partially stereotypical, and variation in the exact timing and number of spikes within a packet conveys information about the identity of the stimulus. Similar packets also occur during ongoing stimuli and spontaneously. We suggest that such packets constitute the basic building blocks of cortical coding.},
	pages = {745--755},
	number = {12},
	journaltitle = {Nature Reviews Neuroscience},
	shortjournal = {Nat Rev Neurosci},
	author = {Luczak, Artur and {McNaughton}, Bruce L. and Harris, Kenneth D.},
	urldate = {2017-08-29},
	date = {2015-12},
	langid = {english},
	keywords = {cortex, Neural decoding, Neuronal physiology},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/2HNCNHTW/Luczak et al. - 2015 - Packet-based communication in the cortex.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/CJ8JM222/nrn4026.html:text/html}
}

@article{bernacchia_reservoir_2011-1,
	title = {A reservoir of time constants for memory traces in cortical neurons},
	volume = {14},
	rights = {© 2011 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1097-6256},
	url = {https://www.nature.com/neuro/journal/v14/n3/full/nn.2752.html},
	doi = {10.1038/nn.2752},
	abstract = {According to reinforcement learning theory of decision making, reward expectation is computed by integrating past rewards with a fixed timescale. In contrast, we found that a wide range of time constants is available across cortical neurons recorded from monkeys performing a competitive game task. By recognizing that reward modulates neural activity multiplicatively, we found that one or two time constants of reward memory can be extracted for each neuron in prefrontal, cingulate and parietal cortex. These timescales ranged from hundreds of milliseconds to tens of seconds, according to a power law distribution, which is consistent across areas and reproduced by a 'reservoir' neural network model. These neuronal memory timescales were weakly, but significantly, correlated with those of monkey's decisions. Our findings suggest a flexible memory system in which neural subpopulations with distinct sets of long or short memory timescales may be selectively deployed according to the task demands.},
	pages = {366--372},
	number = {3},
	journaltitle = {Nature Neuroscience},
	shortjournal = {Nat Neurosci},
	author = {Bernacchia, Alberto and Seo, Hyojung and Lee, Daeyeol and Wang, Xiao-Jing},
	urldate = {2017-08-29},
	date = {2011-03},
	langid = {english},
	keywords = {Decision, Learning and memory},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/G44EW6KJ/Bernacchia et al. - 2011 - A reservoir of time constants for memory traces in.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/25342SJ9/nn.2752.html:text/html}
}

@article{konig_method_1994,
	title = {A method for the quantification of synchrony and oscillatory properties of neuronal activity},
	volume = {54},
	issn = {0165-0270},
	url = {http://www.sciencedirect.com/science/article/pii/0165027094901570},
	doi = {10.1016/0165-0270(94)90157-0},
	abstract = {Interactions between neurones can be analysed by simultaneously recording from several cells and computing correlation functions between the respective activities. Recent studies have revealed that neuronal responses are often synchronous and exhibit an oscillatory temporal structure. These two properties are commonly assessed together from correlation functions. In order to evaluate these variables independently a method was devised for the quantification of a generalized Gabor function that was fitted to the correlograms. The performance of the method was tested on a large data set from cat area 17 and its stability was examined with respect to its dependence on the number of free parameters. The results demonstrate that the proposed fitting algorithm is robust in that it is rather independent of starting conditions and converges to optimal fits even with different settings of free variables. The fitted correlation functions allow for an automatic and independent classification of synchrony on the one hand and oscillatory firing patterns on the other.},
	pages = {31--37},
	number = {1},
	journaltitle = {Journal of Neuroscience Methods},
	shortjournal = {Journal of Neuroscience Methods},
	author = {König, Peter},
	date = {1994-09-01},
	keywords = {Visual Cortex, Correlation analysis, Oscillation, Synchronization, temporal coding},
	file = {konig_1994 (1).pdf:/home/jdehning/Zotero/storage/XBN7DB6X/konig_1994 (1).pdf:application/pdf;ScienceDirect Snapshot:/home/jdehning/Zotero/storage/5KJMT6A4/0165027094901570.html:text/html}
}

@article{vrieze_model_2012,
	title = {Model selection and psychological theory: a discussion of the differences between the Akaike information criterion ({AIC}) and the Bayesian information criterion ({BIC})},
	volume = {17},
	issn = {1939-1463},
	doi = {10.1037/a0027127},
	shorttitle = {Model selection and psychological theory},
	abstract = {This article reviews the Akaike information criterion ({AIC}) and the Bayesian information criterion ({BIC}) in model selection and the appraisal of psychological theory. The focus is on latent variable models, given their growing use in theory testing and construction. Theoretical statistical results in regression are discussed, and more important issues are illustrated with novel simulations involving latent variable models including factor analysis, latent profile analysis, and factor mixture models. Asymptotically, the {BIC} is consistent, in that it will select the true model if, among other assumptions, the true model is among the candidate models considered. The {AIC} is not consistent under these circumstances. When the true model is not in the candidate model set the {AIC} is efficient, in that it will asymptotically choose whichever model minimizes the mean squared error of prediction/estimation. The {BIC} is not efficient under these circumstances. Unlike the {BIC}, the {AIC} also has a minimax property, in that it can minimize the maximum possible risk in finite sample sizes. In sum, the {AIC} and {BIC} have quite different properties that require different assumptions, and applied researchers and methodologists alike will benefit from improved understanding of the asymptotic and finite-sample behavior of these criteria. The ultimate decision to use the {AIC} or {BIC} depends on many factors, including the loss function employed, the study's methodological design, the substantive research question, and the notion of a true model and its applicability to the study at hand.},
	pages = {228--243},
	number = {2},
	journaltitle = {Psychological Methods},
	shortjournal = {Psychol Methods},
	author = {Vrieze, Scott I.},
	date = {2012-06},
	pmid = {22309957},
	pmcid = {PMC3366160},
	keywords = {Humans, Nonlinear Dynamics, Bayes Theorem, Data Interpretation, Statistical, Factor Analysis, Statistical, Likelihood Functions, Models, Statistical, Monte Carlo Method, Psychological Theory, Psychology, Statistics as Topic}
}

@article{olkin_unbiased_1958,
	title = {Unbiased Estimation of Certain Correlation Coefficients},
	volume = {29},
	issn = {0003-4851, 2168-8990},
	url = {http://projecteuclid.org/euclid.aoms/1177706717},
	doi = {10.1214/aoms/1177706717},
	abstract = {This paper deals with the unbiased estimation of the correlation of two variates having a bivariate normal distribution (Sec. 2), and of the intraclass correlation, i.e., the common correlation coefficient of a ppp-variate normal distribution with equal variances and equal covariances (Sec. 3). In both cases, the estimator has the following properties. It is a function of a complete sufficient statistic and is therefore the unique (except for sets of probability zero) minimum variance unbiased estimator. Its range is the region of possible values of the estimated quantity. It is a strictly increasing function of the usual estimator differing from it only by terms of order 1/n1/n1/n and consequently having the same asymptotic distribution. Since the unbiased estimators are cumbersome in form in that they are expressed as series or integrals, tables are included giving the unbiased estimators as functions of the usual estimators. In Sec. 4 we give an unbiased estimator of the squared multiple correlation. It has the properties mentioned in the second paragraph except that it may be negative, which the squared multiple correlation cannot. In each case the estimator is obtained by inverting a Laplace transform. We are grateful to W. H. Kruskal and L. J. Savage for very helpful comments and suggestions, and to R. R. Blough for his able computations.},
	pages = {201--211},
	number = {1},
	journaltitle = {The Annals of Mathematical Statistics},
	shortjournal = {Ann. Math. Statist.},
	author = {Olkin, Ingram and Pratt, John W.},
	urldate = {2017-05-07},
	date = {1958-03},
	mrnumber = {MR93854},
	zmnumber = {0094.14403},
	file = {Snapshot:/home/jdehning/Zotero/storage/USG8TBFA/1177706717.html:text/html}
}

@article{ramo_measures_2007,
	title = {Measures for information propagation in Boolean networks},
	volume = {227},
	issn = {0167-2789},
	url = {http://www.sciencedirect.com/science/article/pii/S0167278906004829},
	doi = {10.1016/j.physd.2006.12.005},
	abstract = {Boolean networks provide a large-scale model of gene regulatory and neuronal networks. In this paper, we study what kinds of Boolean networks best propagate and process signals, i.e. information, in the presence of stochasticity and noise. We first examine two existing approaches that use mutual information and find that these approaches do not capture well the phenomenon studied. We propose a new measure for information propagation based on perturbation avalanches in Boolean networks and find that the measure is maximized in dynamically critical networks and in subcritical networks if noise is present.},
	pages = {100--104},
	number = {1},
	journaltitle = {Physica D: Nonlinear Phenomena},
	shortjournal = {Physica D: Nonlinear Phenomena},
	author = {R{\textbackslash}\{\{{\textbackslash}textbackslash\}"a{\textbackslash}\}m{\textbackslash}\{\{{\textbackslash}textbackslash\}"o{\textbackslash}\}, Pauli and Kauffman, Stuart and Kesseli, Juha and Yli-Harja, Olli},
	urldate = {2017-03-13},
	date = {2007-03-01},
	keywords = {criticality, Boolean network, Gene regulatory network, Information propagation, Perturbation avalanche},
	file = {ScienceDirect Full Text PDF:/home/jdehning/Zotero/storage/SZKERU5D/Rämö et al. - 2007 - Measures for information propagation in Boolean ne.pdf:application/pdf;ScienceDirect Snapshot:/home/jdehning/Zotero/storage/FIBK3BS9/S0167278906004829.html:text/html}
}

@online{noauthor_human_nodate,
	title = {The Human Brain Project - Human Brain Project},
	url = {https://www.humanbrainproject.eu/},
	urldate = {2017-04-06},
	file = {The Human Brain Project - Human Brain Project:/home/jdehning/Zotero/storage/P2AHZHPE/www.humanbrainproject.eu.html:text/html}
}

@article{haldeman_critical_2005,
	title = {Critical Branching Captures Activity in Living Neural Networks and Maximizes the Number of Metastable States},
	volume = {94},
	url = {http://link.aps.org/doi/10.1103/PhysRevLett.94.058101},
	doi = {10.1103/PhysRevLett.94.058101},
	abstract = {Recent experimental work has shown that activity in living neural networks can propagate as a critical branching process that revisits many metastable states. Neural network theory suggests that attracting states could store information, but little is known about how a branching process could form such states. Here we use a branching process to model actual data and to explore metastable states in the network. When we tune the branching parameter to the critical point, we find that metastable states are most numerous and that network dynamics are not attracting, but neutral.},
	pages = {058101},
	number = {5},
	journaltitle = {Physical Review Letters},
	shortjournal = {Phys. Rev. Lett.},
	author = {Haldeman, Clayton and Beggs, John M.},
	urldate = {2017-03-13},
	date = {2005-02-07},
	file = {APS Snapshot:/home/jdehning/Zotero/storage/RT3CJ3FT/PhysRevLett.94.html:text/html;Full Text PDF:/home/jdehning/Zotero/storage/KSMFP7VX/Haldeman and Beggs - 2005 - Critical Branching Captures Activity in Living Neu.pdf:application/pdf}
}

@article{shew_neuronal_2009,
	title = {Neuronal Avalanches Imply Maximum Dynamic Range in Cortical Networks at Criticality},
	volume = {29},
	issn = {0270-6474},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3862241/},
	doi = {10.1523/JNEUROSCI.3864-09.2009},
	abstract = {Spontaneous neuronal activity is a ubiquitous feature of cortex. Its spatiotemporal organization reflects past input and modulates future network output. Here we study whether a particular type of spontaneous activity is generated by a network that is optimized for input processing. Neuronal avalanches are a type of spontaneous activity observed in superficial cortical layers in vitro and in vivo with statistical properties expected from a network operating at “criticality.” Theory predicts that criticality and, therefore, neuronal avalanches are optimal for input processing, but until now, this has not been tested in experiments. Here, we use cortex slice cultures grown on planar microelectrode arrays to demonstrate that cortical networks that generate neuronal avalanches benefit from a maximized dynamic range, i.e., the ability to respond to the greatest range of stimuli. By changing the ratio of excitation and inhibition in the cultures, we derive a network tuning curve for stimulus processing as a function of distance from criticality in agreement with predictions from our simulations. Our findings suggest that in the cortex, (1) balanced excitation and inhibition establishes criticality, which maximizes the range of inputs that can be processed, and (2) spontaneous activity and input processing are unified in the context of critical phenomena.},
	pages = {15595--15600},
	number = {49},
	journaltitle = {The Journal of Neuroscience},
	shortjournal = {J Neurosci},
	author = {Shew, Woodrow L. and Yang, Hongdian and Petermann, Thomas and Roy, Rajarshi and Plenz, Dietmar},
	urldate = {2017-03-13},
	date = {2009-12-09},
	pmid = {20007483},
	pmcid = {PMC3862241},
	file = {PubMed Central Full Text PDF:/home/jdehning/Zotero/storage/UKD8PBDG/Shew et al. - 2009 - Neuronal Avalanches Imply Maximum Dynamic Range in.pdf:application/pdf}
}

@article{chialvo_emergent_2010,
	title = {Emergent complex neural dynamics},
	volume = {6},
	rights = {© 2010 Nature Publishing Group},
	issn = {1745-2473},
	url = {http://www.nature.com/nphys/journal/v6/n10/abs/nphys1803.html},
	doi = {10.1038/nphys1803},
	abstract = {A large repertoire of spatiotemporal activity patterns in the brain is the basis for adaptive behaviour. Understanding the mechanism by which the brain’s hundred billion neurons and hundred trillion synapses manage to produce such a range of cortical configurations in a flexible manner remains a fundamental problem in neuroscience. One plausible solution is the involvement of universal mechanisms of emergent complex phenomena evident in dynamical systems poised near a critical point of a second-order phase transition. We review recent theoretical and empirical results supporting the notion that the brain is naturally poised near criticality, as well as its implications for better understanding of the brain.
View full text},
	pages = {744--750},
	number = {10},
	journaltitle = {Nature Physics},
	shortjournal = {Nat Phys},
	author = {Chialvo, Dante R.},
	urldate = {2017-03-13},
	date = {2010-10},
	langid = {english},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/NPIVG9QH/Chialvo - 2010 - Emergent complex neural dynamics.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/IG643IA7/nphys1803.html:text/html}
}

@article{maass_fading_2004,
	title = {Fading memory and kernel properties of generic cortical microcircuit models},
	volume = {98},
	issn = {0928-4257},
	doi = {10.1016/j.jphysparis.2005.09.020},
	abstract = {It is quite difficult to construct circuits of spiking neurons that can carry out complex computational tasks. On the other hand even randomly connected circuits of spiking neurons can in principle be used for complex computational tasks such as time-warp invariant speech recognition. This is possible because such circuits have an inherent tendency to integrate incoming information in such a way that simple linear readouts can be trained to transform the current circuit activity into the target output for a very large number of computational tasks. Consequently we propose to analyze circuits of spiking neurons in terms of their roles as analog fading memory and non-linear kernels, rather than as implementations of specific computational operations and algorithms. This article is a sequel to [W. Maass, T. Natschläger, H. Markram, Real-time computing without stable states: a new framework for neural computation based on perturbations, Neural Comput. 14 (11) (2002) 2531-2560, Online available as \#130 from: ], and contains new results about the performance of generic neural microcircuit models for the recognition of speech that is subject to linear and non-linear time-warps, as well as for computations on time-varying firing rates. These computations rely, apart from general properties of generic neural microcircuit models, just on capabilities of simple linear readouts trained by linear regression. This article also provides detailed data on the fading memory property of generic neural microcircuit models, and a quick review of other new results on the computational power of such circuits of spiking neurons.},
	pages = {315--330},
	number = {4},
	journaltitle = {Journal of Physiology, Paris},
	shortjournal = {J. Physiol. Paris},
	author = {Maass, Wolfgang and Natschläger, Thomas and Markram, Henry},
	date = {2004-11},
	pmid = {16310350},
	keywords = {Animals, Cerebral Cortex, Humans, Neurons, Neural Networks (Computer), Action Potentials, Computer Simulation, Models, Neurological, Linear Models, Nonlinear Dynamics, Software, Speech, Time Factors}
}

@article{bertschinger_real-time_2004,
	title = {Real-time computation at the edge of chaos in recurrent neural networks},
	volume = {16},
	issn = {0899-7667},
	doi = {10.1162/089976604323057443},
	abstract = {Depending on the connectivity, recurrent networks of simple computational units can show very different types of dynamics, ranging from totally ordered to chaotic. We analyze how the type of dynamics (ordered or chaotic) exhibited by randomly connected networks of threshold gates driven by a time-varying input signal depends on the parameters describing the distribution of the connectivity matrix. In particular, we calculate the critical boundary in parameter space where the transition from ordered to chaotic dynamics takes place. Employing a recently developed framework for analyzing real-time computations, we show that only near the critical boundary can such networks perform complex computations on time series. Hence, this result strongly supports conjectures that dynamical systems that are capable of doing complex computational tasks should operate near the edge of chaos, that is, the transition from ordered to chaotic dynamics.},
	pages = {1413--1436},
	number = {7},
	journaltitle = {Neural Computation},
	shortjournal = {Neural Comput},
	author = {Bertschinger, Nils and Natschläger, Thomas},
	date = {2004-07},
	pmid = {15165396},
	keywords = {Animals, Neural Networks (Computer), Computer Simulation, Models, Neurological, Nonlinear Dynamics, Time Factors, Artificial Intelligence, Feedback, Memory}
}

@book{hubel_eye_1995,
	location = {Boston},
	edition = {Reprint},
	title = {Eye, Brain, and Vision},
	isbn = {978-0-7167-6009-2},
	abstract = {For over thirty years, Nobel Prize winner David H. Hubel has been at the forefront of research on questions of vision. In "Eye, Brain, and Vision," he brings you to the edge of current knowledge about vision, and explores the tasks scientists face in deciphering the many remaining mysteries of vision and the workings of the human brain.},
	pagetotal = {240},
	publisher = {Scientific American Library},
	author = {Hubel, David H.},
	date = {1995-07-10},
	file = {[Hubel_D.H.]_Eye,_Brain,_and_Vision(BookZZ.org).pdf:/home/jonas/Downloads/[Hubel_D.H.]_Eye,_Brain,_and_Vision(BookZZ.org).pdf:application/pdf}
}

@article{priesemann_neuronal_2013,
	title = {Neuronal Avalanches Differ from Wakefulness to Deep Sleep - Evidence from Intracranial Depth Recordings in Humans},
	volume = {9},
	issn = {1553-7358},
	url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002985},
	doi = {10.1371/journal.pcbi.1002985},
	abstract = {Author Summary  Brain activity shows complex dynamics, even in the absence of external stimulation. In fact, most brain activity is generated internally. Therefore, it is crucial to understand the generation principles of internal activity. One hypothesis is that complex brain dynamics emerges from simple local interactions if the network is in a specific state, called “self-organized critical” ({SOC}). {SOC} indeed can account for dynamics in slices of brain tissue. However, we lack evidence that human brain dynamics is {SOC}. In addition, we wondered whether {SOC} can account for brain activity from wakefulness to deep sleep, despite clear changes in brain dynamics with vigilances states. To answer these questions, we analyzed intracranial depth recordings in humans. We found evidence that the human brain indeed operates close to criticality from wakefulness to deep sleep. However, we found deviations from criticality with vigilance states. These deviations, together with our modelling results, indicated that the human brain is close to {SOC}, but in a subcritical regime. In the subcritical regime complex dynamics still emerges from purely local interactions, but are more stable than the {SOC} state. In fact, operation the subcritical regime allows for a safety margin to supercriticality, which was linked to epilepsy.},
	pages = {e1002985},
	number = {3},
	journaltitle = {{PLOS} Comput Biol},
	shortjournal = {{PLOS} Comput Biol},
	author = {Priesemann, Viola and Valderrama, Mario and Wibral, Michael and Quyen, Michel Le Van},
	urldate = {2016-07-08},
	date = {2013-03-21},
	keywords = {Electrode recording, Neural networks, Action Potentials, Neuromodulation, Sleep, Electroencephalography, Eye movements, Vigilance (psychology)},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/8SMKM6Z2/Priesemann et al. - 2013 - Neuronal Avalanches Differ from Wakefulness to Dee.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/2U3BVUGK/article.html:text/html}
}

@incollection{lashley_problem_1951,
	location = {Oxford, England},
	title = {The problem of serial order in behavior},
	rights = {(c) 2016 {APA}, all rights reserved},
	abstract = {A discussion of "the logical and orderly arrangement of thought and action" from the point of view that "the input is never into a quiescent or static system, but always into a system which is already actively excited and organized" and that "behavior is the result of interaction of this background of excitation with input from any designated stimulus." Particular emphasis is placed on the time factor in behavior. A panel discussion is included between pages 136-146.},
	pages = {112--146},
	booktitle = {Cerebral mechanisms in behavior; the Hixon Symposium},
	publisher = {Wiley},
	author = {Lashley, K. S.},
	date = {1951},
	file = {APA PsycNET Snapshot:/home/jdehning/Zotero/storage/R94GDXXK/1952-04498-003.html:text/html;Lashley_1951_The_Problem_of_Serial_Order_in_Behavior (1).pdf:/home/jdehning/Zotero/storage/2P3ZZ2XC/Lashley_1951_The_Problem_of_Serial_Order_in_Behavior (1).pdf:application/pdf}
}

@article{bak_self-organized_1987,
	title = {Self-organized criticality: An explanation of the 1/f noise},
	volume = {59},
	url = {http://link.aps.org/doi/10.1103/PhysRevLett.59.381},
	doi = {10.1103/PhysRevLett.59.381},
	shorttitle = {Self-organized criticality},
	abstract = {We show that dynamical systems with spatial degrees of freedom naturally evolve into a self-organized critical point. Flicker noise, or 1/f noise, can be identified with the dynamics of the critical state. This picture also yields insight into the origin of fractal objects.},
	pages = {381--384},
	number = {4},
	journaltitle = {Physical Review Letters},
	shortjournal = {Phys. Rev. Lett.},
	author = {Bak, Per and Tang, Chao and Wiesenfeld, Kurt},
	urldate = {2017-03-08},
	date = {1987-07-27},
	file = {APS Snapshot:/home/jdehning/Zotero/storage/FGTE8AU7/PhysRevLett.59.html:text/html}
}

@article{hasson_hierarchy_2008,
	title = {A Hierarchy of Temporal Receptive Windows in Human Cortex},
	volume = {28},
	rights = {Copyright © 2008 Society for Neuroscience 0270-6474/08/282539-12\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/28/10/2539},
	doi = {10.1523/JNEUROSCI.5487-07.2008},
	abstract = {Real-world events unfold at different time scales and, therefore, cognitive and neuronal processes must likewise occur at different time scales. We present a novel procedure that identifies brain regions responsive to sensory information accumulated over different time scales. We measured functional magnetic resonance imaging activity while observers viewed silent films presented forward, backward, or piecewise-scrambled in time. Early visual areas (e.g., primary visual cortex and the motion-sensitive area {MT}+) exhibited high response reliability regardless of disruptions in temporal structure. In contrast, the reliability of responses in several higher brain areas, including the superior temporal sulcus ({STS}), precuneus, posterior lateral sulcus ({LS}), temporal parietal junction ({TPJ}), and frontal eye field ({FEF}), was affected by information accumulated over longer time scales. These regions showed highly reproducible responses for repeated forward, but not for backward or piecewise-scrambled presentations. Moreover, these regions exhibited marked differences in temporal characteristics, with {LS}, {TPJ}, and {FEF} responses depending on information accumulated over longer durations (∼36 s) than {STS} and precuneus (∼12 s). We conclude that, similar to the known cortical hierarchy of spatial receptive fields, there is a hierarchy of progressively longer temporal receptive windows in the human brain.},
	pages = {2539--2550},
	number = {10},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Hasson, Uri and Yang, Eunice and Vallines, Ignacio and Heeger, David J. and Rubin, Nava},
	urldate = {2017-02-24},
	date = {2008-03-05},
	langid = {english},
	pmid = {18322098},
	keywords = {{fMRI}, cortex, temporal coding, functional organization, receptive fields, time},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/VNBJRGQS/Hasson et al. - 2008 - A Hierarchy of Temporal Receptive Windows in Human.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/QK9MBQ7B/2539.html:text/html}
}

@article{glasser_multi-modal_2016,
	title = {A multi-modal parcellation of human cerebral cortex},
	volume = {536},
	rights = {© 2016 Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
	issn = {0028-0836},
	url = {http://www.nature.com/nature/journal/v536/n7615/full/nature18933.html},
	doi = {10.1038/nature18933},
	abstract = {Understanding the amazingly complex human cerebral cortex requires a map (or parcellation) of its major subdivisions, known as cortical areas. Making an accurate areal map has been a century-old objective in neuroscience. Using multi-modal magnetic resonance images from the Human Connectome Project ({HCP}) and an objective semi-automated neuroanatomical approach, we delineated 180 areas per hemisphere bounded by sharp changes in cortical architecture, function, connectivity, and/or topography in a precisely aligned group average of 210 healthy young adults. We characterized 97 new areas and 83 areas previously reported using post-mortem microscopy or other specialized study-specific approaches. To enable automated delineation and identification of these areas in new {HCP} subjects and in future studies, we trained a machine-learning classifier to recognize the multi-modal ‘fingerprint’ of each cortical area. This classifier detected the presence of 96.6\% of the cortical areas in new subjects, replicated the group parcellation, and could correctly locate areas in individuals with atypical parcellations. The freely available parcellation and classifier will enable substantially improved neuroanatomical precision for studies of the structural and functional organization of human cerebral cortex and its variation across individuals and in development, aging, and disease.},
	pages = {171--178},
	number = {7615},
	journaltitle = {Nature},
	shortjournal = {Nature},
	author = {Glasser, Matthew F. and Coalson, Timothy S. and Robinson, Emma C. and Hacker, Carl D. and Harwell, John and Yacoub, Essa and Ugurbil, Kamil and Andersson, Jesper and Beckmann, Christian F. and Jenkinson, Mark and Smith, Stephen M. and Van Essen, David C.},
	urldate = {2017-01-09},
	date = {2016-08-11},
	langid = {english},
	keywords = {Cognitive neuroscience, Image processing},
	file = {Snapshot:/home/jdehning/Zotero/storage/MC7AJTC5/nature18933.html:text/html}
}

@article{herculano-houzel_human_2009,
	title = {The Human Brain in Numbers: A Linearly Scaled-up Primate Brain},
	volume = {3},
	issn = {1662-5161},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2776484/},
	doi = {10.3389/neuro.09.031.2009},
	shorttitle = {The Human Brain in Numbers},
	abstract = {The human brain has often been viewed as outstanding among mammalian brains: the most cognitively able, the largest-than-expected from body size, endowed with an overdeveloped cerebral cortex that represents over 80\% of brain mass, and purportedly containing 100 billion neurons and 10× more glial cells. Such uniqueness was seemingly necessary to justify the superior cognitive abilities of humans over larger-brained mammals such as elephants and whales. However, our recent studies using a novel method to determine the cellular composition of the brain of humans and other primates as well as of rodents and insectivores show that, since different cellular scaling rules apply to the brains within these orders, brain size can no longer be considered a proxy for the number of neurons in the brain. These studies also showed that the human brain is not exceptional in its cellular composition, as it was found to contain as many neuronal and non-neuronal cells as would be expected of a primate brain of its size. Additionally, the so-called overdeveloped human cerebral cortex holds only 19\% of all brain neurons, a fraction that is similar to that found in other mammals. In what regards absolute numbers of neurons, however, the human brain does have two advantages compared to other mammalian brains: compared to rodents, and probably to whales and elephants as well, it is built according to the very economical, space-saving scaling rules that apply to other primates; and, among economically built primate brains, it is the largest, hence containing the most neurons. These findings argue in favor of a view of cognitive abilities that is centered on absolute numbers of neurons, rather than on body size or encephalization, and call for a re-examination of several concepts related to the exceptionality of the human brain.},
	journaltitle = {Frontiers in Human Neuroscience},
	shortjournal = {Front Hum Neurosci},
	author = {Herculano-Houzel, Suzana},
	urldate = {2017-01-09},
	date = {2009-11-09},
	pmid = {19915731},
	pmcid = {PMC2776484},
	file = {PubMed Central Full Text PDF:/home/jdehning/Zotero/storage/CF8UXMXN/Herculano-Houzel - 2009 - The Human Brain in Numbers A Linearly Scaled-up P.pdf:application/pdf}
}

@article{fries_mechanism_2005,
	title = {A mechanism for cognitive dynamics: neuronal communication through neuronal coherence},
	volume = {9},
	issn = {1364-6613},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661305002421},
	doi = {10.1016/j.tics.2005.08.011},
	shorttitle = {A mechanism for cognitive dynamics},
	abstract = {At any one moment, many neuronal groups in our brain are active. Microelectrode recordings have characterized the activation of single neurons and {fMRI} has unveiled brain-wide activation patterns. Now it is time to understand how the many active neuronal groups interact with each other and how their communication is flexibly modulated to bring about our cognitive dynamics. I hypothesize that neuronal communication is mechanistically subserved by neuronal coherence. Activated neuronal groups oscillate and thereby undergo rhythmic excitability fluctuations that produce temporal windows for communication. Only coherently oscillating neuronal groups can interact effectively, because their communication windows for input and for output are open at the same times. Thus, a flexible pattern of coherence defines a flexible communication structure, which subserves our cognitive flexibility.},
	pages = {474--480},
	number = {10},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Fries, Pascal},
	urldate = {2016-10-26},
	date = {2005-10},
	file = {ScienceDirect Full Text PDF:/home/jdehning/Zotero/storage/STB44GTX/Fries - 2005 - A mechanism for cognitive dynamics neuronal commu.pdf:application/pdf;ScienceDirect Snapshot:/home/jdehning/Zotero/storage/PEKB26N4/S1364661305002421.html:text/html}
}

@article{lee_top-down_2013,
	title = {Top-Down Beta Rhythms Support Selective Attention via Interlaminar Interaction: A Model},
	volume = {9},
	issn = {1553-7358},
	url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003164},
	doi = {10.1371/journal.pcbi.1003164},
	shorttitle = {Top-Down Beta Rhythms Support Selective Attention via Interlaminar Interaction},
	abstract = {Author Summary  Top-down signals originate from higher cognitive areas such as parietal and prefrontal cortex and propagate to earlier stages of the brain. They have been thought to be associated with selective attention, and recent physiological studies suggest that top-down signals in the beta frequency band can support selective attention. In this study, we employ a computational model to investigate potential mechanisms by which top-down beta rhythms can influence neural responses induced by presentation of stimuli. The model includes several cell types, reportedly crucial for generating cortical rhythmic activity in the gamma and beta frequency bands, and the simulation results show that top-down beta rhythms are capable of reproducing experimentally observed attentional effects on neural responses to visual stimuli. These modulatory effects of top-down beta rhythms are mainly induced via activation of ascending inhibition originating from deep layer slow inhibitory interneurons. Since the excitability of slow interneurons can be increased by cholinergic neuromodulators, these interneurons may mediate the effects of cholinergic tone on attention.},
	pages = {e1003164},
	number = {8},
	journaltitle = {{PLOS} Comput Biol},
	shortjournal = {{PLOS} Comput Biol},
	author = {Lee, Jung H. and Whittington, Miles A. and Kopell, Nancy J.},
	urldate = {2016-10-26},
	date = {2013-08-08},
	keywords = {Interneurons, Synapses, Action Potentials, Attention, Inhibitions, Pyramidal cells, Simulation and modeling, Thalamus},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/Q3P5NUTB/Lee et al. - 2013 - Top-Down Beta Rhythms Support Selective Attention .pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/7I3XKI4R/article.html:text/html}
}

@article{dotson_methods_2015,
	title = {Methods, caveats and the future of large-scale microelectrode recordings in the non-human primate},
	volume = {9},
	issn = {1662-5137},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4630292/},
	doi = {10.3389/fnsys.2015.00149},
	abstract = {Cognitive processes play out on massive brain-wide networks, which produce widely distributed patterns of activity. Capturing these activity patterns requires tools that are able to simultaneously measure activity from many distributed sites with high spatiotemporal resolution. Unfortunately, current techniques with adequate coverage do not provide the requisite spatiotemporal resolution. Large-scale microelectrode recording devices, with dozens to hundreds of microelectrodes capable of simultaneously recording from nearly as many cortical and subcortical areas, provide a potential way to minimize these tradeoffs. However, placing hundreds of microelectrodes into a behaving animal is a highly risky and technically challenging endeavor that has only been pursued by a few groups. Recording activity from multiple electrodes simultaneously also introduces several statistical and conceptual dilemmas, such as the multiple comparisons problem and the uncontrolled stimulus response problem. In this perspective article, we discuss some of the techniques that we, and others, have developed for collecting and analyzing large-scale data sets, and address the future of this emerging field.},
	journaltitle = {Frontiers in Systems Neuroscience},
	shortjournal = {Front Syst Neurosci},
	author = {Dotson, Nicholas M. and Goodell, Baldwin and Salazar, Rodrigo F. and Hoffman, Steven J. and Gray, Charles M.},
	urldate = {2016-10-26},
	date = {2015-11-03},
	pmid = {26578906},
	pmcid = {PMC4630292},
	file = {PubMed Central Full Text PDF:/home/jdehning/Zotero/storage/E237PQMF/Dotson et al. - 2015 - Methods, caveats and the future of large-scale mic.pdf:application/pdf}
}

@article{michalareas_alpha-beta_2016,
	title = {Alpha-Beta and Gamma Rhythms Subserve Feedback and Feedforward Influences among Human Visual Cortical Areas},
	volume = {89},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627315011204},
	doi = {10.1016/j.neuron.2015.12.018},
	abstract = {Summary
Primate visual cortex is hierarchically organized. Bottom-up and top-down influences are exerted through distinct frequency channels, as was recently revealed in macaques by correlating inter-areal influences with laminar anatomical projection patterns. Because this anatomical data cannot be obtained in human subjects, we selected seven homologous macaque and human visual areas, and we correlated the macaque laminar projection patterns to human inter-areal directed influences as measured with magnetoencephalography. We show that influences along feedforward projections predominate in the gamma band, whereas influences along feedback projections predominate in the alpha-beta band. Rhythmic inter-areal influences constrain a functional hierarchy of the seven homologous human visual areas that is in close agreement with the respective macaque anatomical hierarchy. Rhythmic influences allow an extension of the hierarchy to 26 human visual areas including uniquely human brain areas. Hierarchical levels of ventral- and dorsal-stream visual areas are differentially affected by inter-areal influences in the alpha-beta band.},
	pages = {384--397},
	number = {2},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Michalareas, Georgios and Vezoli, Julien and van Pelt, Stan and Schoffelen, Jan-Mathijs and Kennedy, Henry and Fries, Pascal},
	urldate = {2016-10-26},
	date = {2016-01-20},
	file = {ScienceDirect Full Text PDF:/home/jdehning/Zotero/storage/D4GNPRDJ/Michalareas et al. - 2016 - Alpha-Beta and Gamma Rhythms Subserve Feedback and.pdf:application/pdf;ScienceDirect Snapshot:/home/jdehning/Zotero/storage/DTFNGSBF/S0896627315011204.html:text/html}
}

@article{bastos_dcm_2015,
	title = {A {DCM} study of spectral asymmetries in feedforward and feedback connections between visual areas V1 and V4 in the monkey},
	volume = {108},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811915000117},
	doi = {10.1016/j.neuroimage.2014.12.081},
	abstract = {This paper reports a dynamic causal modeling study of electrocorticographic ({ECoG}) data that addresses functional asymmetries between forward and backward connections in the visual cortical hierarchy. Specifically, we ask whether forward connections employ gamma-band frequencies, while backward connections preferentially use lower (beta-band) frequencies. We addressed this question by modeling empirical cross spectra using a neural mass model equipped with superficial and deep pyramidal cell populations—that model the source of forward and backward connections, respectively. This enabled us to reconstruct the transfer functions and associated spectra of specific subpopulations within cortical sources. We first established that Bayesian model comparison was able to discriminate between forward and backward connections, defined in terms of their cells of origin. We then confirmed that model selection was able to identify extrastriate (V4) sources as being hierarchically higher than early visual (V1) sources. Finally, an examination of the auto spectra and transfer functions associated with superficial and deep pyramidal cells confirmed that forward connections employed predominantly higher (gamma) frequencies, while backward connections were mediated by lower (alpha/beta) frequencies. We discuss these findings in relation to current views about alpha, beta, and gamma oscillations and predictive coding in the brain.},
	pages = {460--475},
	journaltitle = {{NeuroImage}},
	shortjournal = {{NeuroImage}},
	author = {Bastos, A. M. and Litvak, V. and Moran, R. and Bosman, C. A. and Fries, P. and Friston, K. J.},
	urldate = {2016-10-26},
	date = {2015-03},
	keywords = {Beta oscillations, Computation, Connectivity, Dynamic causal modeling, Gamma oscillations, Neuronal, Synchronization coherence, Transfer functions},
	file = {ScienceDirect Full Text PDF:/home/jdehning/Zotero/storage/WFTII4A9/Bastos et al. - 2015 - A DCM study of spectral asymmetries in feedforward.pdf:application/pdf;ScienceDirect Snapshot:/home/jdehning/Zotero/storage/82GS32VV/S1053811915000117.html:text/html}
}

@article{honey_slow_2012-2,
	title = {Slow Cortical Dynamics and the Accumulation of Information over Long Timescales},
	volume = {76},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627312007179},
	doi = {10.1016/j.neuron.2012.08.011},
	abstract = {Summary
Making sense of the world requires us to process information over multiple timescales. We sought to identify brain regions that accumulate information over short and long timescales and to characterize the distinguishing features of their dynamics. We recorded electrocorticographic ({ECoG}) signals from individuals watching intact and scrambled movies. Within sensory regions, fluctuations of high-frequency (64–200 Hz) power reliably tracked instantaneous low-level properties of the intact and scrambled movies. Within higher order regions, the power fluctuations were more reliable for the intact movie than the scrambled movie, indicating that these regions accumulate information over relatively long time periods (several seconds or longer). Slow (\&lt;0.1 Hz) fluctuations of high-frequency power with time courses locked to the movies were observed throughout the cortex. Slow fluctuations were relatively larger in regions that accumulated information over longer time periods, suggesting a connection between slow neuronal population dynamics and temporally extended information processing.},
	pages = {423--434},
	number = {2},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Honey, Christopher J. and Thesen, Thomas and Donner, Tobias H. and Silbert, Lauren J. and Carlson, Chad E. and Devinsky, Orrin and Doyle, Werner K. and Rubin, Nava and Heeger, David J. and Hasson, Uri},
	urldate = {2016-10-25},
	date = {2012-10-18},
	file = {ScienceDirect Full Text PDF:/home/jdehning/Zotero/storage/G7I3QCNV/Honey et al. - 2012 - Slow Cortical Dynamics and the Accumulation of Inf.pdf:application/pdf;ScienceDirect Snapshot:/home/jdehning/Zotero/storage/EIC3HXEN/S0896627312007179.html:text/html}
}

@article{felleman_distributed_1991,
	title = {Distributed Hierarchical Processing in the Primate Cerebral Cortex},
	volume = {1},
	issn = {1047-3211, 1460-2199},
	url = {http://cercor.oxfordjournals.org/content/1/1/1.1},
	doi = {10.1093/cercor/1.1.1},
	abstract = {In recent years, many new cortical areas have been identified in the macaque monkey. The number of iden tified connections hetween areas has increased even more dramatically. We report here on (1) a summary of the layout of cortical areas associated with vision and with other modalities, (2) a computerized database for storing and representing large amounts of information on connectivity patterns, and (3) the application of these data to the analysis of hierarchical organization of the cerebral cortex. Our analysis concentrates on the visual system, which includes 25 neocortical areas that are predominantly or exclusively visual in function, plus an additional 7 areas that we regard as visual-association areas on the basis of their extensive visual inputs. A total of 305 connections among these 32 visual and visual-association areas have been reported. This represents 31\% of the possible number of pathways it each area were connected with all others. The actual degree of connectivity is likely to he closer to 40\%. The great majority of pathways involve reciprocal connections be tween areas. There are also extensive connections with cortical areas outside the visual system proper, including the somatosensory cortex, as well as neocortical, transitional, and archicortical regions in the temporal and frontal lobes. In the somatosensory/motor system, there are 62 identified pathways linking 13 cortical areas, suggesting an overall connectivity of about 40\%. Based on the laminar patterns of connections between areas, we propose a hierarchy of visual areas and of somato sensory/motor areas that is more comprehensive thao those suggested in other recent studies. The current version of the visual hierarchy includes 10 levels of cortical processing. Altogether, it contains 14 levels if one includes the retina and lateral geniculate nucleus at the bottom as well as the entorhinal cortex and hippocampus at the top. Within this hierarchy, there are multiple, intertwined processing streams, which, at a low level, are related to the compartmental organization of areas V1 and V2 and, at a high level, are related to the distinction between processing centers in the temporal and parietal lobes. However, there are some pathways and relationships (about 10\% of the total) whose descriptions do not fit cleanly into this hierarchical scheme for one reason or another. In most instances, though, it is unclear whether these represent genuine exceptions to a strict hierarchy rather than inaccuracies or uncertainties in the reported assignment.},
	pages = {1--47},
	number = {1},
	journaltitle = {Cerebral Cortex},
	shortjournal = {Cereb. Cortex},
	author = {Felleman, Daniel J. and Essen, David C. Van},
	urldate = {2016-07-31},
	date = {1991-01-01},
	langid = {english},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/HN2AUN7I/Felleman and Essen - 1991 - Distributed Hierarchical Processing in the Primate.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/JXHMX87G/1.html:text/html}
}

@article{murray_hierarchy_2014,
	title = {A hierarchy of intrinsic timescales across primate cortex},
	volume = {17},
	rights = {© 2014 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1097-6256},
	url = {http://www.nature.com.328-0.han.sub.uni-goettingen.de/neuro/journal/v17/n12/full/nn.3862.html},
	doi = {10.1038/nn.3862},
	abstract = {Specialization and hierarchy are organizing principles for primate cortex, yet there is little direct evidence for how cortical areas are specialized in the temporal domain. We measured timescales of intrinsic fluctuations in spiking activity across areas and found a hierarchical ordering, with sensory and prefrontal areas exhibiting shorter and longer timescales, respectively. On the basis of our findings, we suggest that intrinsic timescales reflect areal specialization for task-relevant computations over multiple temporal ranges.},
	pages = {1661--1663},
	number = {12},
	journaltitle = {Nature Neuroscience},
	shortjournal = {Nat Neurosci},
	author = {Murray, John D. and Bernacchia, Alberto and Freedman, David J. and Romo, Ranulfo and Wallis, Jonathan D. and Cai, Xinying and Padoa-Schioppa, Camillo and Pasternak, Tatiana and Seo, Hyojung and Lee, Daeyeol and Wang, Xiao-Jing},
	urldate = {2016-07-29},
	date = {2014-12},
	langid = {english},
	keywords = {Dynamical systems},
	file = {nn.3862-S1.pdf:/home/jdehning/Zotero/storage/HC5F38JK/nn.3862-S1.pdf:application/pdf;nn.3862.pdf:/home/jdehning/Zotero/storage/VHD44995/nn.3862.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/UCKRZUCS/nn.3862.html:text/html}
}

@article{chaudhuri_large-scale_2015-1,
	title = {A Large-Scale Circuit Mechanism for Hierarchical Dynamical Processing in the Primate Cortex},
	volume = {88},
	issn = {0896-6273},
	url = {/neuron/abstract/S0896-6273(15)00765-5},
	doi = {10.1016/j.neuron.2015.09.008},
	abstract = {We developed a large-scale dynamical model of the macaque neocortex, which is based on recently acquired directed- and weighted-connectivity data from tract-tracing experiments, and which incorporates heterogeneity across areas. A hierarchy of timescales naturally emerges from this system: sensory areas show brief, transient responses to input (appropriate for sensory processing), whereas association areas integrate inputs over time and exhibit persistent activity (suitable for decision-making and working memory). The model displays multiple temporal hierarchies, as evidenced by contrasting responses to visual versus somatosensory stimulation. Moreover, slower prefrontal and temporal areas have a disproportionate impact on global brain dynamics. These findings establish a circuit mechanism for “temporal receptive windows” that are progressively enlarged along the cortical hierarchy, suggest an extension of time integration in decision making from local to large circuits, and should prompt a re-evaluation of the analysis of functional connectivity (measured by {fMRI} or electroencephalography/magnetoencephalography) by taking into account inter-areal heterogeneity.},
	pages = {419--431},
	number = {2},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Chaudhuri, Rishidev and Knoblauch, Kenneth and Gariel, Marie-Alice and Kennedy, Henry and Wang, Xiao-Jing},
	urldate = {2016-07-29},
	date = {2015-10-21},
	file = {1-s2.0-S0896627315007655-main.pdf:/home/jdehning/Zotero/storage/LCB7BVBJ/1-s2.0-S0896627315007655-main.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/5W5ZNMVJ/S0896-6273(15)00765-5.html:text/html;timescales.pdf:/home/jonas/Dropbox/studium/Bachelor/literature/timescales.pdf:application/pdf}
}

@book{barlow_statistics:_1993,
	location = {Chichester, England ; New York},
	title = {Statistics: A Guide to the Use of Statistical Methods in the Physical Sciences},
	isbn = {978-0-471-92295-7},
	shorttitle = {Statistics},
	abstract = {The Manchester Physics Series General Editors: D. J. Sandiford; F. Mandl; A. C. Phillips Department of Physics and Astronomy, University of Manchester Properties of Matter B. H. Flowers and E. Mendoza Optics Second Edition F. G. Smith and J. H. Thomson Statistical Physics Second Edition F. Mandl Electromagnetism Second Edition I. S. Grant and W. R. Phillips Statistics R. J. Barlow Solid State Physics Second Edition J. R. Hook and H. E. Hall Quantum Mechanics F. Mandl Particle Physics Second Edition B. R. Martin and G. Shaw The Physics of Stars Second Edition A.C. Phillips Computing for Scientists R. J. Barlow and A. R. Barnett Written by a physicist, Statistics is tailored to the needs of physical scientists, containing and explaining all they need to know. It concentrates on parameter estimation, especially the methods of Least Squares and Maximum Likelihood, but other techniques, such as hypothesis testing, Bayesian statistics and non-parametric methods are also included. Intended for reasonably numerate scientists it contains all the basic formulae, their derivations and applications, together with some more advanced ones. Statistics features: * Comprehensive coverage of the essential techniques physical scientists are likely to need. * A wealth of examples, and problems with their answers. * Flexible structure and organisation allows it to be used as a course text and a reference. * A review of the basics, so that little prior knowledge is required.},
	pagetotal = {222},
	publisher = {Wiley},
	author = {Barlow, R. J.},
	date = {1993-11}
}

@article{wilke_local_2006,
	title = {Local field potential reflects perceptual suppression in monkey visual cortex},
	volume = {103},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0604673103},
	doi = {10.1073/pnas.0604673103},
	pages = {17507--17512},
	number = {46},
	journaltitle = {Proceedings of the National Academy of Sciences},
	author = {Wilke, M. and Logothetis, N. K. and Leopold, D. A.},
	urldate = {2016-07-09},
	date = {2006-11-14},
	langid = {english},
	file = {Local_field_potential_reflects_perceptual_suppress (1).pdf:/home/jdehning/Zotero/storage/EZWF3NH2/Local_field_potential_reflects_perceptual_suppress (1).pdf:application/pdf}
}

@article{priesemann_subsampling_2009-1,
	title = {Subsampling effects in neuronal avalanche distributions recorded in vivo},
	volume = {10},
	issn = {1471-2202},
	url = {http://dx.doi.org/10.1186/1471-2202-10-40},
	doi = {10.1186/1471-2202-10-40},
	abstract = {Many systems in nature are characterized by complex behaviour where large cascades of events, or avalanches, unpredictably alternate with periods of little activity. Snow avalanches are an example. Often the size distribution f(s) of a system's avalanches follows a power law, and the branching parameter sigma, the average number of events triggered by a single preceding event, is unity. A power law for f(s), and sigma = 1, are hallmark features of self-organized critical ({SOC}) systems, and both have been found for neuronal activity in vitro. Therefore, and since {SOC} systems and neuronal activity both show large variability, long-term stability and memory capabilities, {SOC} has been proposed to govern neuronal dynamics in vivo. Testing this hypothesis is difficult because neuronal activity is spatially or temporally subsampled, while theories of {SOC} systems assume full sampling. To close this gap, we investigated how subsampling affects f(s) and sigma by imposing subsampling on three different {SOC} models. We then compared f(s) and sigma of the subsampled models with those of multielectrode local field potential ({LFP}) activity recorded in three macaque monkeys performing a short term memory task.},
	pages = {40},
	journaltitle = {{BMC} Neuroscience},
	shortjournal = {{BMC} Neuroscience},
	author = {Priesemann, Viola and Munk, Matthias {HJ} and Wibral, Michael},
	urldate = {2016-07-08},
	date = {2009},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/JQQCAQQ3/Priesemann et al. - 2009 - Subsampling effects in neuronal avalanche distribu.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/4Q7UF82D/1471-2202-10-40.html:text/html}
}

@article{levina_dynamical_2007,
	title = {Dynamical synapses causing self-organized criticality in neural networks},
	volume = {3},
	rights = {© 2007 Nature Publishing Group},
	issn = {1745-2473},
	url = {http://www.nature.com/nphys/journal/v3/n12/full/nphys758.html},
	doi = {10.1038/nphys758},
	abstract = {Self-organized criticality is one of the key concepts to describe the emergence of complexity in natural systems. The concept asserts that a system self-organizes into a critical state where system observables are distributed according to a power law. Prominent examples of self-organized critical dynamics include piling of granular media, plate tectonics and stick–slip motion. Critical behaviour has been shown to bring about optimal computational capabilities, optimal transmission, storage of information and sensitivity to sensory stimuli. In neuronal systems, the existence of critical avalanches was predicted and later observed experimentally. However, whereas in the experiments generic critical avalanches were found, in the model of ref. 11 they only show up if the set of parameters is fine-tuned externally to a critical transition state. Here, we demonstrate analytically and numerically that by assuming (biologically more realistic) dynamical synapses in a spiking neural network, the neuronal avalanches turn from an exceptional phenomenon into a typical and robust self-organized critical behaviour, if the total resources of neurotransmitter are sufficiently large.},
	pages = {857--860},
	number = {12},
	journaltitle = {Nature Physics},
	shortjournal = {Nat Phys},
	author = {Levina, A. and Herrmann, J. M. and Geisel, T.},
	urldate = {2016-07-08},
	date = {2007-12},
	langid = {english},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/3F7ZBV6Z/Levina et al. - 2007 - Dynamical synapses causing self-organized critical.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/E2NCQWG7/nphys758.html:text/html}
}

@article{beggs_being_2012,
	title = {Being critical of criticality in the brain},
	volume = {3},
	issn = {1664-042X},
	doi = {10.3389/fphys.2012.00163},
	abstract = {Relatively recent work has reported that networks of neurons can produce avalanches of activity whose sizes follow a power law distribution. This suggests that these networks may be operating near a critical point, poised between a phase where activity rapidly dies out and a phase where activity is amplified over time. The hypothesis that the electrical activity of neural networks in the brain is critical is potentially important, as many simulations suggest that information processing functions would be optimized at the critical point. This hypothesis, however, is still controversial. Here we will explain the concept of criticality and review the substantial objections to the criticality hypothesis raised by skeptics. Points and counter points are presented in dialog form.},
	pages = {163},
	journaltitle = {Frontiers in Physiology},
	shortjournal = {Front Physiol},
	author = {Beggs, John M. and Timme, Nicholas},
	date = {2012},
	pmid = {22701101},
	pmcid = {PMC3369250},
	keywords = {criticality, avalanche, Ising model, multi-electrode array, network, scale-free, statistical physics},
	file = {Beggs-Timme-2012-CriticalOfCriticality (1).pdf:/home/jdehning/Zotero/storage/U9PD5VS5/Beggs-Timme-2012-CriticalOfCriticality (1).pdf:application/pdf}
}

@online{hubel_receptive_1962,
	title = {Receptive fields, binocular interaction and functional architecture in the cat's visual cortex},
	url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.1962.sp006837},
	titleaddon = {The Journal of Physiology},
	author = {Hubel, D. H. and Wiesel, T. N.},
	urldate = {2019-07-17},
	date = {1962-01-01},
	langid = {english},
	doi = {10.1113/jphysiol.1962.sp006837},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/7F7YXR8E/Hubel and Wiesel - 1962 - Receptive fields, binocular interaction and functi.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/LS4T8J35/jphysiol.1962.html:text/html}
}

@article{hubel_receptive_1965,
	title = {Receptive fields and functional architecture in two nonstriate visual areas (18 and 19) of the cat},
	volume = {28},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/abs/10.1152/jn.1965.28.2.229},
	doi = {10.1152/jn.1965.28.2.229},
	pages = {229--289},
	number = {2},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Hubel, David H. and Wiesel, Torsten N.},
	urldate = {2019-07-17},
	date = {1965-03-01},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/7XX2L2KK/Hubel and Wiesel - 1965 - Receptive fields and functional architecture in tw.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/U3DCLUUI/jn.1965.28.2.html:text/html}
}

@article{freidlin_should_2000,
	title = {Should the Median Test be Retired from General Use?},
	volume = {54},
	issn = {0003-1305},
	url = {https://www.jstor.org/stable/2685584},
	doi = {10.2307/2685584},
	abstract = {Although several authors have indicated that the median test has low power in small samples, it continues to be presented in many statistical textbooks, included in a number of popular statistical software packages, and used in a variety of application areas. We present results of a power simulation study that shows that the median test has noticeably lower power, even for the double exponential distribution for which it is asymptotically most powerful, than other readily available rank tests. We suggest that the median test be "retired" from routine use and recommend alternative rank tests that have superior power over a relatively large family of symmetric distributions.},
	pages = {161--164},
	number = {3},
	journaltitle = {The American Statistician},
	author = {Freidlin, Boris and Gastwirth, Joseph L.},
	urldate = {2019-07-21},
	date = {2000}
}

@article{hart_mann-whitney_2001,
	title = {Mann-Whitney test is not just a test of medians: differences in spread can be important},
	volume = {323},
	issn = {0959-8138},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1120984/},
	shorttitle = {Mann-Whitney test is not just a test of medians},
	pages = {391--393},
	number = {7309},
	journaltitle = {{BMJ} : British Medical Journal},
	shortjournal = {{BMJ}},
	author = {Hart, Anna},
	urldate = {2019-07-21},
	date = {2001-08-18},
	pmid = {11509435},
	pmcid = {PMC1120984},
	file = {PubMed Central Full Text PDF:/home/jdehning/Zotero/storage/4G7DXDDB/Hart - 2001 - Mann-Whitney test is not just a test of medians d.pdf:application/pdf}
}

@book{wilcox_statistics_1996,
	location = {San Diego, {CA}, {US}},
	title = {Statistics for the social sciences},
	isbn = {978-0-12-751540-3},
	series = {Statistics for the social sciences},
	abstract = {The primary goal of this book is to provide students in social sciences with a modern introduction to the basic concepts and procedures in statistics. Another goal is to describe various trends and developments that can make a substantial difference in the conclusions reached in analyzing data.  This book is aimed at students whose primary interests are not quantitative methods, but who require modern statistical procedures to do their research. The book is intended for a 2-semester course for graduate students, but it can also be used for a 1-semester course at the undergraduate level. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pagetotal = {xix, 454},
	publisher = {Academic Press},
	author = {Wilcox, Rand R.},
	date = {1996},
	keywords = {Social Sciences, Statistics},
	file = {Snapshot:/home/jdehning/Zotero/storage/A49EMQM4/1996-97140-000.html:text/html}
}

@article{pratt_robustness_1964,
	title = {Robustness of Some Procedures for the Two-Sample Location Problem},
	volume = {59},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/2283092},
	doi = {10.2307/2283092},
	abstract = {The level of ordinary two-sample procedures is not preserved if the two populations differ in dispersion or shape. The effect of such differences, especially differences in dispersion, on the t, median, Mann-Whitney, and normal scores procedures is investigated asymptotically, and tables are given comparing the four procedures.},
	pages = {665--680},
	number = {307},
	journaltitle = {Journal of the American Statistical Association},
	author = {Pratt, John W.},
	urldate = {2019-07-22},
	date = {1964}
}

@inproceedings{brown_median_1951,
	location = {Berkeley, Calif.},
	title = {On Median Tests for Linear Hypotheses},
	url = {https://projecteuclid.org/euclid.bsmsp/1200500226},
	pages = {159--166},
	booktitle = {Proceedings of the Second Berkeley Symposium on Mathematical Statistics and Probability},
	publisher = {University of California Press},
	author = {Brown, G. W. and Mood, A. M.},
	date = {1951},
	file = {Brown and Mood - ON MEDIAN TESTS FOR LINEAR HYPOTHESES.pdf:/home/jdehning/Zotero/storage/GLNYALIQ/Brown and Mood - ON MEDIAN TESTS FOR LINEAR HYPOTHESES.pdf:application/pdf}
}

@article{fligner_modification_1982,
	title = {A Modification of Mood's Median Test for The Generalized Behrens--Fisher Problem},
	volume = {69},
	issn = {0006-3444},
	url = {https://www.jstor.org/stable/2335872},
	doi = {10.2307/2335872},
	abstract = {A modification of Mood's median test is described which allows one to test for differences between two medians without making any assumptions on the shapes of the underlying populations. The proposed procedure is exactly distribution-free when the populations have the same shape and is asymptotically distribution-free when they do not. It is the retention of the exact distribution-free property when the populations have the same shape which distinguishes the proposed procedure from previous work.},
	pages = {221--226},
	number = {1},
	journaltitle = {Biometrika},
	author = {Fligner, Michael A. and Rust, Steven W.},
	urldate = {2019-07-22},
	date = {1982}
}

@incollection{gibbons_nonparametric_2011,
	location = {Berlin, Heidelberg},
	title = {Nonparametric Statistical Inference},
	isbn = {978-3-642-04898-2},
	url = {https://doi.org/10.1007/978-3-642-04898-2_420},
	pages = {977--979},
	booktitle = {International Encyclopedia of Statistical Science},
	publisher = {Springer Berlin Heidelberg},
	author = {Gibbons, Jean Dickinson and Chakraborti, Subhabrata},
	editor = {Lovric, Miodrag},
	urldate = {2019-07-23},
	date = {2011},
	langid = {english},
	doi = {10.1007/978-3-642-04898-2_420}
}

@article{brown_robust_1974,
	title = {Robust Tests for the Equality of Variances},
	volume = {69},
	issn = {0162-1459},
	url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1974.10482955},
	doi = {10.1080/01621459.1974.10482955},
	abstract = {Alternative formulations of Levene's test statistic for equality of variances are found to be robust under nonnormality. These statistics use more robust estimators of central location in place of the mean. They are compared with the unmodified Levene's statistic, a jackknife procedure, and a χ2 test suggested by Layard which are all found to be less robust under nonnormality.},
	pages = {364--367},
	number = {346},
	journaltitle = {Journal of the American Statistical Association},
	author = {Brown, Morton B. and Forsythe, Alan B.},
	urldate = {2019-07-23},
	date = {1974-06-01},
	file = {Brown and Forsythe - 1974 - Robust Tests for the Equality of Variances.pdf:/home/jdehning/Zotero/storage/AT7JKIHD/Brown and Forsythe - 1974 - Robust Tests for the Equality of Variances.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/CZGIHAIH/01621459.1974.html:text/html}
}

@incollection{levene_robust_1960,
	title = {Robust Tests for Equality of Variances},
	booktitle = {Contributions to probability and statistics: essays in honor of Harold Hotelling},
	publisher = {Stanford University Press},
	author = {Levene, Howard},
	date = {1960},
	file = {Levene - 1960 - Robust Tests for Equality of Variances.pdf:/home/jdehning/Zotero/storage/8WBI5HL2/Levene - 1960 - Robust Tests for Equality of Variances.pdf:application/pdf}
}

@article{sussillo_generating_2009,
	title = {Generating Coherent Patterns of Activity from Chaotic Neural Networks},
	volume = {63},
	issn = {0896-6273},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2756108/},
	doi = {10.1016/j.neuron.2009.07.018},
	abstract = {Neural circuits display complex activity patterns both spontaneously and when responding to a stimulus or generating a motor output. How are these two forms of activity related? We develop a procedure called {FORCE} learning for modifying synaptic strengths either external to or within a model neural network to change chaotic spontaneous activity into a wide variety of desired activity patterns. {FORCE} learning works even though the networks we train are spontaneously chaotic and we leave feedback loops intact and unclamped during learning. Using this approach, we construct networks that produce a wide variety of complex output patterns, input-output transformations that require memory, multiple outputs that can be switched by control inputs, and motor patterns matching human motion capture data. Our results reproduce data on pre-movement activity in motor and premotor cortex, and suggest that synaptic plasticity may be a more rapid and powerful modulator of network activity than generally appreciated.},
	pages = {544--557},
	number = {4},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Sussillo, David and Abbott, L. F.},
	urldate = {2019-07-28},
	date = {2009-08-27},
	pmid = {19709635},
	pmcid = {PMC2756108},
	file = {PubMed Central Full Text PDF:/home/jdehning/Zotero/storage/VAD9PFNJ/Sussillo and Abbott - 2009 - Generating Coherent Patterns of Activity from Chao.pdf:application/pdf}
}

@article{sussillo_lfads_2016,
	title = {{LFADS} - Latent Factor Analysis via Dynamical Systems},
	url = {http://arxiv.org/abs/1608.06315},
	abstract = {Neuroscience is experiencing a data revolution in which many hundreds or thousands of neurons are recorded simultaneously. Currently, there is little consensus on how such data should be analyzed. Here we introduce {LFADS} (Latent Factor Analysis via Dynamical Systems), a method to infer latent dynamics from simultaneously recorded, single-trial, high-dimensional neural spiking data. {LFADS} is a sequential model based on a variational auto-encoder. By making a dynamical systems hypothesis regarding the generation of the observed data, {LFADS} reduces observed spiking to a set of low-dimensional temporal factors, per-trial initial conditions, and inferred inputs. We compare {LFADS} to existing methods on synthetic data and show that it significantly out-performs them in inferring neural firing rates and latent dynamics.},
	journaltitle = {{arXiv}:1608.06315 [cs, q-bio, stat]},
	author = {Sussillo, David and Jozefowicz, Rafal and Abbott, L. F. and Pandarinath, Chethan},
	urldate = {2019-07-28},
	date = {2016-08-22},
	eprinttype = {arxiv},
	eprint = {1608.06315},
	keywords = {Quantitative Biology - Neurons and Cognition, Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv\:1608.06315 PDF:/home/jdehning/Zotero/storage/5D6AH4PZ/Sussillo et al. - 2016 - LFADS - Latent Factor Analysis via Dynamical Syste.pdf:application/pdf;arXiv.org Snapshot:/home/jdehning/Zotero/storage/I5MSSCZL/1608.html:text/html}
}

@article{churchland_neural_2012-1,
	title = {Neural population dynamics during reaching},
	volume = {487},
	issn = {0028-0836},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3393826/},
	doi = {10.1038/nature11129},
	abstract = {Most theories of motor cortex have assumed that neural activity represents movement parameters. This view derives from an analogous approach to primary visual cortex, where neural activity represents patterns of light. Yet it is unclear how well that analogy holds. Single-neuron responses in motor cortex appear strikingly complex, and there is marked disagreement regarding which movement parameters are represented. A better analogy might be with other motor systems, where a common principle is rhythmic neural activity. We found that motor cortex responses during reaching contain a brief but strong oscillatory component, something quite unexpected for a non-periodic behavior. Oscillation amplitude and phase followed naturally from the preparatory state, suggesting a mechanistic role for preparatory neural activity. These results demonstrate unexpected yet surprisingly simple structure in the population response. That underlying structure explains many of the confusing features of individual-neuron responses.},
	pages = {51--56},
	number = {7405},
	journaltitle = {Nature},
	shortjournal = {Nature},
	author = {Churchland, {MM} and Cunningham, {JP} and Kaufman, {MT} and Foster, {JD} and Nuyujukian, P and Ryu, {SI} and Shenoy, {KV}},
	urldate = {2019-07-28},
	date = {2012-07-05},
	pmid = {22722855},
	pmcid = {PMC3393826},
	file = {PubMed Central Full Text PDF:/home/jdehning/Zotero/storage/IM8RG84N/Churchland et al. - 2012 - Neural population dynamics during reaching.pdf:application/pdf}
}

@article{mackevicius_unsupervised_2019,
	title = {Unsupervised discovery of temporal sequences in high-dimensional datasets, with applications to neuroscience},
	volume = {8},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.38471},
	doi = {10.7554/eLife.38471},
	abstract = {Identifying low-dimensional features that describe large-scale neural recordings is a major challenge in neuroscience. Repeated temporal patterns (sequences) are thought to be a salient feature of neural dynamics, but are not succinctly captured by traditional dimensionality reduction techniques. Here, we describe a software toolbox—called {seqNMF}—with new methods for extracting informative, non-redundant, sequences from high-dimensional neural data, testing the significance of these extracted patterns, and assessing the prevalence of sequential structure in data. We test these methods on simulated data under multiple noise conditions, and on several real neural and behavioral datas. In hippocampal data, {seqNMF} identifies neural sequences that match those calculated manually by reference to behavioral events. In songbird data, {seqNMF} discovers neural sequences in untutored birds that lack stereotyped songs. Thus, by identifying temporal structure directly from neural data, {seqNMF} enables dissection of complex neural circuits without relying on temporal references from stimuli or behavioral outputs.},
	pages = {e38471},
	journaltitle = {{eLife}},
	author = {Mackevicius, Emily L and Bahle, Andrew H and Williams, Alex H and Gu, Shijie and Denisenko, Natalia I and Goldman, Mark S and Fee, Michale S},
	editor = {Colgin, Laura and Behrens, Timothy E},
	urldate = {2019-07-28},
	date = {2019-02-05},
	keywords = {matrix factorization, sequence, unsupervised, Zebra finch},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/MBDVGKTJ/Mackevicius et al. - 2019 - Unsupervised discovery of temporal sequences in hi.pdf:application/pdf}
}

@article{kuhn_expansion_2018,
	title = {Expansion of the effective action around non-Gaussian theories},
	volume = {51},
	issn = {1751-8113, 1751-8121},
	url = {http://arxiv.org/abs/1711.05599},
	doi = {10.1088/1751-8121/aad52e},
	abstract = {This paper derives the Feynman rules for the diagrammatic perturbation expansion of the effective action around an arbitrary solvable problem. The perturbation expansion around a Gaussian theory is well known and composed of one-line irreducible diagrams only. For the expansions around an arbitrary, non-Gaussian problem, we show that a more general class of irreducible diagrams remains in addition to a second set of diagrams that has no analogue in the Gaussian case. The effective action is central to field theory, in particular to the study of phase transitions, symmetry breaking, effective equations of motion, and renormalization. We exemplify the method on the Ising model, where the effective action amounts to the Gibbs free energy, recovering the Thouless-Anderson-Palmer mean-field theory in a fully diagrammatic derivation. Higher order corrections follow with only minimal effort compared to existing techniques. Our results show further that the Plefka expansion and the high-temperature expansion are special cases of the general formalism presented here.},
	pages = {375004},
	number = {37},
	journaltitle = {Journal of Physics A: Mathematical and Theoretical},
	shortjournal = {J. Phys. A: Math. Theor.},
	author = {Kühn, Tobias and Helias, Moritz},
	urldate = {2019-07-28},
	date = {2018-09-14},
	eprinttype = {arxiv},
	eprint = {1711.05599},
	keywords = {Condensed Matter - Statistical Mechanics, Mathematical Physics},
	file = {arXiv\:1711.05599 PDF:/home/jdehning/Zotero/storage/R22TW848/Kühn and Helias - 2018 - Expansion of the effective action around non-Gauss.pdf:application/pdf;arXiv.org Snapshot:/home/jdehning/Zotero/storage/6LI7L4RV/1711.html:text/html}
}

@article{jazayeri_navigating_2017,
	title = {Navigating the Neural Space in Search of the Neural Code},
	volume = {93},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(17)30103-4},
	doi = {10.1016/j.neuron.2017.02.019},
	pages = {1003--1014},
	number = {5},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Jazayeri, Mehrdad and Afraz, Arash},
	urldate = {2019-07-28},
	date = {2017-03-08},
	pmid = {28279349},
	keywords = {behavior, causation, correlation, neural code, neural manifold, perturbation},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/2IVZYWAK/Jazayeri and Afraz - 2017 - Navigating the Neural Space in Search of the Neura.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/2CP49QLW/S0896-6273(17)30103-4.html:text/html}
}

@article{marinescu_quasi-experimental_2018,
	title = {Quasi-experimental causality in neuroscience and behavioural research},
	volume = {2},
	rights = {2018 Springer Nature Limited},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-018-0466-5},
	doi = {10.1038/s41562-018-0466-5},
	abstract = {How to establish causal links is a central question across scientific disciplines. Marinescu and colleagues describe methods from empirical economics and how they could be adapted across fields, for example, to psychology and neuroscience, to test causality.},
	pages = {891},
	number = {12},
	journaltitle = {Nature Human Behaviour},
	author = {Marinescu, Ioana E. and Lawlor, Patrick N. and Kording, Konrad P.},
	urldate = {2019-07-28},
	date = {2018-12},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/AMRLBVTZ/Marinescu et al. - 2018 - Quasi-experimental causality in neuroscience and b.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/KZVG6LU4/s41562-018-0466-5.html:text/html}
}

@article{asllani_structure_2018,
	title = {Structure and dynamical behavior of non-normal networks},
	volume = {4},
	rights = {Copyright © 2018 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution {NonCommercial} License 4.0 ({CC} {BY}-{NC}).. This is an open-access article distributed under the terms of the Creative Commons Attribution-{NonCommercial} license, which permits use, distribution, and reproduction in any medium, so long as the resultant use is not for commercial advantage and provided the original work is properly cited.},
	issn = {2375-2548},
	url = {https://advances.sciencemag.org/content/4/12/eaau9403},
	doi = {10.1126/sciadv.aau9403},
	abstract = {We analyze a collection of empirical networks in a wide spectrum of disciplines and show that strong non-normality is ubiquitous in network science. Dynamical processes evolving on non-normal networks exhibit a peculiar behavior, as initial small disturbances may undergo a transient phase and be strongly amplified in linearly stable systems. In addition, eigenvalues may become extremely sensible to noise and have a diminished physical meaning. We identify structural properties of networks that are associated with non-normality and propose simple models to generate networks with a tunable level of non-normality. We also show the potential use of a variety of metrics capturing different aspects of non-normality and propose their potential use in the context of the stability of complex ecosystems.
We show that many real-world networks are non-normal, with important consequences for their stability and dynamical behavior.
We show that many real-world networks are non-normal, with important consequences for their stability and dynamical behavior.},
	pages = {eaau9403},
	number = {12},
	journaltitle = {Science Advances},
	author = {Asllani, Malbor and Lambiotte, Renaud and Carletti, Timoteo},
	urldate = {2019-07-28},
	date = {2018-12-01},
	langid = {english},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/2VQCHSB6/Asllani et al. - 2018 - Structure and dynamical behavior of non-normal net.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/34TW4CIP/eaau9403.html:text/html}
}

@article{demirtas_hierarchical_2018,
	title = {Hierarchical Heterogeneity Across Human Cortex Shapes Large-Scale Neural Dynamics},
	rights = {© 2018, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/341966v1},
	doi = {10.1101/341966},
	abstract = {{\textless}h3{\textgreater}Summary{\textless}/h3{\textgreater} {\textless}p{\textgreater}The large-scale organization of dynamical neural activity across cortex emerges through long-range interactions among local circuits. We hypothesized that large-scale dynamics are also shaped by heterogeneity of intrinsic local properties across cortical areas. One key axis along which microcircuit properties are specialized relates to hierarchical levels of cortical organization. We developed a large-scale dynamical circuit model of human cortex that incorporates heterogeneity of local synaptic strengths, following a hierarchical axis inferred from {MRI}-derived T1w/T2w mapping, and fit the model using multimodal neuroimaging data. We found that incorporating hierarchical heterogeneity substantially improves the model fit to {fMRI}-measured resting-state functional connectivity and captures sensory-association organization of multiple {fMRI} features. The model predicts hierarchically organized high-frequency spectral power, which we tested with resting-state magnetoencephalography. These findings suggest circuit-level mechanisms linking spatiotemporal levels of analysis and highlight the importance of local properties and their hierarchical specialization on the large-scale organization of human cortical dynamics.{\textless}/p{\textgreater}},
	pages = {341966},
	journaltitle = {{bioRxiv}},
	author = {Demirtaş, Murat and Burt, Joshua B. and Helmer, Markus and Ji, Jie Lisa and Adkinson, Brendan D. and Glasser, Matthew F. and Essen, David C. Van and Sotiropoulos, Stamatios N. and Anticevic, Alan and Murray, John D.},
	urldate = {2019-07-28},
	date = {2018-06-08},
	langid = {english},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/BKLESVTK/Demirtaş et al. - 2018 - Hierarchical Heterogeneity Across Human Cortex Sha.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/2GEWLCS4/341966v1.html:text/html}
}

@article{wang_inversion_2019,
	title = {Inversion of a large-scale circuit model reveals a cortical hierarchy in the dynamic resting human brain},
	volume = {5},
	rights = {Copyright © 2019 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution License 4.0 ({CC} {BY}).. This is an open-access article distributed under the terms of the Creative Commons Attribution license, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.},
	issn = {2375-2548},
	url = {https://advances.sciencemag.org/content/5/1/eaat7854},
	doi = {10.1126/sciadv.aat7854},
	abstract = {We considered a large-scale dynamical circuit model of human cerebral cortex with region-specific microscale properties. The model was inverted using a stochastic optimization approach, yielding markedly better fit to new, out-of-sample resting functional magnetic resonance imaging ({fMRI}) data. Without assuming the existence of a hierarchy, the estimated model parameters revealed a large-scale cortical gradient. At one end, sensorimotor regions had strong recurrent connections and excitatory subcortical inputs, consistent with localized processing of external stimuli. At the opposing end, default network regions had weak recurrent connections and excitatory subcortical inputs, consistent with their role in internal thought. Furthermore, recurrent connection strength and subcortical inputs provided complementary information for differentiating the levels of the hierarchy, with only the former showing strong associations with other macroscale and microscale proxies of cortical hierarchies (meta-analysis of cognitive functions, principal resting {fMRI} gradient, myelin, and laminar-specific neuronal density). Overall, this study provides microscale insights into a macroscale cortical hierarchy in the dynamic resting brain.
Converging evidence from biophysical modeling, magnetic resonance imaging, and histology reveals a large-scale cortical gradient.
Converging evidence from biophysical modeling, magnetic resonance imaging, and histology reveals a large-scale cortical gradient.},
	pages = {eaat7854},
	number = {1},
	journaltitle = {Science Advances},
	author = {Wang, Peng and Kong, Ru and Kong, Xiaolu and Liégeois, Raphaël and Orban, Csaba and Deco, Gustavo and Heuvel, Martijn P. van den and Yeo, B. T. Thomas},
	urldate = {2019-07-28},
	date = {2019-01-01},
	langid = {english},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/Y7FT4QCG/Wang et al. - 2019 - Inversion of a large-scale circuit model reveals a.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/EUEDZUCS/eaat7854.html:text/html}
}

@article{chen_ultrasensitive_2013,
	title = {Ultrasensitive fluorescent proteins for imaging neuronal activity},
	volume = {499},
	issn = {1476-4687},
	doi = {10.1038/nature12354},
	abstract = {Fluorescent calcium sensors are widely used to image neural activity. Using structure-based mutagenesis and neuron-based screening, we developed a family of ultrasensitive protein calcium sensors ({GCaMP}6) that outperformed other sensors in cultured neurons and in zebrafish, flies and mice in vivo. In layer 2/3 pyramidal neurons of the mouse visual cortex, {GCaMP}6 reliably detected single action potentials in neuronal somata and orientation-tuned synaptic calcium transients in individual dendritic spines. The orientation tuning of structurally persistent spines was largely stable over timescales of weeks. Orientation tuning averaged across spine populations predicted the tuning of their parent cell. Although the somata of {GABAergic} neurons showed little orientation tuning, their dendrites included highly tuned dendritic segments (5-40-µm long). {GCaMP}6 sensors thus provide new windows into the organization and dynamics of neural circuits over multiple spatial and temporal scales.},
	pages = {295--300},
	number = {7458},
	journaltitle = {Nature},
	shortjournal = {Nature},
	author = {Chen, Tsai-Wen and Wardill, Trevor J. and Sun, Yi and Pulver, Stefan R. and Renninger, Sabine L. and Baohan, Amy and Schreiter, Eric R. and Kerr, Rex A. and Orger, Michael B. and Jayaraman, Vivek and Looger, Loren L. and Svoboda, Karel and Kim, Douglas S.},
	date = {2013-07-18},
	pmid = {23868258},
	pmcid = {PMC3777791},
	keywords = {Action Potentials, Animals, Calcium, Calcium-Binding Proteins, Cells, Cultured, Dendritic Spines, Fluorescent Dyes, {GABAergic} Neurons, Luminescent Proteins, Mice, Molecular Imaging, Mutagenesis, Protein Engineering, Pyramidal Cells, Visual Cortex},
	file = {Accepted Version:/home/jdehning/Zotero/storage/Y4PTWWVN/Chen et al. - 2013 - Ultrasensitive fluorescent proteins for imaging ne.pdf:application/pdf}
}

@article{theis_benchmarking_2016,
	title = {Benchmarking Spike Rate Inference in Population Calcium Imaging},
	volume = {90},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627316300733},
	doi = {10.1016/j.neuron.2016.04.014},
	abstract = {Summary
A fundamental challenge in calcium imaging has been to infer spike rates of neurons from the measured noisy fluorescence traces. We systematically evaluate different spike inference algorithms on a large benchmark dataset ({\textgreater}100,000 spikes) recorded from varying neural tissue (V1 and retina) using different calcium indicators ({OGB}-1 and {GCaMP}6). In addition, we introduce a new algorithm based on supervised learning in flexible probabilistic models and find that it performs better than other published techniques. Importantly, it outperforms other algorithms even when applied to entirely new datasets for which no simultaneously recorded data is available. Future data acquired in new experimental conditions can be used to further improve the spike prediction accuracy and generalization performance of the model. Finally, we show that comparing algorithms on artificial data is not informative about performance on real data, suggesting that benchmarking different methods with real-world datasets may greatly facilitate future algorithmic developments in neuroscience.},
	pages = {471--482},
	number = {3},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Theis, Lucas and Berens, Philipp and Froudarakis, Emmanouil and Reimer, Jacob and Román Rosón, Miroslav and Baden, Tom and Euler, Thomas and Tolias, Andreas S. and Bethge, Matthias},
	urldate = {2019-07-29},
	date = {2016-05-04},
	file = {ScienceDirect Full Text PDF:/home/jdehning/Zotero/storage/SBL7GVSU/Theis et al. - 2016 - Benchmarking Spike Rate Inference in Population Ca.pdf:application/pdf;ScienceDirect Snapshot:/home/jdehning/Zotero/storage/IEMVXH82/S0896627316300733.html:text/html}
}

@article{pachitariu_robustness_2018,
	title = {Robustness of Spike Deconvolution for Neuronal Calcium Imaging},
	volume = {38},
	rights = {Copyright © 2018 Pachitariu et al.. This is an open-access article distributed under the terms of the Creative Commons Attribution License Creative Commons Attribution 4.0 International, which permits unrestricted use, distribution and reproduction in any medium provided that the original work is properly attributed.},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/38/37/7976},
	doi = {10.1523/JNEUROSCI.3339-17.2018},
	abstract = {Calcium imaging is a powerful method to record the activity of neural populations in many species, but inferring spike times from calcium signals is a challenging problem. We compared multiple approaches using multiple datasets with ground truth electrophysiology and found that simple non-negative deconvolution ({NND}) outperformed all other algorithms on out-of-sample test data. We introduce a novel benchmark applicable to recordings without electrophysiological ground truth, based on the correlation of responses to two stimulus repeats, and used this to show that unconstrained {NND} also outperformed the other algorithms when run on “zoomed out” datasets of ∼10,000 cell recordings from the visual cortex of mice of either sex. Finally, we show that {NND}-based methods match the performance of a supervised method based on convolutional neural networks while avoiding some of the biases of such methods, and at much faster running times. We therefore recommend that spikes be inferred from calcium traces using simple {NND} because of its simplicity, efficiency, and accuracy.
{SIGNIFICANCE} {STATEMENT} The experimental method that currently allows for recordings of the largest numbers of cells simultaneously is two-photon calcium imaging. However, use of this powerful method requires that neuronal firing times be inferred correctly from the large resulting datasets. Previous studies have claimed that complex supervised learning algorithms outperform simple deconvolution methods at this task. Unfortunately, these studies suffered from several problems and biases. When we repeated the analysis, using the same data and correcting these problems, we found that simpler spike inference methods perform better. Even more importantly, we found that supervised learning methods can introduce artifactual structure into spike trains, which can in turn lead to erroneous scientific conclusions. Of the algorithms we evaluated, we found that an extremely simple method performed best in all circumstances tested, was much faster to run, and was insensitive to parameter choices, making incorrect scientific conclusions much less likely.},
	pages = {7976--7985},
	number = {37},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Pachitariu, Marius and Stringer, Carsen and Harris, Kenneth D.},
	urldate = {2019-07-29},
	date = {2018-09-12},
	langid = {english},
	pmid = {30082416},
	keywords = {calcium imaging, spike deconvolution, spike inference},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/9M36L4WP/Pachitariu et al. - 2018 - Robustness of Spike Deconvolution for Neuronal Cal.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/CFD2MQDU/7976.html:text/html}
}

@online{noauthor_neuronal_1900,
	title = {Neuronal spatial arrangement shapes effective connectivity traits of in vitro cortical networks},
	url = {https://www.computer.org/csdl/journal/tn/5555/01/08424896/13rRUxYIMVY},
	abstract = {We studied effective connectivity in rat cortical cultures with various degrees of spatial aggregation, ranging from homogeneous networks to highly aggregated ones. We considered small cultures 3 mm in diameter and that contained about 2000 neurons. Spatial inhomogeneity favored an increase of metric correlations and connectivity among neighboring neurons. Effective connectivity was determined from spontaneous activity recordings using calcium fluorescence imaging. We used generalized transfer entropy as tool to infer the effective connectivity. We carried out numerical simulations to build networks that mimicked the experimental ones and to test the reliability of the connectivity-inference algorithm. Effective connectivity traits were investigated during the development of the cultures over two weeks, and along the gradual blockade of excitatory connections through {CNQX}. We observed that the average effective connectivity rapidly increased during culture development. At {DIV} 15 the average excitatory in-degree was measured as \${\textbackslash}bar k{\textasciicircum}{\textbackslash}text\{in\}\_E{\textbackslash}simeq 50\$ for homogeneous and semi aggregated networks, and \${\textbackslash}bar k{\textasciicircum}{\textbackslash}text\{in\}\_E{\textbackslash}simeq 120\$ for aggregated ones, and with 20\% inhibition. Aggregated cultures exhibited assortative traits and a high resilience to chemical damage, while the other cultures were dissassortative or neutral, and less resilient. Our work illustrates the role of metric correlations in spatially embedded networks in shaping connectivity and activity traits in living neuronal networks.},
	type = {text},
	urldate = {2019-07-29},
	date = {1900-01-01},
	langid = {english},
	doi = {10.1109/TNSE.2018.2862919},
	file = {1900 - Neuronal spatial arrangement shapes effective conn.pdf:/home/jdehning/Zotero/storage/CV3QUWWW/1900 - Neuronal spatial arrangement shapes effective conn.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/QBJSLVT3/13rRUxYIMVY.html:text/html}
}

@article{friedrich_fast_2017,
	title = {Fast online deconvolution of calcium imaging data},
	volume = {13},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005423},
	doi = {10.1371/journal.pcbi.1005423},
	abstract = {Fluorescent calcium indicators are a popular means for observing the spiking activity of large neuronal populations, but extracting the activity of each neuron from raw fluorescence calcium imaging data is a nontrivial problem. We present a fast online active set method to solve this sparse non-negative deconvolution problem. Importantly, the algorithm 3progresses through each time series sequentially from beginning to end, thus enabling real-time online estimation of neural activity during the imaging session. Our algorithm is a generalization of the pool adjacent violators algorithm ({PAVA}) for isotonic regression and inherits its linear-time computational complexity. We gain remarkable increases in processing speed: more than one order of magnitude compared to currently employed state of the art convex solvers relying on interior point methods. Unlike these approaches, our method can exploit warm starts; therefore optimizing model hyperparameters only requires a handful of passes through the data. A minor modification can further improve the quality of activity inference by imposing a constraint on the minimum spike size. The algorithm enables real-time simultaneous deconvolution of O(105) traces of whole-brain larval zebrafish imaging data on a laptop.},
	pages = {e1005423},
	number = {3},
	journaltitle = {{PLOS} Computational Biology},
	shortjournal = {{PLOS} Computational Biology},
	author = {Friedrich, Johannes and Zhou, Pengcheng and Paninski, Liam},
	urldate = {2019-07-29},
	date = {2017-03-14},
	langid = {english},
	keywords = {Action potentials, Algorithms, Calcium imaging, Calcium signaling, Fluorescence imaging, Isotonic, Neurons, Optimization},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/ALBTBQSM/Friedrich et al. - 2017 - Fast online deconvolution of calcium imaging data.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/M64JZBGJ/article.html:text/html}
}

@online{noauthor_spikefinder_nodate,
	title = {spikefinder},
	url = {http://spikefinder.codeneuro.org/},
	abstract = {benchmarking challenge for detecting spikes in imaging data},
	urldate = {2019-07-29},
	file = {Snapshot:/home/jdehning/Zotero/storage/K4WGAKBT/spikefinder.codeneuro.org.html:text/html}
}

@article{pachitariu_suite2p:_2017,
	title = {Suite2p: beyond 10,000 neurons with standard two-photon microscopy},
	rights = {© 2017, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), {CC} {BY} 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/061507v2},
	doi = {10.1101/061507},
	shorttitle = {Suite2p},
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}p{\textgreater}Two-photon microscopy of calcium-dependent sensors has enabled unprecedented recordings from vast populations of neurons. While the sensors and microscopes have matured over several generations of development, computational methods to process the resulting movies remain inefficient and can give results that are hard to interpret. Here we introduce Suite2p: a fast, accurate and complete pipeline that registers raw movies, detects active cells, extracts their calcium traces and infers their spike times. Suite2p runs on standard workstations, operates faster than real time, and recovers {\textasciitilde}2 times more cells than the previous state-of-the-art method. Its low computational load allows routine detection of {\textasciitilde}10,000 cells simultaneously with standard two-photon resonant-scanning microscopes. Recordings at this scale promise to reveal the fine structure of activity in large populations of neurons or large populations of subcellular structures such as synaptic boutons.{\textless}/p{\textgreater}},
	pages = {061507},
	journaltitle = {{bioRxiv}},
	author = {Pachitariu, Marius and Stringer, Carsen and Dipoppa, Mario and Schröder, Sylvia and Rossi, L. Federico and Dalgleish, Henry and Carandini, Matteo and Harris, Kenneth D.},
	urldate = {2019-07-29},
	date = {2017-07-20},
	langid = {english},
	file = {Full Text PDF:/home/jdehning/Zotero/storage/V2XLL22E/Pachitariu et al. - 2017 - Suite2p beyond 10,000 neurons with standard two-p.pdf:application/pdf;Snapshot:/home/jdehning/Zotero/storage/BHZSU3UI/061507v2.html:text/html}
}